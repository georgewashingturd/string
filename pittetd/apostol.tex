\documentclass[aps,preprint,preprintnumbers,nofootinbib,showpacs,prd]{revtex4-1}
\usepackage{graphicx,color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amssymb}
\usepackage{multirow}
\usepackage{amsthm}%        But you can't use \usewithpatch for several packages as in this line. The search 

\usepackage{cancel}

%%% for SLE
\usepackage{dcolumn}   % needed for some tables
\usepackage{bm}        % for math
\usepackage{amssymb}   % for math
\usepackage{multirow}
%%% for SLE -End

\usepackage{ulem}
\usepackage{cancel}

\usepackage{hyperref}

\usepackage[top=1in, bottom=1.25in, left=1.1in, right=1.1in]{geometry}

\usepackage{mathtools} % for \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\usepackage{simplewick}

\newcommand{\msout}[1]{\text{\sout{\ensuremath{#1}}}}


%%%%%% My stuffs - Stef
\newcommand{\lsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$<$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}
\newcommand{\gsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$>$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}

%
% Key
%
\newcommand{\key}[1]{\medskip{\sffamily\bfseries\color{blue}#1}\par\medskip}
%\newcommand{\key}[1]{}
\newcommand{\q}[1] {\medskip{\sffamily\bfseries\color{red}#1}\par\medskip}
\newcommand{\comment}[2]{{\color{red}{{\bf #1:}  #2}}}


\newcommand{\ie}{{\it i.e.} }
\newcommand{\eg}{{\it e.g.} }

%
% Energy scales
%
\newcommand{\ev}{{\,{\rm eV}}}
\newcommand{\kev}{{\,{\rm keV}}}
\newcommand{\mev}{{\,{\rm MeV}}}
\newcommand{\gev}{{\,{\rm GeV}}}
\newcommand{\tev}{{\,{\rm TeV}}}
\newcommand{\fb}{{\,{\rm fb}}}
\newcommand{\ifb}{{\,{\rm fb}^{-1}}}

%
% SUSY notations
%
\newcommand{\neu}{\tilde{\chi}^0}
\newcommand{\neuo}{{\tilde{\chi}^0_1}}
\newcommand{\neut}{{\tilde{\chi}^0_2}}
\newcommand{\cha}{{\tilde{\chi}^\pm}}
\newcommand{\chao}{{\tilde{\chi}^\pm_1}}
\newcommand{\chaop}{{\tilde{\chi}^+_1}}
\newcommand{\chaom}{{\tilde{\chi}^-_1}}
\newcommand{\Wpm}{W^\pm}
\newcommand{\chat}{{\tilde{\chi}^\pm_2}}
\newcommand{\smu}{{\tilde{\mu}}}
\newcommand{\smur}{\tilde{\mu}_R}
\newcommand{\smul}{\tilde{\mu}_L}
\newcommand{\sel}{{\tilde{e}}}
\newcommand{\selr}{\tilde{e}_R}
\newcommand{\sell}{\tilde{e}_L}
\newcommand{\smurl}{\tilde{\mu}_{R,L}}

\newcommand{\casea}{\texttt{IA}}
\newcommand{\caseb}{\texttt{IB}}
\newcommand{\casec}{\texttt{II}}

\newcommand{\caseasix}{\texttt{IA-6}}

%
% Greek
%
\newcommand{\es}{{\epsilon}}
\newcommand{\sg}{{\sigma}}
\newcommand{\dt}{{\delta}}
\newcommand{\kp}{{\kappa}}
\newcommand{\lm}{{\lambda}}
\newcommand{\Lm}{{\Lambda}}
\newcommand{\gm}{{\gamma}}
\newcommand{\mn}{{\mu\nu}}
\newcommand{\Gm}{{\Gamma}}
\newcommand{\tho}{{\theta_1}}
\newcommand{\tht}{{\theta_2}}
\newcommand{\lmo}{{\lambda_1}}
\newcommand{\lmt}{{\lambda_2}}
%
% LaTeX equations
%
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bit}{\begin{itemize}}
\newcommand{\eit}{\end{itemize}}

\newcommand{\nbea}{\begin{eqnarray*}}
\newcommand{\neea}{\end{eqnarray*}}
\newcommand{\nbeq}{\begin{equation*}}
\newcommand{\neeq}{\end{equation*}}

\newcommand{\no}{{\nonumber}}
\newcommand{\td}[1]{{\widetilde{#1}}}
\newcommand{\sqt}{{\sqrt{2}}}
%
\newcommand{\me}{{\rlap/\!E}}
\newcommand{\met}{{\rlap/\!E_T}}
\newcommand{\rdmu}{{\partial^\mu}}
\newcommand{\gmm}{{\gamma^\mu}}
\newcommand{\gmb}{{\gamma^\beta}}
\newcommand{\gma}{{\gamma^\alpha}}
\newcommand{\gmn}{{\gamma^\nu}}
\newcommand{\gmf}{{\gamma^5}}
%
% Roman expressions
%
\newcommand{\br}{{\rm Br}}
\newcommand{\sign}{{\rm sign}}
\newcommand{\Lg}{{\mathcal{L}}}
\newcommand{\M}{{\mathcal{M}}}
\newcommand{\tr}{{\rm Tr}}

\newcommand{\msq}{{\overline{|\mathcal{M}|^2}}}

%
% kinematic variables
%
%\newcommand{\mc}{m^{\rm cusp}}
%\newcommand{\mmax}{m^{\rm max}}
%\newcommand{\mmin}{m^{\rm min}}
%\newcommand{\mll}{m_{\ell\ell}}
%\newcommand{\mllc}{m^{\rm cusp}_{\ell\ell}}
%\newcommand{\mllmax}{m^{\rm max}_{\ell\ell}}
%\newcommand{\mllmin}{m^{\rm min}_{\ell\ell}}
%\newcommand{\elmax} {E_\ell^{\rm max}}
%\newcommand{\elmin} {E_\ell^{\rm min}}
\newcommand{\mxx}{m_{\chi\chi}}
\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%\newcommand{\mpt}{\rlap/p_T}

%%%song
\newcommand{\cosmax}{|\cos\Theta|_{\rm max} }
\newcommand{\maa}{m_{aa}}
\newcommand{\maac}{m^{\rm cusp}_{aa}}
\newcommand{\maamax}{m^{\rm max}_{aa}}
\newcommand{\maamin}{m^{\rm min}_{aa}}
\newcommand{\eamax} {E_a^{\rm max}}
\newcommand{\eamin} {E_a^{\rm min}}
\newcommand{\eaamax} {E_{aa}^{\rm max}}
\newcommand{\eaacusp} {E_{aa}^{\rm cusp}}
\newcommand{\eaamin} {E_{aa}^{\rm min}}
\newcommand{\exxmax} {E_{\neuo \neuo}^{\rm max}}
\newcommand{\exxcusp} {E_{\neuo \neuo}^{\rm cusp}}
\newcommand{\exxmin} {E_{\neuo \neuo}^{\rm min}}
%\newcommand{\mxx}{m_{XX}}
%\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\erec}{E_{\rm rec}}
%\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
%\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
%\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%%%song

\newcommand{\mc}{m^{\rm cusp}}
\newcommand{\mmax}{m^{\rm max}}
\newcommand{\mmin}{m^{\rm min}}
\newcommand{\mll}{m_{\mu\mu}}
\newcommand{\mllc}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\mllmax}{m^{\rm max}_{\mu\mu}}
\newcommand{\mllmin}{m^{\rm min}_{\mu\mu}}
\newcommand{\mllcusp}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\elmax} {E_\mu^{\rm max}}
\newcommand{\elmin} {E_\mu^{\rm min}}
\newcommand{\elmaxw} {E_W^{\rm max}}
\newcommand{\elminw} {E_W^{\rm min}}
\newcommand{\R} {{\cal R}}

\newcommand{\ewmax} {E_W^{\rm max}}
\newcommand{\ewmin} {E_W^{\rm min}}
\newcommand{\mwrec}{m_{WW}}
\newcommand{\mwrecmin}{m_{WW}^{\rm min}}
\newcommand{\mwrecc}{m_{WW}^{\rm cusp}}
\newcommand{\mwrecmax}{m_{WW}^{\rm max}}

\newcommand{\mpt}{{\rlap/p}_T}

%%%%%% END My stuffs - Stef

\newcommand{\dunno}{$ {}^{\mbox {--}}\backslash(^{\rm o}{}\underline{\hspace{0.2cm}}{\rm o})/^{\mbox {--}}$}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\tor}{tor}





\begin{document}

\title{Apostol's Analytic Number Theory}
\bigskip
\author{Stefanus$^1$\\
$^1$ Samsung Semiconductor Inc\\ San Jose, CA 95134 USA\\
}
%
\date{\today}
%
\begin{abstract}
Just for fun :)

\end{abstract}
%
\maketitle

\renewcommand{\theequation}{A.\arabic{equation}}  % redefine the command that creates the equation no.
\setcounter{equation}{0}  % reset counter 

\bigskip
\underline{\textbf{\textit{Chapter 1}}}
\bigskip

{\bf Problem 1.11}. Prove that $n^4 + 4$ is composite if $n > 1$.

This problem can be easily solved by completing the square
%
\nbea
n^4 + 4 & = & (n^2)^2 + 2^2 \\
& = & (n^2 + 2)^2 - (2n)^2 \\
& = & (n^2 + 2 - 2n)(n^2 + 2 + 2n)
\neea
%
But, suppose you're not aware of completing the square trick, here's what you can do. Since $4$ is even if $n$ is also even then $n^4 + 4$ is guaranteed to be composite. What if $n$ is odd? Let's see
%
\nbea
\begin{array}{r c r c r c r}
3^4 + 4 & = & 8\underline{1} &+& 4 &=& 8\underline{5} \\
5^4 + 4 & = & 62\underline{5} &+& 4 &=& 62\underline{9} \\
7^4 + 4 & = & 240\underline{1} &+& 4 &=& 240\underline{5} \\
9^4 + 4 & = & 656\underline{1} &+& 4 &=& 656\underline{5} \\
11^4 + 4 & = & 1464\underline{1} &+& 4 &=& 1464\underline{5} \\
13^4 + 4 & = & 2856\underline{1} &+& 4 &=& 2856\underline{5} \\
15^4 + 4 & = & 5062\underline{5} &+& 4 &=& 5062\underline{9}
\end{array}
\neea
%
so we see that if $n \not\equiv 0 \pmod{5}$ then $n^4 \equiv 1 \pmod{10}$ and therefore $n^4 + 4 \equiv 0 \pmod{5}$ and if $n \equiv 0 \pmod{5}$ then $n^4 + 4 \equiv -1 \pmod{5}$, does this always apply? well, let's do everything in mod 5 then
%
\nbea
\begin{array}{r c l c r c l}
n & \equiv & 1\pmod{5} & \to & 1^4 + 4 & \equiv & 0 \pmod {5} \\
n & \equiv & 2\pmod{5} & \to & 2^4 + 4 & \equiv & 0 \pmod {5} \\
n & \equiv & 3\pmod{5} & \to & 3^4 + 4 & \equiv & 0 \pmod {5} \\
n & \equiv & 4\pmod{5} & \to & 4^4 + 4 & \equiv & 0 \pmod {5} \\
n & \equiv & 5\pmod{5} & \to & 5^4 + 4 & \equiv & 4 \pmod {5}
\end{array}
\neea
%
So it is true, for $n \not\equiv 0 \pmod{5}$, $n^4 + 4 \equiv 0 \pmod{5}$ and thus $5|n^4 + 4$ and $n^4 + 4$ is composite, except for $n=1$ of course where $1^4 + 4 = 5$ which is prime.

Our task is to now see if we can prove that $n^4 + 4 \equiv 4 \pmod{5}$ is composite. We know that if $n$ is even then we are done, our task now is to see what happens if $n$ is odd and a multiple of $5$, \ie to check whether $(5(2k+1))^4 + 4$ is composite.

A strategy would be to show explicitly that we can factorize $(5(2k+1))^4 + 4 = (5a + 2)(5b + 2)$. The way I did it was to try out different $k$'s and see if there's a pattern to $a$ and $b$
%
\nbea
\begin{array}{r c l c r c l r c l c r c l r c l}
k &=& 0 & ~\to~ & a &=& 3 &,~b&=&7 &~~~& \frac{a}{2k+1} &=& \underline{0}3 &,~b-a &=& 4  + 8\cdot \underline{0}\\
k &=& 1 & ~\to~ & a &=& 39 &,~b&=&51 &~~~& \frac{a}{2k+1} &=& \underline{1}3 &,~b-a &=& 4 + 8\cdot \underline{1} \\
k &=& 2 & ~\to~ & a &=& 115 &,~b&=&135 &~~~& \frac{a}{2k+1} &=& \underline{2}3 &,~b-a &=& 4  + 8\cdot \underline{2}\\
k &=& 3 & ~\to~ & a &=& 231 &,~b&=&259 &~~~& \frac{a}{2k+1} &=& \underline{3}3 &,~b-a &=& 4  + 8\cdot \underline{3}\\
k &=& 4 & ~\to~ & a &=& 387 &,~b&=&423 &~~~& \frac{a}{2k+1} &=& \underline{4}3 &,~b-a &=& 4  + 8\cdot \underline{4}\\
k &=& 5 & ~\to~ & a &=& 583 &,~b&=&627 &~~~& \frac{a}{2k+1} &=& \underline{5}3 &,~b-a &=& 4  + 8\cdot \underline{5}\\
k &=& 6 & ~\to~ & a &=& 819 &,~b&=&871 &~~~& \frac{a}{2k+1} &=& \underline{6}3 &,~b-a &=& 4  + 8\cdot \underline{6}\\
k &=& 7 & ~\to~ & a &=& 1095 &,~b&=&1155 &~~~& \frac{a}{2k+1} &=& \underline{7}3 &,~b-a &=& 4  + 8\cdot \underline{7}
\end{array}
\neea
%
so it seems like $a = (2k+1)(10k+3) = 20k^2+16k+3$ and $b = a + 4 + 8k= 20k^2+24k+7$ and indeed if we expand
%
\nbea
(5a + 2)(5b + 2) & = & (5(20k^2+16k+3) + 2)(5(20k^2+24k+7) + 2) \\
& = & 10000k^4+20000k^3+15000k^2+5000k+625 + 4 \\
& = & (5(2k+1))^4 + 4
\neea
%
so indeed $(5(2k+1))^4 + 4$ can be factorized into $(5(20k^2+16k+3) + 2)(5(20k^2+24k+7) + 2)$ therefore they must be composite.

So in short, if $n \not\equiv 0 \pmod{5}$ then $5|n^4 + 4$ and if $5|n$ then $(5(2k+1))^4 + 4 = (5(20k^2+16k+3) + 2)(5(20k^2+24k+7) + 2)$ and therefore $n^4 + 4$ is composite for $n>1$.

{\bf Problem 1.15}. Prove that every $n \ge 12$ is the sum of two composite numbers.

Here I assume the composite numbers are positive otherwise it is just a restatement of Bezout's lemma. Although this question looks tough initially it's actually very simple, for any even numbers $\ge 12$ we have
%
\nbea
2(6 + n) & = & 4 + 2(4+n)
\neea
%
with $n \ge 0$ and for any odd number $\ge 13$ we have
%
\nbea
2(6 + n) + 1 & = & 9 + 2(2 + n)
\neea
%
again with $n \ge 0$ and the reason we start with 12 is because between 1 and 12 only $8=4+4$ and $10=4+6$ are sums of composite numbers but for 12 and above, every number is a sum of composite numbers.

{\bf Problem 1.16}. Prove that if $2^n - 1$ is prime then $n$ is prime

The trick we need to know here is that
%
\nbea
x^n - 1 & = & (x - 1)(x^{n-1} + x^{n-2} + \dots + 1)
\neea
%
Thus if $n$ is not prime we must have $n = ab$
%
\nbea
2^n - 1 & = & 2^{ab} - 1 = (2^a)^b - 1 \\
\to (2^a)^b - 1 & = & (2^a - 1)((2^a)^{b-1} + (2^a)^{b-2} + \dots + 1)
\neea
%
and thus $2^n - 1$ is not prime, we can immediately generalize this to if $a^m - b^n$ is prime with $a,b > 1$ then $\gcd(m,n) = 1$ because otherwise
%
\nbea
a^m - b^n & = & a^{m'd} - b^{n'd} = (a^{m'})^d - (b^{n'})^d \\
& = & \left (a^{m'} - b^{n'} \right ) \left ((a^{m'})^{d-1} + (a^{m'})^{d-2} (b^{n'})+ \dots + (a^{m'})(b^{n'})^{d-2} + (b^{n'})^{d-1} \right )
\neea
%

{\bf Problem 1.17}. Prove that if $2^n + 1$ is prime, then $n$ is a power of 2.

The key point we need to know here is
%
\nbea
x^m + 1 & = & (x^h + 1)(x^{m-h} - x^{m-h-h} + x^{m-h-h-h} - \ldots + 1)
\neea
%
since the signs alternate from plus to minus on the RHS, the above factorization can only occur if $h|m$ and that $m/h$ is {\bf odd}. Another piece of info we need is that $(x^h-1)\nmid(x^m+1)$ for any $h$ due to the same reason and so we need not care about nor consider $x^h-1$.

Now say $n$ in the $2^n+1$ is even $\to n=2w \to 2^{2w} + 1$, now if $w$ is odd then $2^{2w} + 1$ is divisible by $2^2 + 1$, if $w$ is even we can repeat the process $w = 2t \to 2^{4t} + 1$ and again, if $t$ is odd then $2^{4t} + 1$ is divisible by $2^4 + 1$ but if $t$ is even then we again repeat the process. So the only way it is not divisible by $2^z+1$ is that the remaining factors are all even and it only happens when $n$ is a power of 2.

If $n$ is odd and composite then all factors of $n$ are odd and therefore $2^n+1$ is divisible by $2^u+1$ where $u|n$, the only case left is when $n$ is prime but in this case $2^n+1$ is immediately divisible by $2^1 + 1$ which is kind of a cool fact actually that any $2^n+1$ where $n$ is prime is divisible by 3 :)

{\bf Problem 1.18}. If $m\neq n$ compute $\gcd\left( a^{2m}+1, a^{2n}+1\right)$ in terms of $a$. [{\it Hint:} Let $A_n = a^{2n}+1$ and show that $A_n|(A_m-2)$ if $m>n$.]

Without loss of generality let's assume that $m > n$. If $d = \gcd(a^{2n}+1, a^{2m}+1)$ then $d|(a^{2m}+1) - (a^{2n}+1) \to d|a^{2n}(a^{2(m-n)} - 1)$, if $d|a^{2n}$ then since $d|(a^{2n}+1)$ this means that $d|(a^{2n}+1 - a^{2n}) \to d|1$ which is not that interesting.

The interesting part is when $d|(a^{2(m-n)} - 1)$ and since $m > n \to m = nq + r$, in this case 
%
\nbea
d &|& ((a^{2(nq+r-n)} - 1) + (a^{2n} + 1)) \\
d &|& (a^{2(n(q-1)+r)} + a^{2n}) \\
d &|& a^{2n}(a^{2(n(q-2)+r)} + 1)
\neea
%
just like before, if $d|a^{2n}$ then $d|1$, so we ignore this case, the other case is $d | (a^{2(n(q-2)+r)} + 1)$. Now, if $q-2 > 2$ we can repeat the process but this time by taking the difference
%
\nbea
d &|& ((a^{2(n(q-2)+r)} + 1) - (a^{2n} + 1)) \\
d &|& (a^{2(n(q-2)+r)} - a^{2n}) \\
d &|& a^{2n}(a^{2(n(q-3)+r)} - 1)
\neea
%
again, we can repeat the process but this time by taking the sum just like before, once we reach $n(q-q) + r = r$ (or if $q=1$ to begin with we will reach this step immediately) since $0 \le r < n$ we will now express $n = rq' + r'$ (depending on whether $q$ was even or odd we might have plus or minus in front of the constant 1 for simplicity we will choose plus)
%
\nbea
d &|& ((a^{2n} + 1) - (a^{2r} + 1)) \\
d &|& ((a^{2(rq'+r')} + 1) - (a^{2r} + 1)) \\
d &|& (a^{2(rq'+r')} - a^{2r}) \\
d &|& a^{2r'}(a^{2(r(q'-1)+r')} - 1)
\neea
%
and the process continues with the same exact pattern as Euclid's algorithm for finding the gcd between two numbers and that's what we will find, the $\gcd(m,n) = g$, \ie we will eventually get $d|(a^{2g} \pm 1)$ we can of course continue one step further to get $d|0$ (a tautology) or $d|2$ but this depends on a few things that we'll discuss later.

The next piece of information we need is the following
%
\nbea
a^{2s} - 1 & = & (a^{2r} + 1)(a^{2s-2r} - a^{2s-2r-2r} + a^{2s - 2r - 2r - 2r} -  \ldots - 1)
\neea
%
so $(a^{2r} + 1)|(a^{2s} - 1)$ if $s = rk$ where $k$ is {\it even} because we want the constant $1$ in the second bracket of the RHS to have a minus sign and the pattern of the second bracket is $+-+-+-+-\ldots$~, next,
%
\nbea
a^{2s} + 1 & = & (a^{2r} + 1)(a^{2s-2r} - a^{2s-2r-2r} + a^{2s - 2r - 2r - 2r} -  \ldots + 1)
\neea
%
by the same token $(a^{2r} + 1)|(a^{2s} + 1)$ only if $s = rk$ where $k$ is {\it odd} and last one $(a^{2r} - 1)\nmid(a^{2s} + 1)$ this is because the second bracket of the RHS must all have positive sign but the $-1$ requires a minus sign. And of course we know about
%
\nbea
a^{2s} - 1 & = & (a^{2r} - 1)(a^{2s-2r} + a^{2s-2r-2r} + a^{2s - 2r - 2r - 2r} +  \ldots + 1)
\neea
%
as long as $r|s$.

Going back to our case $d|(a^{2g}\pm1)$, first thing to note is that this means $d \le a^{2g}\pm1$. Next, let's tackle it case by case, first case, $d|(a^{2g}+1)$, we know that $d$ divides both $a^{2m}+1$ and $a^{2n}+1$ and we also know that since $m = gk_m$ and $n = gk_n$ (note that $g = \gcd(m,n)$) if $k_m$ and $k_n$ are both odd then since $d \le a^{2g} + 1$ and $(a^{2g}+1)$ divides both this means that $a^{2m}+1$ and $a^{2n}+1$, $d = a^{2g}+1$.

But if one of or both of $k_m$ or $k_n$ are even then we have something different :) Let's just assume that $k_n$ is even (this will not change the conclusion and only simplify things), now let $h = \gcd(a^{2g}+1, a^{2n}+1)$ where $n=gk_n$, this also means
%
\nbea
h &|& (a^{2n}+1) - (a^{2g}+1) \\
\to h &|& (a^{2g(k_n-1)}-1) \\
h &|& (a^{2g(k_n-2)}+1) \\
h &|& (a^{2g(k_n-3)}-1) \\
&\vdots& \\
h &|& (a^{2g(k_n-k_n)}+1) \\
\to h &|& 2
\neea
%
the last constant $1$ has a plus sign in front of it because $k_n$ is even, this means that since $d|a^{2g}+1$ and $d|a^{2n}+1$, $d \le h$ but since $h \le 2 \to d \le 2$, therefore if $a$ is odd $a^{w} + 1$ is even and $d=2$ (because $d$ is the {\it greatest} common divisor) but if $a$ is even then $a^w+1$ is odd and $d=1$.

If $d|a^{2g}-1$ then we know that from the above discussion that $(a^{2g}-1)\nmid (a^{2m} + 1), ~(a^{2g}-1)\nmid (a^{2n} + 1)$, however since $g|m,~ g|n$ the following is true $(a^{2g}-1)| (a^{2m} - 1), (a^{2g}-1)| (a^{2n} - 1)$. But this means that any common divisor $x$ between $a^{2g}-1$ and $a^{2m,n}+1$ must also divide $a^{2m,n}-1$ that is
%
\nbea
x &|& (a^{2m,n}+1) - (a^{2m,n}-1) \\
x &|& 2
\neea
%
which means that $d \le x \to d \le 2$, so again depending on whether $a$ is even or odd we get $d=1$ or $d=2$ respectively.

{\bf Problem 1.19}. The {\it Fibonacci sequence} $1,1,2,3,5,8,13,21,34,\dots$ is defined by the recursion formula $a_{n+1} = a_n + a_{n-1}$, with $a_1 = a_2 = 1$. Prove that $(a_n,a_{n+1})=1$ for each $n$.

The suitable action is to induce :) We know that $(a_1,a_2) = (1,1) = 1$, that's the base case, now say it is true that up to $n = m$, $(a_{m-1},a_m)=1$, now assume the opposite for say $d = (a_m,a_{m+1}) > 1$ then
%
\nbea
a_{m+1} & = & a_n + a_{m-1} \\
(a_{m+1} - a_n) & = &  a_{m-1} \\
d(a'_{m+1} - a'_n) & = &  a_{m-1} \\
d &|& a_{m-1}
\neea
%
thus $(a_{m-1},a_m) = d > 1$ which is a contradiction, therefore $d=1$

{\bf Problem 1.24}. Prove the following multiplicative property of the gcd:
%
\nbea
(ah,bk) = (a,b)(h,k)\left ( \frac{a}{(a,b)},\frac{k}{(h,k)}\right )\left ( \frac{b}{(a,b)},\frac{h}{(h,k)}\right )
\neea
%
In particular this shows that $(ah,bk) = (a,k)(b,h)$ whenever $(a,b)=(h,k)=1$.

Let's solve this the way a physicist might have done it. First, the whole situation is symmetrical under $a \leftrightarrow h$ and $b \leftrightarrow k$ and $ah \leftrightarrow bk$ therefore a first guess would be
%
\nbea
(ah,bk) & = & (a,b)(h,k)(a,k)(b,h)
\neea
%
but this immediately fails when $a=p,h=p,b=p,k=1$
%
\nbea
(p\cdot p, p\cdot 1) & = & (p,p)(p,1)(p,1)(p,p) \\
& = & p^2
\neea
%
so this means that we have to remove some overcountings, \ie we have to divide the whole thing with something like this
%
\nbea
(ah,bk) & = & (a,b)(h,k)\frac{(a,k)(b,h)}{(a,b)(h,k)}
\neea
%
we divide by both $(a,b)$ and $(h,k)$ because the $ab \leftrightarrow hk$ symmetry, but again this is overdoing it, for example for $a=pp,h=1,b=p,k=p$
%
\nbea
(pp\cdot1, p\cdot p) & = & (pp,p)(1,p)\frac{(pp,p)(1,p)}{(pp,p)(1,p)} \\
& = & (p)(1)\frac{(p)(1)}{(p)(1)} \\
& = & p
\neea
%
the next choice that makes sense would then be to absorb those denominators into the numerators and to still respect the symmetry we will have
%
\nbea
(ah,bk) = (a,b)(h,k)\left ( \frac{a}{(a,b)},\frac{k}{(h,k)}\right )\left ( \frac{b}{(a,b)},\frac{h}{(h,k)}\right )
\neea
%
and that turns out to be correct :) Well for consistency we should do the nested test
%
\nbea
(a(hh'),b) & = & ((ah)h',b) \\
(a,b)(hh',1) \left ( \frac{a}{(a,b)},\frac{1}{(hh',1)}\right )\left ( \frac{b}{(a,b)},\frac{hh'}{(hh',1)}\right ) & = & (ah,b)(h',1)\left ( \frac{ah}{(ah,b)},\frac{1}{(h',1)}\right )\left ( \frac{b}{(ah,b)},\frac{h'}{(h',1)}\right ) \\
(a,b) \left ( \frac{b}{(a,b)},hh'\right ) & = & (ah,b)\left ( \frac{b}{(ah,b)},h'\right )
\neea
%
we now reapply the same formula to both LHS and RHS to see if this is consistent, first the LHS
%
\nbea
(a,b) \left ( \frac{b}{(a,b)},hh'\right ) & = & (a,b) \left\{\left ( \frac{b}{(a,b)},h\right )  \left ( \frac{b}{(a,b)\left(\frac{b}{(a,b)}, h\right)},h'\right ) \right\}
\neea
%
and now the RHS
%
\nbea
(ah,b)\left ( \frac{b}{(ah,b)},h'\right ) & = & \left \{ (a,b)\left(\frac{b}{(a,b)},h\right) \right \} \left ( \frac{b}{(a,b)\left(h,\frac{b}{(a,b)}\right)},h'\right ) 
\neea
%
and they are apparently the same :)

There are two reasons I chose to do the above problem, one, it's fun to apply what I learned during my physics PhD on a math problem and two we will need this result to solve Problem 1.28.

{\bf Problem 1.28}. If $a>1$ then $(a^m-1,a^n-1)=a^{(m,n)}-1$.

I have actually solved this problem when I was doing Stein's elementary number theory book, it's Problem 2.25 of that book but here I'll do it differently :) 

{\bf Proposition 1.28.1}, $\gcd(x^n + x^{n-1} + \ldots + x + 1,x-1) = \gcd(x-1,n+1)$

{\it Proof}. Say there's a common divisor $d$ of $\sum_{i=1}^{n+1} x^{i-1} = x^n + x^{n-1} + \ldots + x + 1 $ and $x-1$, since it divides $x-1$ it also divides
%
\nbea
d &|& x - 1 \\
d &|& (x-1)(x+1) = x^2 - 1 \\
d &|& (x-1)(x^2 + x + 1) = x^3 - 1 \\
& \vdots & \\
d &|& (x-1)(x^{n-1} + x^{n-2} + \ldots + 1) = x^n - 1
\neea
%
if we sum all of them, $d$ will still be a divisor of the sum
%
\nbea
\left (x^n + x^{n-1} + \ldots + 1\right ) - \left \{ (x^n-1) + (x^{n-1}-1) + \ldots + (x-1)\right\} & = & n + 1
\neea
%
therefore $d|(n+1)$ since this is true for any common divisor $d$, it is also true for the gcd so if $g=\gcd\left(\sum_{i=1}^{n+1} x^{i-1}, x-1\right)$ then $g|(n+1)$ but this still doesn't guarantee that $g=\gcd(x-1,n+1)$ but we can turn the above argument on its head, say $h = \gcd(x-1,n+1)$, since $h$ divides $x-1$, just like before it must also divide $x^2-1,x^3-1,\dots,x^n+1$, if we sum all of these and also $n+1$ we get
%
\nbea
\left \{ (x^n-1) + (x^{n-1}-1) + \ldots + (x-1)\right\} + (n+1) & = & x^n + x^{n-1} + \ldots + 1
\neea
%
and so $h$ must also divide $x^n + x^{n-1} + \ldots + 1$ and that is that :) well almost, just one more little detail, what this says is that $h|\sum_{i=1}^{n+1} x^{i-1}$ and $g|(n+1)$ but it doesn't say $h=g$? say they are different, $h\neq g$, then one of them must be smaller, say $h > g$, now from the above discussion we know that $h$ is also a common divisor of $(\sum_{i=1}^{n+1} x^{i-1}, x-1)$ but if $h>g$ then $g$ is not the {\bf greatest} common divisor and we can choose $h$ to be the $\gcd(\sum_{i=1}^{n+1} x^{i-1}, x-1)$, the other way is also true, if $g > h$ then since $g$ is a common divisor of $(x-1,n+1)$ then we can choose $g$ as the gcd instead of $h$ and therefore $\gcd(\sum_{i=1}^{n+1} x^{i-1}, x-1)=\gcd(x-1,n+1)$.

One important thing to note here is that {\bf the gcd depends on the value of} $x$, this is somewhat interesting.

There's another way to see why the above is true, note that $\sum_{i=1}^{n+1} x^{i-1}$ is just a geometric series
%
\nbea
\sum_{i=1}^{n+1} x^{i-1} = x^n + x^{n-1} + \dots + x + 1 = \frac{x^{n+1}-1}{x-1}
\neea
%
now if we set $x = (n+1) + 1$, from the numerator we get
%
\nbea
\left\{(n+1)+1\right\}^{n+1} - 1 & = & {n+1\choose 0}(n+1)^{n+1} + {n+1\choose 1}(n+1)^{n} + \ldots + {n+1\choose n}(n+1) + \bcancel{1} - \bcancel{1}
\neea
%
if we divide the above with $x-1 = (n+1) + 1 - 1 = (n+1)$ we get
%
\nbea
\frac{x^{n+1}-1}{x-1} & = & {n+1\choose 0}(n+1)^{n} + {n+1\choose 1}(n+1)^{n-1} + \ldots + {n+1\choose n} \\
& = & {n+1\choose 0}(n+1)^{n} + {n+1\choose 1}(n+1)^{n-1} + \ldots + (n+1) \\
& = & (n+1) \left \{ {n+1\choose 0}(n+1)^{n-1} + {n+1\choose 1}(n+1)^{n-2} + \ldots + 1 \right \} \\
\to & = & (x-1) \left \{ {n+1\choose 0}(x-1)^{n-1} + {n+1\choose 1}(x-1)^{n-2} + \ldots + 1 \right \}
\neea
%
so the key here is that although the last binomial coefficient ${n+1\choose n}$ is independent of what value we choose for $x$, if we judiciously choose $x-1$ we can pull out a factor of $x-1$ out of the terms like above, on the other hand, if $x-1$ has no common factor with ${n+1\choose n}=(n+1)$ then we cannot pull a common factor out and that's the key.

{\bf Proposition 1.28.2}, $\gcd(x^{a}, \sum_{i=0}^{N}x^{b_i})=1$ where $a \ge 0, b_0 = 0, ~b_{i\neq 0} \neq 0$

{\it Proof}. Say we have a {\it non-composite} common divisor, $d$, of $x^a$ and $\sum_{i=0}^{N}x^{b_i}$ (non-composite so we cover primes and 1), since $d$ is non-composite and $d|x^a$ we have $d|x$ and
%
\nbea
\sum_{i=0}^{N}x^{b_i} & = & 1 + d\sum_{i=1}^{N}d^{b_i-1} x^{b_i}
\neea
%
therefore since $d|\sum_{i=0}^{N}x^{b_i} \to d|1$, therefore since {\it every} non-composite divisor is 1 the $\gcd(x^{a}, \sum_{i=0}^{N}x^{b_i})=1$ (note that any other divisor is a (possibly duplicate) product of the non-composite divisors)

{\bf Proposition 1.28.3}, $\gcd(x^n + x^{n-1} + \ldots + 1,x^m + x^{m-1} + \ldots + 1) = \sum_{i=0}^{\gcd(n+1,m+1)-1}x^{i}$

{\it Proof}. This one is actually quite interesting, the sequence $x^n + x^{n-1} + \ldots + x + 1$ can be thought of just a number $\to n+1$, let's see a concrete example, say we have
%
\nbea
x^{11} + x^{10}+x^9+x^8+x^7+x^6+x^5 + x^4 + x^3 + x^2 + x + 1
\neea
%
and we want to know what we get if we divide it by $x^2+x+1$, in this we can easily factorize the above
%
\nbea
(x^2 + x + 1)(x^9 + x^6 + x^3 + 1)
\neea
%
and there you go, we can immediately see the pattern, if $(n+1)|(m+1)$ then
%
\nbea
x^m + x^{m-1} + \ldots + x + 1 & = &(x^n + x^{n-1} + \ldots + x + 1) (x^{(n+1)\cdot(s - 1)} + x^{(n+1)\cdot(s - 2)} + \ldots + x^{(n+1)} + 1) \\
\to \sum_{i=0}^{m} x^i & = & \left ( \sum_{j=0}^{n} x^j \right ) \left ( \sum_{k=0}^{s-1} x^{(n+1)\cdot k} \right )
\neea
%
where $s = (m+1)/(n+1)$ but this also means something else, say we have $\sum_{i=0}^{n}x^i$, we can always produce a higher powered sequence by multiplying it with another sequence according to the rules above, \ie
%
\nbea
\left ( \sum_{j=0}^{n} x^j \right ) \left ( \sum_{k=0}^{w} x^{(n+1)\cdot k} \right ) & = & \sum_{i=0}^{((n+1)\cdot(w+1)) - 1} x^i
\neea
%
since what matters here is whether $(n+1)|(m+1)$, let's come up with a better notation to eliminate this $\pm1$ offset, say $f_{n} = \sum_{i=0}^{n-1}x^i$ and $g_{w} = \sum_{i=0}^{w-1} x^{(n+1)\cdot i}$ such that
%
\nbea
f_n \cdot g_w & = & f_{n\cdot w}
\neea
%
in other words what we care most here is the number of terms in the sequence and {\bf not} the highest power of the sequence. With this notation we can treat these sequences just like natural numbers, the most important thing we want to apply to them is Bezout's lemma that says for any number $a$ and $b$ there are $c$ and $d$ such that
%
\nbea
ac + bd & = & \gcd(a,b)
\neea
%
we are now ready to utilize Bezout, say we have two sequences $f_m$ and $f_n$ where $\gcd(m,n)=1$ and say we have a {\it non-composite} common divisor, $d \to d|f_m,~d|f_n$, of those two (non-composite because I want to include primes and 1, recall that 1 is not prime nor composite), this means that
%
\nbea
d &|& f_n\cdot g_y = f_{n\cdot y} \\
d &|& f_m\cdot g_z = f_{m\cdot z}
\neea
%
such that $ny - mz = 1$ which is guaranteed by Bezout (here we have assumed that $ny > mz$ but the conclusion still applies even if $mz > ny$), now let's take the difference
%
\nbea
f_{n\cdot y} - f_{m\cdot z} & = & (x^{ny-1} + x^{ny-2} + \ldots + x + 1) - (x^{mz-1} + x^{mz-2} + \ldots + x + 1) \\
& = & (x^{mz} + x^{mz-1} + \ldots + x + 1) - (x^{mz-1} + x^{mz-2} + \ldots + x + 1) \\
& = & x^{mz}
\neea
%
which in turn means
%
\nbea
d &|& f_{n\cdot y} - f_{m\cdot z} \\
\to d &|& x^{mz}
\neea
%
now since $d$ is non-composite $\to d|x$ but since $d|f_n$ this also means that $d|1$, since {\it every} non-composite common divisor of $f_n$ and $f_m$, $\gcd(f_n,f_m) = 1$ when $\gcd(m,n)=1$.

Now if $g = \gcd(m,n) > 1$ what we have from Bezout is $ny - mz = g$
%
\nbea
f_{n\cdot y} - f_{m\cdot z} & = & (x^{ny-1} + x^{ny-2} + \ldots + x + 1) - (x^{mz-1} + x^{mz-2} + \ldots + x + 1) \\
& = & (x^{mz+g-1} + x^{mz+g-2} + \ldots + x + 1) - (x^{mz-1} + x^{mz-2} + \ldots + x + 1) \\
& = & x^{mz+g-1} + x^{mz+g-2} + \ldots + x^{mz} \\
& = & x^{mz}\left ( x^{g-1} + x^{g-2} + \ldots + 1 \right ) \\
f_{n\cdot y} - f_{m\cdot z} & = & x^{mz} \cdot f_g
\neea
%
Also note that
%
\nbea
f_{n} & = & f_g\cdot g_{n/g} \\
f_{m} & = & f_g\cdot g_{m/g}
\neea
%
this all means that since $g|f_n, ~g|f_m$
%
\nbea
g &|& \left(f_{n\cdot y} - f_{m\cdot z}\right) \\
g &|& \left(x^{mz} \cdot f_g\right)
\neea
%
Now $g=\gcd(f_n,f_m)$ and by definition gcd is divisible by all common divisors so in this case it is divisible by $f_g \to f_g|g$ and since $g | (x^{mz} \cdot f_g)$ and by Proposition 1.28.2 $\gcd(x^{mz}, f_g)=1$ this means that $g = hf_g$ where $h|x^{mz}$ and we now need to figure out what $h$ is.

Now note that $g|f_n \to h f_g| f_g\cdot g_{n/g} \to h | g_{n/g}$ but again by the proof Proposition 1.28.2 noting that $g_n = \sum_{i=0}^{N} x^{b_i}$, $\gcd(h,g_{n/g})=1 \to h=1$ and thus $g = f_g$.

Therefore, the final conclusion is $\gcd(x^n + x^{n-1} + \ldots + 1,x^m + x^{m-1} + \ldots + 1) = \sum_{i=0}^{\gcd(n+1,m+1)-1}x^{i}$

Now back to {\bf Problem 1.28}, first step is to utilize the result of Problem 1.24, let's denote $d = \gcd(m,n)$ and utilizing a similar notation to that of Proposition 1.28.3
%
\nbea
(a^m-1,a^n-1) & = & ((a^d-1)f_{m/d},(a^d-1)f_{n/d}) \\
& = & (a^d-1,a^d-1)(f_{m/d},f_{n/d}) \times \\
&& \left ( \frac{a^d-1}{(a^d-1,a^d-1)},\frac{f_{n/d}}{(f_{m/d},f_{n/d})}\right )\left ( \frac{a^d-1}{(a^d-1,a^d-1)},\frac{f_{m/d}}{(f_{m/d},f_{n/d})}\right ) \\
& = & (a^d-1)(f_{m/d},f_{n/d}) \left ( 1, \frac{f_{n/d}}{(f_{m/d},f_{n/d})}\right )\left ( 1,\frac{f_{m/d}}{(f_{m/d},f_{n/d})}\right ) \\
& = & (a^d-1)(f_{m/d},f_{n/d})
\neea
%
where now $f_{m/d} = \left ( (a^d)^{m/d-1} + (a^d)^{m/d-2} + \ldots + a^d + 1 \right )$, by Proposition 1.28.3 $\gcd(f_{m/d},f_{n/d}) = \gcd(m/d,n/d)=1$ and we are done :) well of course if we have chosen $a,h,b,k$ differently we will not get the answer as easily, \eg 
%
\nbea
(a^m-1,a^n-1) & = & ((a^d-1)f_{m/d},f_{n/d}(a^d-1)) \\
& = & (a^d-1,f_{n/d})(f_{m/d},a^d-1) \times \\
&& \left ( \frac{a^d-1}{(a^d-1,f_{n/d})},\frac{a^d-1}{(f_{m/d},a^d-1)}\right )\left ( \frac{f_{n/d}}{(a^d-1,f_{n/d})},\frac{f_{m/d}}{(f_{m/d},a^d-1)}\right ) \\
& = & (a^d-1,n/d)(m/d,a^d-1) \left ( \frac{a^d-1}{(a^d-1,n/d)},\frac{a^d-1}{(m/d,a^d-1)}\right ) \\
& = & (a^d-1)
\neea
%
from line 2 to 3 we have used the fact that since $(f_{m/d},f_{n/d}) = 1$ therefore $(f_{m/d}/t,f_{n/d}/s) = 1$, going into the last line might need a bit more explanation, let's denote
%
\nbea
(a^d-1,n/d) & = & c_n \\
(a^d-1,m/d) & = & c_m
\neea
%
now since $\gcd(m/d,n/d)=1$ we have
%
\nbea
a^d - 1 & = & c_a c_m c_n
\neea
%
therefore
%
\nbea
(a^d-1,n/d)(m/d,a^d-1) \left ( \frac{a^d-1}{(a^d-1,n/d)},\frac{a^d-1}{(m/d,a^d-1)}\right ) & = & c_n c_m (c_a c_m, c_a c_n)\\
& = & c_n c_m c_a \\
& = & a^d - 1
\neea
%
so depending on how stupidly you make your choices, you might have to suffer a bit more :)

\bigskip
\underline{\textbf{\textit{Chapter 2}}}
\bigskip

{\bf Problem 2.1} Find all integers $n$ such that
%
\nbea
\begin{array}{l r c l c l r c l c l r c l}
{\rm(a)} & \varphi(n) & = & n/2 & ~~~~~~~~~ & {\rm(b)} & \varphi(n) & = & \varphi(2n) & ~~~~~~~~~ & {\rm(c)} & \varphi(n) & = & 12
\end{array}
\neea
%

For (a), using the definition of $\varphi(n)$, $\varphi(n) = n \prod_{p|n} \left ( 1 - \frac{1}{p} \right )$
%
\nbea
\frac{\bcancel{n}}{2} & = & \bcancel{n} \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\frac{1}{2} & = & \frac{\prod_{p|n} \left ( p - 1 \right )}{\prod_{p|n} p} \\
\prod_{p|n} p & = & 2\prod_{p|n} \left ( p - 1 \right )
\neea
%
if $n$ is odd the LHS is odd while the RHS is even, so it can't be. If $n$ is even the LHS only has one factor of 2 while the RHS has many so it will only work if $n=2$.

For (b)
%
\nbea
\bcancel{n} \prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2\bcancel{n} \prod_{p|2n} \left ( 1 - \frac{1}{p} \right )
\neea
%
If $n$ is even then
%
\nbea
\prod_{p|2n} \left ( 1 - \frac{1}{p} \right ) & = & \prod_{p|n} \left ( 1 - \frac{1}{p} \right )
\neea
%
and so
%
\nbea
\prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2\prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\to 1 & = & 2
\neea
%
which is impossible, so $n$ has to be odd, in that case
%
\nbea
\prod_{p|2n} \left ( 1 - \frac{1}{p} \right ) & = & \left ( 1 - \frac{1}{2} \right ) \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
& = & \frac{1}{2} \prod_{p|n} \left ( 1 - \frac{1}{p} \right )
\neea
%
and therefore
%
\nbea
\prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2 \frac{1}{2} \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\to 1 & = & 1
\neea
%
and therefore $\varphi(n) = \varphi(2n)$ for all odd $n$.

For (c)
%
\nbea
\varphi(n) = 12 & = & 2 \cdot 2 \cdot 3 \\
& = & \prod_{p|n} p^{\alpha_p} - p^{\alpha_p-1} \\
\varphi\left (\prod_{p|n} p^{\alpha_p} \right ) & = & \prod_{p|n}p^{\alpha_p-1} (p - 1)
\neea
%
the only possible solution is $n=13$

{\bf Problem 2.2}. For each of the following statements either give a proof or exhibit a counter example.

(a) If $(m,n)=1$ then $(\varphi(m),\varphi(n)) = 1$

(b) If $n$ is composite, then $(n, \varphi(n)) > 1$

(c) If the same primes divide $m$ and $n$, then $n\varphi(m) = m\varphi(n)$

For (a) a counter example will be $(3,4) = 1$, while $\varphi(3) = 2, ~\varphi(4) = 2$

For (b) a counter example would be $n = 15$ which means that $\varphi(15) = 8$ and $(15,8) = 1$

For (c) I think what it means by ``the same primes divide $m$ and $n$'' is that $m = \prod p^{\alpha_p}$ and $n = \prod p^{\beta_p}$, so they both have the same primes but they might have different exponents for each prime, in this case $\prod_{p|n} = \prod_{p|m}$
%
\nbea
n\varphi(m) & = & n \left ( m \prod_{p|m} \left ( 1 - \frac{1}{p}\right ) \right ) \\
& = & m \left ( n \prod_{p|n} \left ( 1 - \frac{1}{p}\right ) \right ) \\
n\varphi(m) & = & m\varphi(n)
\neea
%

{\bf Problem 2.3}. Prove that
%
\nbea
\frac{n}{\varphi(n)} = \sum_{d|n} \frac{\mu^2(d)}{\varphi(d)}
\neea
%

Since $\mu(n)$ and $\varphi(n)$ are both multiplicative so is $\mu^2/\varphi$, in that case $g(n) = \sum_{d|n} \frac{\mu^2(d)}{\varphi(d)}$ is also multiplicative. To determine $g(n)$ we need only compute $g(p^\alpha)$ for prime powers
%
\nbea
g(p^\alpha) & = & \sum_{d|p^\alpha} \frac{\mu^2(d)}{\varphi(d)} \\
& = & \frac{\mu^2(1)}{\varphi(1)} + \frac{\mu^2(p)}{\varphi(p)} + \ldots + \frac{\mu^2(p^\alpha)}{\varphi(p^\alpha)} \\
& = & 1 + \frac{1}{p - 1} \\
& = & \frac{p}{p - 1} \\
& = & p^\alpha \cdot \frac{p}{p^\alpha(p - 1)} \\
\to \sum_{d|p^\alpha} \frac{\mu^2(d)}{\varphi(d)}& = & \frac{p^\alpha}{\varphi(p^\alpha)}
\neea
%

We can also prove it the other way around by assuming the LHS, to do this it is easiest to use the Mobius inversion formula
%
\nbea
\frac{n}{\varphi(n)} = \sum_{d|n} g(d)
\neea
%
and we want to find out what this $g(d)$ is, which is
%
\nbea
g(n) & = & \sum_{d|n} \frac{d}{\varphi(d)} \mu\left ( \frac{n}{d}\right )
\neea
%
The RHS is multiplicative so like above we just need to evaluate $g(p^\alpha)$ for prime powers
%
\nbea
g(p^\alpha) & = & \sum_{d|p^\alpha} \frac{d}{\varphi(d)} \mu\left ( \frac{p^\alpha}{d}\right ) \\
& = & \frac{p^{\alpha-1}}{\varphi(p^{\alpha-1})} \mu\left ( \frac{p^\alpha}{p^{\alpha-1}}\right ) + \frac{p^\alpha}{\varphi(p^\alpha)} \mu\left ( \frac{p^\alpha}{p^\alpha}\right ) \\
& = & -\frac{p^{\alpha-1}}{\varphi(p^{\alpha-1})} + \frac{p^\alpha}{\varphi(p^\alpha)} \\
& = & -\frac{p^\alpha}{\varphi(p^\alpha)}  + \frac{p^\alpha}{\varphi(p^\alpha)} \\
& = & 0
\neea
%
if $\alpha > 1$ and if $\alpha = 1$ we get
%
\nbea
g(p) & = & \sum_{d|p} \frac{d}{\varphi(d)} \mu\left ( \frac{p}{d}\right ) \\
& = & \frac{1}{\varphi(1)} \mu\left ( \frac{p}{1}\right ) + \frac{p}{\varphi(p)} \mu\left ( \frac{p}{p}\right ) \\
& = & -1 + \frac{p}{\varphi(p)} \\
& = & -1 + \frac{p}{p - 1} \\
& = & \frac{1}{p - 1} \\
g(p) & = & \frac{1}{\varphi(p)}
\neea
%
This means that $g(p^\alpha) = 1/\varphi(p^\alpha)$ is $\alpha = 1$ and $g(p^\alpha) = 0$ if $\alpha > 1$, in other words $g(p^\alpha) = \mu^2(p^\alpha)/\varphi(p^\alpha)$

{\bf Problem 2.4}. Prove that $\varphi(n) > n/6$ for all $n$ with at most $8$ distinct prime factors.

First, let's demystify this number $8$, the reason $8$ is involved is because if you multiply out $(p-1)/p$ for the first eight primes we get
%
\nbea
\frac{1}{2}\cdot\frac{2}{3}\cdot\frac{4}{5}\cdot\frac{6}{7}\cdot\frac{10}{11}\cdot\frac{12}{13}\cdot\frac{16}{17}\cdot\frac{18}{19} & = & \frac{55296}{323323} \sim 0.171  > \frac{1}{6}
\neea
%
but if we multiply the first nine
%
\nbea
\frac{1}{2}\cdot\frac{2}{3}\cdot\frac{4}{5}\cdot\frac{6}{7}\cdot\frac{10}{11}\cdot\frac{12}{13}\cdot\frac{16}{17}\cdot\frac{18}{19}\cdot\frac{22}{23} & = & \frac{110592}{676039} \sim 0.164  < \frac{1}{6}
\neea
%
So that's how we got the eight and of course if we chose any other eight primes we will get something bigger than $55296/323323>1/6$ because $n/(n+1)$ converges to 1 as $n \to \infty$, \ie $n/(n+1)$ gets bigger as $n$ gets bigger.

Another reason we have to limit it to eight is because $n/(n+1) < 1$ and if we keep multiplying them we'll get a smaller and smaller number and after some point we will reach $< 1/6$.

The rest is straightforward,
%
\nbea
\frac{\varphi(n)}{n} & = & \prod_{p|n}\frac{p - 1}{p}
\neea
%
so the argument above holds

{\bf Problem 2.5}. Define $\nu(1) = 0$, and for $n > 1$ let $\nu(n)$ be the number of distinct prime factors of $n$. Let $f = \mu * \nu$ and prove that $f(n)$ is either 0 or 1.

As the inverse of $\mu$ is $\mu^{-1} = u$, this means that
%
\nbea
u * f & = & (u * \mu) * \nu \\
& = & I * \nu \\
u * f & = & \nu \\
\to \nu(n) & = & \sum_{d|n} f(d)
\neea
%
$\nu$ is obviously not multiplicative since $\nu(1) \neq 1,~\nu(pq) \neq \nu(p)\nu(q)$ but it is actually additive since $\nu(p^\alpha q^\beta) = \nu(p^\alpha) + \nu(q^\beta) = \nu(p) + \nu(q)$ where $p \neq q$ are distinct primes, so let's decompose $n$ into its primal constituents, $n = \prod_i p_i^{\alpha_i}$
%
\nbea
\nu\left(\prod_i p_i^{\alpha_i}\right) & = & \sum_{d|n} f(d) \\
\sum_i \nu\left(p_i^{\alpha_i}\right) & = & \sum_{d|n} f(d) \\
\sum_i \nu\left(p_i\right) & = & \sum_{d|n} f(d)
\neea
%
from here we can immediately see that $f(n)$ is given by
%
\nbea
f(n) = \left\{
\begin{array}{l}
1 {\rm~if~} n {\rm ~is~prime} \\
0 {\rm~otherwise}
\end{array} \right.
\neea
%

{\bf Problem 2.6}. Prove that
%
\nbea
\sum_{d^2|n} \mu(d) & = & \mu^2(n)
\neea
%
and, more generally,
%
\nbea
\sum_{d^k|n} \mu(d) = \left \{
\begin{array}{l c l}
0 & & {\rm if~} m^k|n {\rm~for~some~} m > 1 \\
1 & & {\rm otherwise}
\end{array}\right.
\neea
%
The last sum is extended over all positive divisors $d$ of $n$ whose $k$th power also divide $n$.

The key point here is again ``multiplicative'', since $\mu(d)$ is multiplicative so is $\sum_{d^2|n} \mu(d)$ so we need to only consider $g(p^\alpha) = \sum_{d^2|p^\alpha} \mu(d)$ but note that even though the sum is over $d^2 \to \sum_{d^2|n}$, $\mu$ is only taking $d$, $\mu(d)$ and not $\mu(d^2)$
%
\nbea
\sum_{d^2|p^\alpha} \mu(d) & = & \mu(1) + \mu(p) \\
& = & 1 - 1 \\
& = & 0
\neea
%
The above holds if $\alpha > 1$ otherwise for $0 \le \alpha \le 1 \to \sum_{d^2|p^\alpha} \mu(d) = \mu(1) = +1$, in short
%
\nbea
g(p^\alpha) = \sum_{d^2|p^\alpha} \mu(d) & = & \left \{
\begin{array}{r c  l}
0 && {\rm if ~} \alpha > 1 \\
1 && {\rm if ~} 0 \le \alpha \le 1 \\
\end{array}\right. \\
& = & \mu^2(p^\alpha)
\neea
%
The second part follows closely, again since it is multiplicative and again note that even though the sum is over $d^k \to \sum_{d^k|n}$, $\mu$ is only taking $d$, $\mu(d)$ and not $\mu(d^k)$
%
\nbea
\sum_{d^k|p^\alpha} \mu(d) & = & \mu(1) + \mu(p) \\
& = & 1 - 1 \\
& = & 0
\neea
%
if $\alpha > k$ otherwise for $0 \le \alpha \le k \to \sum_{d^k|p^\alpha} \mu(d) = \mu(1) = +1$, the only difference now is that we can't say it is equal to $\mu^2(p^\alpha)$ because say $\alpha = k-1 > 0 \to \mu(p^{k-1}) = 0$ but $\sum_{d^k|p^{k-1}} \mu(d) = \mu(1) = +1$

{\bf Problem 2.7}. Let $\mu(p,d)$ denote the value of the Mobius function at the gcd of $p$ and $d$. Prove that for every prime $p$ we have
%
\nbea
\sum_{d|n} \mu(d)\mu(p,d) = \left \{
\begin{array}{l c l}
1 && {\rm if~} n = 1 \\
2 && {\rm if~} n = p^a, a \ge 1 \\
0 && {\rm otherwise}.
\end{array}\right.
\neea
%

The thing is the gcd $(p,mn)$ is multiplicative as long as $(m,n)=1$ because $p$ is prime and once we expand $m$ and $n$ in their primal constituents it is evident, \ie $(p,mn) = (p,m)(p,n)$, therefore $\mu(p,mn) = \mu(p,m)\mu(p,n)$

The first case is obvious $\sum_{d|1} \mu(d)\mu(p,d) = \mu(1)\mu(1) = 1$.

The second case
%
\nbea
\sum_{d|p^a} \mu(d)\mu(p,d) & = & \mu(1)\mu(p,1) + \mu(p)\mu(p,p) \\
& = & \mu(1)\mu(1) + \mu(p)\mu(p) \\
& = & (1)(1) + (-1)(-1) \\
& = & 2
\neea
%

To show the last case it's easiest to utilize the fact that $g(n) = \sum_{d|n}\mu(d)\mu(p,d)$ is multiplicative and now we just need to show $g(q^b), ~q\neq p$ as $g(p^a)$ is already covered above
%
\nbea
g(q^b) = \sum_{d|q^b}\mu(d)\mu(p,d) & = & \mu(1)\mu(p,1) + \mu(q)\mu(p,q) \\
& = & \mu(1)\mu(1) + \mu(q)\mu(1) \\
& = & (1)(1) + (-1)(1) \\
& = & 0
\neea
%

{\bf Problem 2.8}. Prove that
%
\nbea
\sum_{d|n} \mu(d) \log^m d = 0
\neea
%
if $m \ge 1$ and $n$ has more than $m$ distinct prime factors. [{\it Hint:} Induction.]

To use induction we need to prove the base case, the thing is that $\log$ is not multiplicative, so that's a bit hard. The base case should be $m = 1$ and then we go up from there to bigger $m$ ?!? \dunno

But one thing I notice is that we only need to consider numbers with one power of distinct primes, \ie $n = p_1p_2\ldots p_k$ because $\mu(d)$ is zero if the powers of the primes are not zero that is
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & \cancel{\mu(1) \log^m(1)} + \mu(p_1)\log^m(p_1) + \ldots + \mu(p_k)\log^m(p_k) + \\
&& \mu(p_1p_2)\log^m(p_1p_2) + \ldots + \mu(p_{k-1}p_k)\log^m(p_{k-1}p_k) + \ldots + \\
&& \mu(p_1p_2\ldots p_k)\log^m(p_1p_2\ldots p_k)
\neea
%
and from the definition of $\mu(d)$ we know that if it has odd number of primes it's negative and it there are an even number of distinct primes $\mu$ is positive, therefore
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -(\log^m(p_1) + \ldots + \log^m(p_k)) \\
&& +(\log^m(p_1p_2) + \ldots + \log^m(p_{k-1}p_k)) + \\
&& -(\log^m(p_1p_2p_3)+ \ldots + \log^m(p_{k-2}p_{k-1}p_k)) +\\
&& (-1)^k\log^m(p_1p_2\ldots p_k)
\neea
%
Since log is additive we can expand them but before we do that let's denote $\log(p_k) = l_k$
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -\sum_{i_1 = (k|1)} l_{i_1}^m + \sum_{i_1, i_2 = (k|2)} (l_{i_1} + l_{i_2})^m - \sum_{i_1, i_2, i_3 = (k|3)} (l_{i_1} + l_{i_2} + l_{i_3})^m + \\
&& \ldots + (-1)^k \sum_{i_1, i_2, \ldots , i_k = (k|k)} (l_{i_1} + l_{i_2} + \ldots + l_{i_k})
\neea
%
where the notation $(k|j)$ means that all combinations of $k$ choose $j$, as a concrete example, say $m=4, ~k=5$ which is the minimum $k$ required
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -(l_1^4 + l_2^4 + l_3^4 + l_4^4 + l_5^4) + \\
&& + ((l_1+l_2)^4 + (l_1+l_3)^4 + (l_1+l_4)^4 + (l_1+l_5)^4 + (l_2+l_3)^4 + (l_2+l_4)^4 +  \\ 
&& ~~~~(l_2+l_5)^4 + (l_3+l_4)^4 + (l_3+l_5)^4 + (l_4+l_5)^4) + \\
&& - ((l_1 + l_2 + l_3)^4 + (l_1 + l_2 + l_4)^4 + (l_1 + l_2 + l_5)^4 + (l_1 + l_3 + l_4)^4 + \\
&& ~~~~ (l_1 + l_3 + l_5)^4  + (l_1 + l_4 + l_5)^4  + (l_2 + l_3 + l_4)^4 + (l_2 + l_3 + l_5)^4 + \\
&& ~~~~ (l_2 + l_4 + l_5)^4 + (l_3 + l_4 + l_5)^4) \\
&& + ((l_1 + l_2 + l_3 + l_4)^4 + (l_1 + l_2 + l_3 + l_5)^4 + (l_1 + l_2 + l_4 + l_5)^4 + \\
&& ~~~~ (l_1 + l_3 + l_4 + l_5)^4 + (l_2 + l_3 + l_4 + l_5)^4) + \\
&& - ((l_1 + l_2 + l_3 + l_4 + l_5)^4)
\neea
%
Now we gather coefficients of same powers, say we collect all $l_1^4$, 
%
\nbea
(5|1) & \to & (-1)l_1^4 \\
(5|2) & \to & (+4)l_1^4 \\
(5|3) & \to & (-6)l_1^4 \\
(5|4) & \to & (+4)l_1^4 \\
(5|5) & \to & (-1)l_1^4
\neea
%
so they're basically the Pascal triangle coefficients, why is this? Well, for example, for $(5|1)$, first we fix {\bf one} $l$ and then choose a partner for it from the remaining {\bf four}, however in this case we only need one $l$ and we already fixed it, so we will just need {\bf zero} partner, \ie ${4 \choose 0} = 1$.

For $(5|2)$ we first pick an $l$ and then choose a partner (again because $(5|${\bf 2}$)$ means we need {\bf 2} $l$'s in total) for it from 4 available choices, which is ${4 \choose 1}$, \ie this $l$ will appear ${4 \choose 1} = 4$ times, for $(5|3)$ it's the same thing we first pick an $l$ and then choose {\it two} partners for it, \ie  this $l$ will then appear ${4 \choose 2} = 6$ times, and for $(5|3)$, it's pick an $l$ and choose ${4 \choose 3} = 4$ partners and so on and therefore the coefficients of $l_1$ is just those of Pascal triangle's but with the signs alternating between plus and minus. And this is true for other $l$'s not just $l_1$.

We now need to tackle the cross terms say $l_1^3l_2$, first thing to note that this cross product is always preceded by a constant (which again is from Pascal triangle), for $(l_1 + l_2)^4$ it is $4l_1^3l_2$, note that this coefficient is the same no matter how many terms are being exponentiated, \ie even for $(l_1 + l_2 + l_3 + \ldots + l_w)^4$, the coefficient for $l_1^3l_2$ is still 4 because it is still ${4 \choose 3}$ no matter what, this is because
%
\nbea
(l_1 + l_2 + \ldots)^4 & = & \underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#1}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#2}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#3}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#4}
\neea
%
To get $l_1^3l_2$ we need to gather {\bf three} $l_1$'s and we have {\bf four} bins to choose for as shown above that's why we have 4 choose 3, ${4 \choose 3} = 4$ possibilities. And as the number of bins are the same no matter how many $l$'s we have the number of possibilities is still the same.

We also have other cross terms like $l_1^2l_3l_4$, in this case, we need to gather {\bf two} $l_1$'s from {\bf four} bins so it's ${4 \choose 2} = 6$, next we need to choose {\bf one} $l_3$ from the remaining {\bf two} bins which is ${2 \choose 1} = 2$ and once we've chosen the bin for $l_2$, the other bin will definitely contain $l_3$, so in total there are
%
\nbea
{4 \choose 2}\times{2 \choose 1} & = & 6 \times 2 = 12
\neea
%
and since the number of bins is constant no matter what this coefficient remains the same no matter how many $l$'s we have.

So now for $4l_1^3l_2$ we have
%
\nbea
(5|1) & \to & (0) \\
(5|2) & \to & (+1)4l_1^3l_2 \\
(5|3) & \to & (-3)4l_1^3l_2 \\
(5|4) & \to & (+3)4l_1^3l_2 \\
(5|5) & \to & (-1)4l_1^3l_2
\neea
%
again Pascal triangle, why is this? This time we fix {\bf two} $l$'s (instead of just one for $l^4$ above), and then calculate how many partners this couple might have, for $(5|2)$, we only need {\bf two} in total so because we already fixed two of them we just need {\bf zero} partner from the three remaining ones, \ie ${3 \choose 0} = 1$. For $(5|3)$, again we fix {\bf two} $l$'s and choose one more partner (because in total we need 3) from the remaining three, \ie ${3 \choose 1} = 3$ and so on. This is also true for any two-term cross terms.

And this pattern continues for higher cross terms like $l_1^2l_2l_3$, \eg for $(5|4)$ we fix {\bf three} $l$'s and then choose one partner from the remaining {\bf two}, which means ${2 \choose 1} = 2$.

This pattern continues for any $k$, say we now have $k=6$ while $m$ stays the same, $m=4$, in this case we have $(6|1),(6|2),(6|3),(6|4),(6|5),(6|6)$, and to get the coefficients for different $l$ powers we use the same method as described above.

Say you want to know the coefficient $l_1^4$ for each $(6|1),(6|2),(6|3),(6|4),(6|5),(6|6)$, then fix an $l$ and choose a partner for it depending on which combination $(6|j)$ you're on; for just a single $l$ the combination is ${6-1\choose j-1}$ and for three $l$'s like $l_1l_2l_3^2$ we fix three and then choose a partner resulting in ${6-3 \choose j-3}$ combo.

And here we immediately see why the number of distinct primes $k$ must be larger than $m$, the exponent of $\log$, it's because if $k = m$ then on the last combo $(k=m|j=m)$ we will have ${m-m\choose m-m} = 1$ but these $l$'s, $l_1^{a_1}l_2^{a_2}\ldots l_m^{a_m}$ can only be found once and there'll be nothing to cancel it, the same is true if $k < m$, the longest $l$ combo $l_1^{a_1}l_2^{a_2}\ldots l_k^{a_k}$ is only generated once and there's nothing to cancel it to zero.

As a concrete example take $m=3$ and $k=2$, we will then have
%
\nbea
-(l_1^3 + l_2^3) + (l_1+l_2)^3 & = & 3l_1^2l_2 + 3l_1l_2^2
\neea
%
and for $m=3$, $k=3$
%
\nbea
-(l_1^3 + l_2^3 + l_3^3) + ((l_1+l_2)^3 + (l_1+l_3)^3 + (l_2+l_3)^3) - (l_1 + l_2 + l_3)^3 & = & -6l_1l_2l_3
\neea
%
so you see the longest $l$ combo is not canceled whenever $k \le m$. But if $k > m$ then the longest $l$ combo is still $m$ and for every combo of the form $(k|m \le j \le k)$ we have a coefficient of ${k-m\choose j - m}$ which is just the Pascal triangle for $(1-1)^{k-m} = 0$.

In summary, there are three numbers involved, the exponent $m$, the number of distinct primes $k$, and lastly the dummy index $j$ as indicated below
%
\nbea
\sum_{j=1}^{k} \sum_{(k|j)} \left ( l_{i_1} + \ldots + l_{i_j} \right )^m
\neea
%
and the pattern of these different combinations of $l$'s can be seen in Table~\ref{Tab:1} and we immediately see why they all sum to zero.

%
\begin{table}[]
\centering
\caption{Coefficients of various combo of $l$'s for different $j$'s with a given $k$ and $m$, note that the sum of the exponents of $l$'s is always $m$, $\sum_i a_i = m$}
\label{Tab:1}
\begin{tabular}{c | c c c c c }
~~~ ~ ~~~ & ~~~$\underbrace{l^m}_\text{one $l$}$~~~ & ~~$\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}}_\text{2 $l$'s}$~~ & ~~$\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}l_{b_3}^{a_3}}_\text{3 $l$'s}$~~ & ~~~ $\ldots$ ~~~ & $\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}\ldots l_{b_m}^{a_m}}_\text{$m$ $l$'s}$ \\ \hline
$(k|1)$ & ${k-1 \choose 1-1}$ & & & & \\ 
$(k|2)$ & ${k-1 \choose 2-1}$ & ${k-2 \choose 2-2}$ & & & \\ 
$(k|3)$ & ${k-1 \choose 3-1}$ & ${k-2 \choose 3-2}$ & ${k-3 \choose 3-3}$ & & \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & &\\ 
$(k|m)$ & ${k-1 \choose m-1}$ & ${k-2 \choose m-2}$ & ${k-3 \choose m-3}$ & & ${k-m \choose m-m}$ \\ 
$(k|m+1)$ & ${k-1 \choose (m+1)-1}$ & ${k-2 \choose (m+1)-2}$ & ${k-3 \choose (m+1)-3}$ & & ${k-m \choose (m+1)-m}$ \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & & $\vdots$ \\ 
$(k|k)$ & ${k-1 \choose k-1}$ & ${k-2 \choose k-2}$ & ${k-3 \choose k-3}$ & & ${k-m \choose m-m}$ \\ 
\end{tabular}
\end{table}
%

\bigskip
In Exercises 10, 11, and 12, $d(n)$ denotes the number of positive divisors of $n$.

{\bf Problem 2.10}. Prove that $\prod_{t|n} t = n^{d(n)/2}$.

Again, let's decompose $n$ into its primal constituents $n = \prod_i^N p_i^{\alpha_i}$ then $d(n)$ is given by
%
\nbea
d(n) = d\left(\prod_i^N p_i^{\alpha_i}\right) & = & \prod_i^N (\alpha_i + 1)
\neea
%
To see why this is we just need to recall that the number of combinations an $N$-digit (base-10) number has is 
%
\nbea
\# {\rm~of~combo} = \underbrace{10 \times 10 \times 10 \times \ldots \times 10}_\text{$N$ {\rm of~them}}
\neea
%
because each digit can take 10 possible different values. For our case, each prime factor plays the role of a digit, however, each has different possible values, which is $(\alpha_i+1)$ because we can have $p_i^0,p_i^1,p_i^2,\ldots,p_N^{\alpha_N}$ so the total number of combinations for $\prod_i^N p_i^{\alpha_i}$ is
%
\nbea
\# {\rm~of~combo} = \underbrace{(\alpha_1 + 1) (\alpha_2 + 1) (\alpha_3 + 1) \ldots (\alpha_N + 1)}_\text{$N$ {\rm prime~factors}}
\neea
%

Next, we can decompose $\prod_{t|n} t$ in terms of its primal constituents as well, say we focus on $p_1$ of $\prod_i^N p_i^{\alpha_i}$, the divisors of $p_1^{\alpha_1}$ are $p_1^0, p_1^1, \ldots, p_1^{\alpha_1}$, so if we multiply all of them we have $p_1^{1 + 2 + 3 + \ldots + \alpha_1} = p_1^{\frac{\alpha_1(\alpha_1 + 1)}{2}} = \left ( p_1^{\alpha_1}\right )^{\frac{\alpha_1+1}{2}}$.

But here $p_1^{\alpha_1}$ is not alone, each divisor of $p_1^{\alpha_1}$, \ie $p_1^{j}, ~0 \le j \le \alpha_1$, occurs $(\alpha_2+1)(\alpha_3+1)\ldots(\alpha_N+1)$ times, so the final exponent for $p_1$ in $\prod_{t|n} t$ is
%
\nbea
\left (p_1^{\alpha_1}\right )^{\frac{(\alpha_1+1)}{2}(\alpha_2+1)(\alpha_3+1)\ldots(\alpha_N+1)} & = & \left (p_1^{\alpha_1}\right )^{d(n)/2}
\neea
%
the same case goes for any other $p_i$, thus $\prod_{t|n}t = n^{d(n)/2}$. As a concrete example, take $n = p_1^2p_2^3$, the divisors of $n$ are
%
\nbea
\begin{array}{c c c c c c c}
p_1^0 ~~ p_2^0 & ~~~~~~~~ & p_1^0 ~~ p_2^1 & ~~~~~~~~ & p_1^0 ~~ p_2^2 & ~~~~~~~~ & p_1^0 ~~ p_2^3 \\
p_1^1 ~~ p_2^0 & ~~~~~~~~ & p_1^1 ~~ p_2^1 & ~~~~~~~~ & p_1^1 ~~ p_2^2 & ~~~~~~~~ & p_1^1 ~~ p_2^3 \\
p_1^2 ~~ p_2^0 & ~~~~~~~~ & p_1^2 ~~ p_2^1 & ~~~~~~~~ & p_1^2 ~~ p_2^2 & ~~~~~~~~ & p_1^2 ~~ p_2^3
\end{array}
\neea
%
so you can see that $(p_1^0~p_1^1~p_1^2)$ occurs $4=(\alpha_2+1)$ times $\to (p_1^0~p_1^1~p_1^2)^{\alpha_2+1}$.

{\bf Problem 2.11}. Prove that $d(n)$ is odd if, and only if, $n$ is square.

As shown above for $n = \prod_i^N p_i^{\alpha_i}$, $d(n) = \prod_i^N (\alpha_i + 1)$, so to get $d(n)$ to be odd we need {\it all} of $\alpha_i$ to be even so that $(\alpha_i + 1)$ is odd, therefore $n$ must be even

{\bf Problem 2.12}. Prove that $\sum_{t|n} d(t)^3 = \left (\sum_{t|n} d(t)\right )^2$.

The above relationship is evidently not true in general, we therefore need to utilize the properties of $d(t)$ to derive it. One thing to note is that $g(n) = \sum_{t|n} d(t)^3$ is multiplicative as $d(t)$ is. Therefore we just need to consider $g(p^\alpha) = \sum_{t|p^\alpha} d(t)^3$.

My strategy would be to utilize induction. Assume that $\sum_{t|p^\alpha} d(t)^3 = \left (\sum_{t|p^\alpha} d(t)\right )^2$ is true up to some $p^\alpha$, we now want to know what happens with $p^{\alpha+1}$
%
\nbea
\sum_{t|p^{\alpha+1}} d(t)^3 & = & d(p^{\alpha+1})^3 + \sum_{t|p^\alpha} d(t)^3
\neea
%
and $d(p^{\alpha+1}) = \alpha+2$ thus
%
\nbea
d(p^{\alpha+1})^3 + \sum_{t|p^\alpha} d(t)^3 & = & (\alpha + 2)^3 + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & (\alpha + 2)^2(\alpha + 2) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & (\alpha + 2)^2 + (\alpha + 2)^2(\alpha + 1) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & d(p^{\alpha + 1})^2 + (\alpha + 2)\cdot 2 \frac{(\alpha + 2)(\alpha + 1)}{2} + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & d(p^{\alpha + 1})^2 + 2 d(p^{\alpha+1})\left (\sum_{t|p^\alpha} d(t) \right ) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & \left ( d(p^{\alpha + 1}) + \sum_{t|p^\alpha} d(t) \right )^2 \\
\sum_{t|p^{\alpha+1}} d(t)^3 & = & \left ( \sum_{t|p^{\alpha+1}} d(t) \right )^2
\neea
%
Going to line 5 we have used the fact that $\sum_{t|p^\alpha} d(t) = \sum_{i=1}^{\alpha+1} i = \frac{(\alpha+1)(\alpha + 2)}{2} $ since $d(p^j) = j+1$. We can of course dispel induction for a bruter force approach by expanding $\sum_{t|p^\alpha+1} d(t)^3 = \sum_{i=1}^{\alpha+1} i^3$ but this requires us to know the formula for a sum of consecutive cubes \dunno

\bigskip
\underline{\textbf{\textit{Chapter 3}}}
\smallskip

{\bf Section 3.3, Page 54}. ``Euler's summation formula, Theorem 3.1'', if you look carefully enough at the definition the lower limit of the sum, $\sum_{y<n\le x}$, is just a less than sign and {\bf not} and less than {\bf equal} sign, this is crucial as we go to the proof of Theorem 3.3

{\bf PROOF of Theorem 3.1, Page 55}, there's some ``fudging'' going on here and not just once :) in the first line
%
\nbea
\int_{n-1}^{n}[t] f'(t)dt & \to & \int_{n-1}^n (n-1)f'(t)dt
\neea
%
so we assume that $[t] = n-1$ for the whole interval $[n-1,n]$, well this is true for if the interval excludes $n$, \ie $[n-1,n)$. So here's where the ``fudging'' comes in, in the definition of Riemann integral we can always remove a point since the area under a curve of just one point is zero $\to dt = 0$ so in this case we remove the end point $n$.

The second ``fudging'' happens in Eq (6) when we go from $-\int_m^k \to -\int_y^x$, the area under the curve is definitely different for those two integrals unless $m=[y]=y$ and $k=[x]=x$ , let's see this with a concrete example say, $f(t) = t \to f'(t) = 1$ with $y = 1.5$ and $x = 3.1$, the integral $\int_y^x[t]f'(t)dt$ is given by
%
\nbea
\int_{1.5}^{3.1}[t]f'(t)dt & = & \int_{1.5}^{2}dt + \int_{2}^{3}2dt+  \int_{3}^{3.1}3dt \\
& = & (2-1.5) + 2(3-2) + 3(3.1-3) \\
& = & 0.5 + 2 + 0.3 \\
& = & 2.8
\neea
%
while the integral $\int_{[y]}^{[x]}[t]f'(t)dt$ is given by
%
\nbea
\int_{[1.5]}^{[3.1]}[t]f'(t)dt & = & \int_{1}^{2}dt + \int_{2}^{3}2dt \\
& = & (2-1) + 2(3-2) \\
& = & 3
\neea
%
so ........ \dunno

{\bf Page 55}, ``Integration by parts gives us $\dots$ and when this is combined with (6) we obtain (5)'', what we want to do here is to move everything to the LHS
%
\nbea
\int_y^x f(t)dt = xf(x) - yf(y) - \int_y^xtf'(t)dt \\
\to \int_y^x f(t)dt - xf(x) + yf(y) + \int_y^xtf'(t)dt & = & 0
\neea
%
and we add this zero to (6) to get (5) sans the fudging discussed above :)

{\bf PROOF of Theorem 3.2, Page 55} The peculiar thing here is the constant 1 which we get from $-f(y)([y]-y)$. The problem here is that the lower limit $y = 1$ and so $[y]-y = 1-1=0$, however, as explained above, the lower limit must not be an integer as $y < n$ and $n$ starts with $n=1$, the less than sign is crucial here.

This means that $0 < y < 1$ and in this case $y$ has to be $y = 1^{-}$ such that we can take the limit $y \to 1$, so even though the lower limit of the integrals is $y=1$ we cannot just simply choose $y=1$, this manifests more strongly in the proof of Theorem 3.2 part (b) where in this case $f(y) = x^{-s}$
%
\nbea
-f(y)([y]-y) & = & -\frac{1}{y^s} (0 - y) \\
& = & \frac{1}{y^{s-1}}
\neea
%
it won't equal 1 unless we take the limit $y \to 1$, we can however, choose any value of $y$ in the range $0 <y < 1$ say $y = 1/w$ where $0 < w < \infty$
%
\nbea
\sum_{n\le x} \frac{1}{n^s} & = & \int_{1/w}^x \frac{dt}{t^s} - s\int_{1/w}^x\frac{t-[t]}{t^{s+1}} + \frac{[x]-x}{x^s} - \frac{0 - (1/w)}{(1/w)^s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{(1/w)^{1-s}}{1-s} - s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + (1/w)^{1-s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{(1/w)^{1-s}}{1-s} - s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + \frac{(1-s)(1/w)^{1-s}}{1-s}
\neea
%
we now focus on the first integral on the RHS
%
\nbea
-s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} & = & -s\int_{1/w}^1\frac{t-[1/w]}{t^{s+1}} \\
& = & -s\int_{1/w}^1\frac{t}{t^{s+1}} \\
& = & -s\int_{1/w}^1\frac{1}{t^{s}} \\
& = & -\frac{s}{1-s} + \frac{s (1/w)^{1-s}}{1-s}
\neea
%
Combining everything we get
%
\nbea
\sum_{n\le x} \frac{1}{n^s} & = & \frac{x^{1-s}}{1-s} - \bcancel{\frac{(1/w)^{1-s}}{1-s}} -\frac{s}{1-s} + \cancel{\frac{s(1/w)^{1-s}}{1-s}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + \frac{(\bcancel{1}-\cancel{s})(1/w)^{1-s}}{1-s} \\
& = & \frac{x^{1-s}}{1-s} +\frac{-1 + (1 - s)}{1-s} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{1}{1-s} + 1 - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s}
\neea
%
and we get the same result.

The lesson here is that we need to be very careful in choosing and processing these limits otherwise we'll get the wrong result.

{\bf Page 56}, first equation, the key here is that $t-[t] < 1$ and so the inequality holds

{\bf Page 56}, the value of $C$ (and $C(s)$), in the roughly middle section of the page we have
%
\nbea
\lim_{x\to\infty}\left ( \sum_{n \le x} \frac{1}{n} - \log x\right) = 1 - \int_1^\infty \frac{t - [t]}{t^2} dt,
\neea
%
and the RHS is $C$ and therefore $C$ equals the Euler's constant since the LHS is Euler's constant but it seems like this is only true when $x \to \infty$, which is to say that $C$ is independent of $x$, but recall that from earlier in the page
%
\nbea
\sum_{n\le x} \frac{1}{n} & = & \log x + C + O\left ( \frac{1}{x}\right ) \\
\to C & = & \sum_{n\le x} \frac{1}{n} - \log x - O\left ( \frac{1}{x}\right ) 
\neea
%
It therefore seems like $C$ depends on $x$ after all, how can this be? The answer is that
%
\nbea
\sum_{n\le x} \frac{1}{n} - \log x - O\left ( \frac{1}{x}\right ) & = & \lim_{x\to\infty}\left ( \sum_{n \le x} \frac{1}{n} - \log x\right)
\neea
%
Thus the LHS does {\bf not} depend on $x$ after all even though it looks like it, this argument also applies to $C(s)$ lower down in the page

{\bf Page 58}, Figure 3.1, note that this figure is a bit deceptive, to calculate $\sum_{qd \le 10}$ we need to draw one hyperbola for every $qd = \{1,2,3,4,5,6,7,8,9,10\}$, in the figure there are only 3 hyperbolas drawn. Also, the way the sum is calculated is by counting {\bf all} lattice points underneath the largest hyperbola, true that we have to count only points that lie on the hyperbolas but if we draw {\bf all} hyperbolas with $qd \le x$ we will cover all lattice points under the largest hyperbolic curve.

{\bf Page 60}, ``It can be shown that $\zeta(2) = \pi^2/6$'', an elementary proof of this fact can be obtained from the Fourier series ({\it not} Fourier transform) of $x^2$
%
\nbea
x^2 = \frac{a_0}{2} + \sum_{n=1}^\infty a_n\cos(nx) + \sum_{n=1}^\infty b_n\sin(nx)
\neea
%
$b_n = 0$ for all $n$ because $x^2$ is an even function while
%
\nbea
a_0 & = & \int_{-\pi}^{+\pi} x^2 \frac{dx}{\pi} \\
& = & \frac{1}{3\pi} \left (\pi^3 - (-\pi)^3 \right ) \\
& = & \frac{2\pi^2}{3}
\neea
%
and
%
\nbea
a_n & = & \int_{-\pi}^{+\pi} x^2 \cos(nx) \frac{dx}{\pi} \\
& = & \left.\frac{2x}{n\pi}\sin(nx)\right|_{-\pi}^{+\pi} - 2\int_{-\pi}^{+\pi} x \sin(nx) \frac{dx}{n\pi}
\neea
%
the boundary terms are zero since $\sin(\pm n\pi) = 0$, we now do another integration by parts on the remaining integral
%
\nbea
- 2\int_{-\pi}^{+\pi} x \sin(nx) \frac{dx}{n\pi} & = & \left.\frac{2x}{n^2\pi}\cos(nx)\right|_{-\pi}^{+\pi} - 2\int_{-\pi}^{+\pi}  \cos(nx) \frac{dx}{n^2\pi} \\
& = & \left.\frac{2x}{n^2\pi}\cos(nx)\right|_{-\pi}^{+\pi}  + \left.\frac{-2}{n^3\pi}\sin(nx)\right|_{-\pi}^{+\pi} \\
a_n & = & (-1)^n\frac{4}{n^2}
\neea
%
where $\cos(\pm n\pi) = \cos(n\pi) = (-1)^n$ and of course $\sin(\pm n\pi) = 0$, thus
%
\nbea
x^2 & = & \frac{\pi^2}{3} + \sum_{n=1}^\infty (-1)^n\frac{4}{n^2} \cos(nx)
\neea
%
setting $x=\pi$ we get
%
\nbea
\pi^2 & = & \frac{\pi^2}{3} + \sum_{n=1}^\infty (-1)^n\frac{4}{n^2} \cos(n\pi) \\
\frac{2\pi^2}{3} & = & \sum_{n=1}^\infty (-1)^{2n}\frac{4}{n^2} \\
\to \frac{\pi^2}{6} & = & \sum_{n=1}^\infty \frac{1}{n^2}
\neea
%

{\bf Page 61}, PROOF of Theorem 3.6, this is rather odd the sum is usually split into the following (see Theorem 3.4 and 3.5)
%
\nbea
\sum_{n \le x} \sigma_\alpha(n) & \to & \sum_{n\le x}\sum_{q|n} q^\alpha = \sum_{d \le x} \left ( \sum_{q \le x/d} q^\alpha \right )
\neea
%
but for Theorem 3.6 it's split another way (with a dramatically different final result)
%
\nbea
\sum_{n \le x} \sigma_{-\beta}(n) & \to & \sum_{n \le x}\sum_{d|n} \frac{1}{d^\beta} = \sum_{d\le x} \left ( \frac{1}{d^\beta} \sum_{q \le x/d} 1 \right )
\neea
%
although the two are equivalent counting wise but once you use Euler's summation formula you get a completely different result. To see that the two are equivalent let's just calculate something simple, say $\sum_{n \le 5} \sigma_{\alpha}(n)$ where $\alpha = -\beta$, the original definition gives us
%
\nbea
\sum_{n \le 5} \sigma_{-\beta}(n) & \to & \sum_{n \le x}\sum_{d|n} \frac{1}{d^\beta} \\
& = & \sum_{d|1} \frac{1}{d^\beta} + \sum_{d|2} \frac{1}{d^\beta} + \sum_{d|3} \frac{1}{d^\beta} + \sum_{d|4} \frac{1}{d^\beta} + \sum_{d|5} \frac{1}{d^\beta} \\
& = & \left ( \frac{1}{1^\beta} \right ) + \left ( \frac{1}{1^\beta} + \frac{1}{2^\beta} \right ) + \left ( \frac{1}{1^\beta} + \frac{1}{3^\beta} \right ) + \left ( \frac{1}{1^\beta} + \frac{1}{2^\beta} + \frac{1}{4^\beta} \right ) + \left ( \frac{1}{1^\beta} + \frac{1}{5^\beta} \right ) \\
& = & \left ( \frac{1}{1^\beta} \times 5 \right ) + \left ( \frac{1}{2^\beta} \times 2 \right ) + \left ( \frac{1}{3^\beta} \times 1 \right ) + \left ( \frac{1}{4^\beta} \times 1 \right ) + \left ( \frac{1}{5^\beta} \times 1 \right )
\neea
%
while Theorem 3.6 decomposition gives us
%
\nbea
\sum_{d\le 5} \left ( \frac{1}{d^\beta} \sum_{q \le 5/d} 1 \right ) & = & \left ( \frac{1}{1^\beta} \sum_{q \le 5/1} 1 \right ) + \left ( \frac{1}{2^\beta} \sum_{q \le 5/2} 1 \right ) + \left ( \frac{1}{3^\beta} \sum_{q \le 5/3} 1 \right ) + \left ( \frac{1}{4^\beta} \sum_{q \le 5/4} 1 \right ) + \left ( \frac{1}{5^\beta} \sum_{q \le 5/5} 1 \right ) \\
& = & \left ( \frac{1}{1^\beta} \times 5 \right ) + \left ( \frac{1}{2^\beta} \times 2 \right ) + \left ( \frac{1}{3^\beta} \times 1 \right ) + \left ( \frac{1}{4^\beta} \times 1 \right ) + \left ( \frac{1}{5^\beta} \times 1 \right )
\neea
%
and lastly Theorem 3.4 and 3.5 decomposition generates
%
\nbea
\sum_{d \le 5} \left ( \sum_{q \le 5/d} q^\alpha \right ) & = & \left ( \sum_{q \le 5/1} q^\alpha \right ) + \left ( \sum_{q \le 5/2} q^\alpha \right ) + \left ( \sum_{q \le 5/3} q^\alpha \right ) + \left ( \sum_{q \le 5/4} q^\alpha \right ) + \left ( \sum_{q \le 5/5} q^\alpha \right ) \\
& = & \left ( 5 \times 1^\alpha\right ) + \left ( 2 \times 2^\alpha\right ) + \left ( 1 \times 3^\alpha\right ) + \left ( 1 \times 4^\alpha\right ) + \left ( 1 \times 5^\alpha\right )
\neea
%
so you see that all three are equivalent but now let's apply Theorem 3.4 and 3.5's decomposition tot he proof of Theorem 3.6
%
\nbea
\sum_{n\le x} \sigma_{-\beta}(n) & = & \sum_{n\le x} \sum_{d|n}\frac{1}{d^\beta} = \sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta}
\neea
%
if $\beta \neq 1$ we have
%
\nbea
\sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta} & = & \sum_{d\le x} \frac{(x/d)^{1-\beta}}{1-\beta} + \zeta(\beta) + O\left ((x/d)^{-\beta}\right ) \\
& = & x\zeta(\beta) + \frac{x^{1-\beta}}{1-\beta} \sum_{d\le x} d^{\beta-1} + O\left (\frac{1}{x^\beta}\sum_{d\le x} d^{\beta}\right ) \\
& = & x\zeta(\beta) + \frac{x^{1-\beta}}{1-\beta} \left ( \frac{x^\beta}{\beta} + O(x^{\beta-1}) \right ) + O\left (\frac{1}{x^\beta}\left (\frac{x^{\beta+1}}{\beta+1} + O(x^{\beta}) \right )\right ) \\
& = & x\zeta(\beta) + O(x)  + O(1)  + O(x) + O(1) \\
& = & x\zeta(\beta) + O(x)
\neea
%
For $\beta=1$ first we need to calculate $\sum_{n\le x} \log n$
%
\nbea
\sum_{n\le x} \log n & = & \int_1^x \log t ~dt + \int _1^x \frac{(t - [t]) }{t} dt + \log x ([x] - x) - \lim_{y\to 1} \log y ([y] - y) \\
& = & \bcancel{ x \log x} - x + 1 + \int _1^x \frac{(t - [t]) }{t} dt - \bcancel{x \log x}  + [x]\log x \\
& = & [x]\log x - x + 1 + O(\log x) \\
& = & O(x \log x)
\neea
%
the above is actually given in the book on Page 68 and on that page the $x\log x$ wasn't canceled using $- \bcancel{x \log x}  + [x]\log x$ instead, the latter terms were grouped as $ \log x ([x] - x) \to O(\log x)$ since $|[x] - x| \le 1$, so this summation integration thingy is kinda somewhat random

While if $\beta = 1$ we have
%
\nbea
\sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta} & = & \sum_{d\le x} \log \left ( \frac{x}{d}\right ) + C + O\left ( \frac{d}{x}\right ) \\
& = & xC + x \log x - \sum_{d\le x} \log d + O\left ( \frac{1}{x} \sum_{d\le x} d\right ) \\
& = & xC + x \log x - O(x \log x) + O\left ( \frac{1}{x} \left (\frac{x^2}{2} + O(x)\right )\right ) \\
& = & xC + x \log x - O(x \log x) + O(x) + O(1)\\
& = & xC + O(x \log x)
\neea
%
so the result is very different from the book's, now if we apply Theorem 3.6's decomposition to Theorem 3.5 we will get
%
\nbea
\sum_{n \le x} \sigma_\alpha(n) & = & \sum_{n \le x} \sum_{d|n} d^{\alpha} = \sum_{d \le x} d^\alpha \sum_{q \le x/d} 1 \\
& = & \sum_{d \le x} d^\alpha \left ( \frac{x}{d} + O(1) \right ) = x \sum_{d \le x} d^{\alpha-1} + O \left ( \sum_{d \le x} d^\alpha \right ) \\
& = & \left ( \frac{x^{\alpha+1}}{\alpha}  + O(x^{\alpha}) \right ) + O\left ( \frac{x^{\alpha+2}}{\alpha+1} + O\left( x^{\alpha + 2}\right )\right ) \\
& = & \frac{x^{\alpha+1}}{\alpha}  + O(x^{\alpha}) + O\left( x^{\alpha + 2}\right )
\neea
%
so here we see why the different decomposition, the thing is that we want to maximize the leading terms and minimize the big Oh terms, in our examples above for $\sigma_{-\beta}$ our big Oh is bigger than the ones in the book and for $\sigma_\alpha$ not only our big Oh is bigger but our leading term is also smaller, so that's the reason why we have different decompositions. But of course the trick is knowing which decomposition to use beforehand which is not that obvious for someone new.

{\bf Page 62}, PROOF of Theorem 3.8, the thing to note here is that the visibility between two points is translationally  invariant (as long as we translate using integer increments), you can translate the two points to any two other points and the visibility will be the same. And if we think of them as vectors then $(a-m,b-n)$ is the the vector pointing to $(a,b)$ from $(m,n)$.

It is also symmetric under reflection w.r.t $x$ or $y$ or $x$ followed by $y$ or vice versa but not under rotation, maybe under boost? \dunno although I'm not sure if these symmetries will bring about any new information about the Euler totient function or any other arithmetical functions ...

{\bf Problem 20}. If $n$ is a positive integer prove that $[\sqrt{n} + \sqrt{n+1}] = [\sqrt{4n+2}]$

This problem turns out to be trickier than I initially thought, the first order of business here is to see how $4n+2$ behaves, the $4n$ scream modulo 4 to me, so let's see.

One thing we know is that only $4n+1$ and $4n$ can be perfect squares, for one thing the square of any odd number is $(2x+1)^2 = 4(x^2+x)+1$ and the square of any even number is $4x^2$ while we know that $2 \pmod{4}$ and $3 \pmod{4}$ are not quadratic residues modulo 4.

To see why $4n+2$ can't be a perfect square, without going into congruence and modulo stuff, let's consider the opposite
%
\nbea
2(2n+1) & = & m^2
\neea
%
which means that $2|m^2$ and that in turn means $m = 2w$ and
%
\nbea
\bcancel{2}(2n+1) & = & \bcancel{2}2w^2 \\
1 & = & 2 (w^2 - n) \\
\to 2 &|& 1
\neea
%
which is a contradiction. For $4n+3$, it is an odd number and thus as shown above, if it is to be a perfect square
%
\nbea
4n+3 & = & 4(x^2+x) + 1 \\
4n + 2 & = & 4(x^2+x) \\
2n + 1 & = & 2(x^2 + x) \\
1 & = & 2 ((x^2+x) - n) \\
\to 2 &|& 1
\neea
%
which again is a contradiction and thus $4n+2$ and $4n+3$ cannot be perfect squares ever.

Next, we will list  the natural numbers (including zero) and their corresponding square roots
%
\nbea
\begin{array}{c|c|c}
\sqrt{m} & ~~m~~ & m = 4n + j\\ \hline
{\bf 0} & {\bf 0} & {\bf 4\cdot0 + 0} \\ \hline
{\bf 1} & {\bf 1} & {\bf 4\cdot0 + 1} \\ \hline
1.414 & 2 & 4\cdot0 + 2 \\
1.732 & 3 & 4\cdot0 + 3 \\ \hline
{\bf 2} & {\bf 4} & {\bf 4\cdot1 + 0} \\ \hline
2.236 & 5 & 4\cdot1 + 1 \\
2.449 & 6 & 4\cdot1 + 2 \\
2.646 & 7 & 4\cdot1 + 3 \\
2.828 & 8 & 4\cdot2 + 0 \\ \hline
{\bf 3} & {\bf 9} & {\bf 4\cdot2 + 1} \\ \hline
3.162 & 10 & 4\cdot2 + 2 \\
3.317 & 11 & 4\cdot2 + 3 \\
3.464 & 12 & 4\cdot3 + 0 \\
3.606 & 13 & 4\cdot3 + 1 \\           
3.742 & 14 & 4\cdot3 + 2 \\           
3.873 & 15 & 4\cdot3 + 3 \\ \hline           
{\bf 4} & {\bf 16} & {\bf 4\cdot4 + 0} \\ \hline          
\end{array}
\neea
%
so we see that $\sqrt{m} = \sqrt{4n+j}$ hits integer points only at $m=4n+0$ or $m=4n+1$ and in between any two consecutive integer $\sqrt{m}$'s (\eg between $\sqrt{m} = 3$ and $\sqrt{m} = 4$) the values of $\sqrt{m}$ in between them all share the same floor because the two consecutive integer $\sqrt{m}$'s only differ by one, this only means one thing
%
\nbea
[\sqrt{4n+1}] = [\sqrt{4n+2}] = [\sqrt{4n+3}]
\neea
%

Next we tackle $\sqrt{n} + \sqrt{n+1}$, if we square it
%
\nbea
\left ( \sqrt{n} + \sqrt{n+1}\right )^2 & = & 2n + 1 + 2\sqrt{n^2 + n}
\neea
%
Now the thing to note is that $n^2 < (n^2 + n) < (n + 1/2)^2$, at least for $n>0$, and so
%
\nbea
2n + 1 + 2\sqrt{n^2} ~~<~~& 2n + 1 + 2\sqrt{n^2 + n}& ~~ < ~~ 2n + 1 + 2\sqrt{(n + 1/2)^2} \\
4n + 1 ~~<~~& \left ( \sqrt{n} + \sqrt{n+1}\right )^2 & ~~ < ~~ 4n + 2 \\
\sqrt{4n + 1} ~~<~~& \sqrt{n} + \sqrt{n+1} & ~~ < ~~ \sqrt{4n + 2}
\neea
%
and if we take the floor of all three items above
%
\nbea
\lbrack\sqrt{4n + 1}\rbrack ~~\le~~&\lbrack \sqrt{n} + \sqrt{n+1}\rbrack & ~~ \le ~~\lbrack \sqrt{4n + 2}\rbrack
\neea
%
note that the inequality signs have all changed into less than {\bf equal} signs. At this point we need to be extra careful because even though $\sqrt{4n + 1}$ and $\sqrt{4n + 2}$ differ by less than one it can be that the three numbers $\sqrt{4n + 1},\sqrt{n} + \sqrt{n+1},\sqrt{4n + 2}$ straddle through an integer, for example say $\sqrt{4n + 1} = 15.91\ldots$ and $\sqrt{n} + \sqrt{n+1} = 15.92\ldots$ while $\sqrt{4n + 2} = 16.01\ldots$, in this case $[\sqrt{4n+1}]=[\sqrt{n} + \sqrt{n+1}] \neq [\sqrt{4n+2}]$ which works against us, so our argument has to be solid to establish the result we want.

Lucky for us, from the above discussion we know that $[\sqrt{4n+1}]=[\sqrt{4n+2}]=[\sqrt{4n+3}]$ therefore since $\lbrack\sqrt{4n + 1}\rbrack \le \lbrack \sqrt{n} + \sqrt{n+1}\rbrack \le \lbrack \sqrt{4n + 2}\rbrack$ the only possibility is $[\sqrt{4n+1}]=[\sqrt{n} + \sqrt{n+1}] = [\sqrt{4n+2}]$ and also
%
\nbea
[\sqrt{n} + \sqrt{n+1}]=[\sqrt{4n+1}]=[\sqrt{4n+2}]=[\sqrt{4n+3}]
\neea
%
which is what we are after and more, for one thing we get equalities with $[\sqrt{4n+1}], [\sqrt{4n+3}]$ and it's obvious that this equality holds for $n=0$, therefore the question could've have been, for any integer $n \ge 0$, prove that the following is true $[\sqrt{n} + \sqrt{n+1}]=[\sqrt{4n+1}]=[\sqrt{4n+2}]=[\sqrt{4n+3}]$

\bigskip
\textit{\textbf{Various Failed Attempts}}
\smallskip

First thing I tried was the famous physicist formula for a square root $\sqrt{1+x}\approx 1 + \frac{1}{2}x$ and so
%
\nbea
\left \lbrack \sqrt{n} + \sqrt{n+1}\right \rbrack & = & \left \lbrack \sqrt{n} + \sqrt{n}\sqrt{1 + \frac{1}{n}} \right \rbrack = \left \lbrack \sqrt{n} + \sqrt{n}\left (1 + \frac{1}{2n}\right ) \right \rbrack \\
& = & \left \lbrack 2\sqrt{n} + \frac{1}{2\sqrt{n}} \right \rbrack
\neea
%
and also
%
\nbea
\left \lbrack \sqrt{4n+2}\right \rbrack & = & \left \lbrack 2\sqrt{n}\sqrt{1 + \frac{1}{2n}} \right \rbrack =  \left \lbrack 2\sqrt{n}\left (1 + \frac{1}{4n}\right ) \right \rbrack \\
& = & \left \lbrack 2\sqrt{n}+ \frac{1}{2\sqrt{n}} \right \rbrack
\neea
%
so to a physicist they're the same :)

But joking aside I did try the Taylor expansion trick above, first I tried to estimate how big (or small) $\frac{1}{2\sqrt{n}}$ is, but this turns out not to be fruitful because I don't know how close $2\sqrt{n}$ is to an integer, because depending on how close it is, the correction term might or might not push it up to the next integer, and I don't see a clear way to tell how close $2\sqrt{n}$ is to an integer.

Next, I did the Taylor expansion above to relate $\sqrt{n} + \sqrt{n+1}$ to $\sqrt{4n+2}$, but first, a couple of things to note, for small $x$
%
\nbea
1 + \frac{1}{2}x & < & \sqrt{1+x} \\
1 - \frac{1}{2}x & > & \sqrt{1-x}
\neea
%
Expanding $\sqrt{n} + \sqrt{n+1}$
%
\nbea
\sqrt{n} + \sqrt{n+1} & = & \sqrt{\left (\sqrt{n} + \sqrt{n+1} \right )^2} \\
& = & \sqrt{2n + 1 + 2\sqrt{n(n+1)}} \\
& = & \sqrt{2n + 1 + 2\sqrt{\left (n+\frac{1}{2}\right )^2 - \frac{1}{4}}} \\
& = & \sqrt{2n + 1 + \sqrt{\left (2n+1\right )^2 - 1}} \\
& = & \sqrt{2n + 1 + \left((2n+1) -\frac{1}{2(2n+1)} \right)} \\
& = & \sqrt{4n + 2 -\frac{1}{2(2n+1)}} \\
\sqrt{n} + \sqrt{n+1} & < & \sqrt{4n+2} - \frac{1}{2(4n+2)^{3/2}}
\neea
%
a somewhat interesting result, next, let's denote $\Delta = \frac{1}{2(4n+2)^{3/2}}$, and I wanted to show that $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}$ is bigger than $\sqrt{4n + 2}$
%
\nbea
\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} & = & \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \\
\to \left ( \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \right )^2 & = & 4n + 2 - \Delta + \Delta + 2\sqrt{\Delta}(4n + 2 - \Delta) \\
\to \left ( \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \right )^2 & > & \left ( \sqrt{4n + 2} \right )^2 \\
\to \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} & > & \sqrt{4n + 2} \\
\to \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} & > & \sqrt{4n + 2}
\neea
%
and since $0 < \Delta < 1$ it means that $0 < \sqrt{\Delta}<1$ and so

Thus what we have is
%
\nbea
\sqrt{n} + \sqrt{n+1}~~ <~~ & \sqrt{4n + 2} & ~~<~~ \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} \\
\lbrack\sqrt{n} + \sqrt{n+1}\rbrack~~ \le~~ & \lbrack\sqrt{4n + 2}\rbrack & ~~\le~~ \lbrack\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack
\neea
%
and I ran into the same straddle thing again, $\sqrt{4n + 2}$ might not be an integer and it can be that say, $\sqrt{n} + \sqrt{n+1} = 15.9\ldots$ while $\sqrt{4n + 2} = 16.001\ldots$ and $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} = 16.002\ldots$, in this case $\lbrack\sqrt{n} + \sqrt{n+1}\rbrack \neq \lbrack\sqrt{4n + 2}\rbrack = \lbrack\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack$.

I wrongfully tried to remedy the situation by claiming that
%
\nbea
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack ~~<~~ & \sqrt{4n + 2} & ~~<~~ \lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack  \\
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack ~~<~~ & \sqrt{4n + 2} & ~~<~~ \lbrack \sqrt{n} + \sqrt{n+1} \rbrack + 1
\neea
%
we can substitute $\lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack$ with $\lbrack \sqrt{n} + \sqrt{n+1}\rbrack+1$ because $\lbrack \sqrt{n} + \sqrt{n+1} \rbrack + 1 \ge \lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} \rbrack$ and here since we are moving the upper bound we want the bigger one. The problem with the above argument is that for our numerical example $\sqrt{4n + 2} = 16.001\ldots$ and $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} = 16.002\ldots$, $\sqrt{4n + 2} = \lbrack \sqrt{n} + \sqrt{n+1} \rbrack + 1$ and the inequality doesn't hold.

So the key here is to make sure that there's no such straddling and that means that $\sqrt{4n+1}$ and $\sqrt{4n+2}$ lie in between the same two integers $[a,b)$ and that's how I got the observation about $4n+j$ above.

For next attempts I was thinking that maybe I should process this whole thing in a different way maybe multiply and add them RHS and LHS or maybe I should get some identity that involves $[\sqrt{n}+\sqrt{n+1}]-[\sqrt{4n+2}]$ and requires this difference to be zero, for example $f(x) = g(x) + [\sqrt{n}+\sqrt{n+1}]-[\sqrt{4n+2}] = 0$ and we already know that $g(x)=0$ so the difference between those two square brackets must be zero, but I couldn't find such identity.

The next thing I tried was to maybe multiply or divide, I tried division together with Taylor expansion
%
\nbea
\frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} & = & \frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} \times \frac{\sqrt{n+1} - \sqrt{n}}{\sqrt{n+1} - \sqrt{n}} \\
& = & \frac{\sqrt{4n+2}\left (\sqrt{n}\sqrt{1+\frac{1}{n}} - \sqrt{n}\right)}{n+1 - n} \\
& = & \frac{\sqrt{4n+2}\left (\sqrt{n}\left ( 1 + \frac{1}{2n}\right ) - \sqrt{n}\right)}{1} \\
& = & \sqrt{4n+2}\left (\frac{1}{2\sqrt{n}}\right ) \\
& = & \sqrt{1 + \frac{1}{2n}} \\
\frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} & = & 1 + \frac{1}{4n}
\neea
%
and I wanted to see if the numerical values compute, \ie $1 + \frac{1}{4n}$ multiplied with $\sqrt{n}+\sqrt{n+1}$ will never produce a number that crosses/straddle an integer point but it was actually a silly idea, there's no easy way to verify this fact and along this silly line of thinking I was also trying to show that the difference between $\ceil{\sqrt{n} + \sqrt{n+1}} - \sqrt{n} + \sqrt{n+1}$ is always bigger than $d = [\sqrt{4n+2}] - [\sqrt{n} + \sqrt{n+1}]$ so that adding $d$ to $[\sqrt{n}+\sqrt{n+1}]$ would never cross an integer point.

{\bf Problem 21}. Determine all positive integers $n$ such that $[\sqrt{n}]$ divides $n$

Say we have a perfect square $m = a^2$, take a number $n=m+k$, if $k = aw$ then $n=a^2+aw$ is divisible by $a=[\sqrt{n}]$, the caveat here is that to make sure $a = [\sqrt{n}]$, we must restrict $w$ such that $n < (a+1)^2$ which means that
%
\nbea
a^2 ~~<~~& n & ~~<~~ (a+1)^2 \\
0 ~~<~~ & aw & ~~<~~ 2a + 1 \\
0 ~~<~~ & w & ~~<~~ 2 + \frac{1}{a}
\neea
%
now let's solve for $a$ generously provided by our friend the quadratic formula for $a^2 + aw - n = 0$
%
\nbea
a & = & \frac{-w\pm\sqrt{w^2+4n}}{2}
\neea
%
for $a$ to have an integer solution $w^2+4n$ must be a perfect square and as described in Problem 3.20, $4n+j$ can be a perfect square if and only if $j=0,1$ so therefore as long as $w=0,1,2$ (which are the valid values for $w$) the above will have a solution. Next thing we need to check is that the solution is an integer, if $w$ is even then $\sqrt{w^2 + 4n}$ is even and the whole numerator is even, if $w$ is odd $\sqrt{w^2 + 4n}$ is also odd and therefore the whole numerator will be even as well so it checks out.

Also $w=0$ means that $4n$ is a perfect square which means that $n$ is a perfect square. Therefore as long as either $n$ is a perfect square or $4n+1$ or $4n+4$ is a perfect square, $n$ is divisible by $[\sqrt{n}]$.

{\bf Problem 22}. If $n$ is a positive integer, prove that
%
\nbea
\left \lbrack \frac{8n + 13}{25} \right \rbrack - \left \lbrack \frac{n - 12 - \left \lbrack \frac{n-17}{25}\right \rbrack}{3} \right \rbrack
\neea
%
is independent of $n$

%
\nbea
\begin{array}{c|c c c | c | c}
n & \left\lbrack \frac{8n+13}{25}\right\rbrack & \left \lbrack \frac{n - 12 - \left \lbrack \frac{n-17}{25}\right \rbrack}{3} \right \rbrack & \left\lbrack\frac{n-17}{25}\right\rbrack & 8n+13 \pmod{25} & n-17 \pmod{25}\\ \hline
-1 & 0 & -4 & -1 & 5 & 7 \\
0 & 0 & -4 & -1 & 13 & 8 \\ \hline
1 & 0 & -4 & -1 & {\bf -4} & 9 \\ \hline
2 & 1 & -3 & -1 & 4 & 10 \\
3 & 1 & -3 & -1 & 12 & 11 \\ \hline
4 & 1 & -3 & -1 & {\bf -5} & 12 \\ \hline
5 & 2 & -2 & -1 & 3 & 13 \\
6 & 2 & -2 & -1 & 11 & 14 \\ \hline
7 & 2 & -2 & -1 & {\bf -6} & 15 \\ \hline
8 & 3 & -1 & -1 & 2 & 16 \\
9 & 3 & -1 & -1 & 10 & 17 \\ \hline
10 & 3 & -1 & -1 & {\bf -7} & 18 \\ \hline
11 & 4 & 0 & -1 & 1 & 19 \\
12 & 4 & 0 & -1 & 9 & 20 \\ \hline
13 & 4 & 0 & -1 & {\bf -8} & 21 \\ \hline
14 & 5 & 1 & -1 & {\bf 0} & 22 \\ \hline
15 & 5 & 1 & -1 & 8 & 23 \\
16 & 5 & 1 & -1 & 16 & 24 \\ \hline
{\bf 17} & {\bf 5} & {\bf 1} & {\bf 0} & {\bf -1} & {\bf 0} \\ \hline
18 & 6 & 2 & 0 & 7 & 1 \\
19 & 6 & 2 & 0 & 15 & 2 \\ \hline
20 & 6 & 2 & 0 & {\bf -2} & 3\\ \hline
\end{array}
\neea
%
OK, the strategy here is simple, although initially I wanted to see if I can utilize something from chapter 3 to solve this problem, maybe like putting a sum in front of those two terms and see what I get but let's just stay simple.

The strategy here is to show that when we increase $n$ the change in the first square bracket is the same as the change in the second square bracket, the above table says it all and it looks like it is true even when $n$ is negative. As for the reason why this works the above table also says it all :)

For the first square bracket, the denominator is 25 and the numerator is $8n$, $8\cdot3=24$ so roughly every 3 increments the quotient increases by one while for the second square bracket, the $-12$ does nothing as it's a multiple of 3, the numerator (barring the other square bracket) is just $n$ and thus the quotient increases every 3 increments as well.

The only exception to the rules is when $n=14$ as $8\cdot14+13$ is a multiple of 25 and thus the quotient only increases when $n$ increases by 4 instead of three, but this shift in pattern is also followed by the second square bracket thanks to $-\left \lbrack \frac{n-17}{25} \right \rbrack$, this bracket plays into effect when $n=17$, it increases its value by one as to delay (due to the minus sign in front of it) the second square bracket from increasing its value by one.

We just need to show this pattern for the first 25 entries because the whole thing repeats every 25 counts, \ie $n \to n+25$, as
%
\nbea
8m + 13 & = & 25q + r \\
\to 8(m+25) + 13 & = & 25q + r + (8\cdot 25) \\
8(m+25) + 13 & = & 25(q + 8) + r \\
\to \left \lbrack \frac{8(n+25)+13}{25} \right \rbrack & = & \left \lbrack \frac{8n+13}{25} \right \rbrack + 8
\neea
%
thus the first square bracket increases by 8 every time $n \to n+25$ while the nested square bracket changes by
%
\nbea
h -17 & = & 25q' + r' \\
\to (h+25) - 17 & = & 25q' + r' + 25 \\
(h+25) - 17 & = & 25(q' + 1) + r' \\
\to \left \lbrack \frac{(n+25)-17}{25} \right \rbrack & = & \left \lbrack \frac{n-17}{25} \right \rbrack + 1
\neea
%
so in total the second square bracket also changes by 8 as shown below
%
\nbea
l - 12 - \left \lbrack \frac{l-17}{25} \right \rbrack & = & 3q'' + r'' \\
\to (l+25) - 12 - \left \lbrack \frac{(l+25)-17}{25} \right \rbrack & = & 3q'' + r'' + 25 - 1\\
(l+25) - 12 - \left \lbrack \frac{(l+25)-17}{25} \right \rbrack  & = & 3(q'' + 8) + r'' \\
\to \left \lbrack \frac{(n+25) - 12 - \left \lbrack \frac{(n+25)-17}{25} \right \rbrack}{3} \right \rbrack  & = & \left \lbrack \frac{n - 12 - \left \lbrack \frac{n-17}{25} \right \rbrack}{3}\right \rbrack + 8
\neea
%























\end{document}