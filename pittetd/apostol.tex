\documentclass[aps,preprint,preprintnumbers,nofootinbib,showpacs,prd]{revtex4-1}
\usepackage{graphicx,color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amssymb}
\usepackage{multirow}
\usepackage{amsthm}%        But you can't use \usewithpatch for several packages as in this line. The search 

\usepackage{cancel}

%%% for SLE
\usepackage{dcolumn}   % needed for some tables
\usepackage{bm}        % for math
\usepackage{amssymb}   % for math
\usepackage{multirow}
%%% for SLE -End

\usepackage{ulem}
\usepackage{cancel}

\usepackage{hyperref}

\usepackage[top=1in, bottom=1.25in, left=1.1in, right=1.1in]{geometry}

\usepackage{mathtools} % for \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\usepackage{simplewick}

\newcommand{\msout}[1]{\text{\sout{\ensuremath{#1}}}}


%%%%%% My stuffs - Stef
\newcommand{\lsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$<$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}
\newcommand{\gsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$>$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}

%
% Key
%
\newcommand{\key}[1]{\medskip{\sffamily\bfseries\color{blue}#1}\par\medskip}
%\newcommand{\key}[1]{}
\newcommand{\q}[1] {\medskip{\sffamily\bfseries\color{red}#1}\par\medskip}
\newcommand{\comment}[2]{{\color{red}{{\bf #1:}  #2}}}


\newcommand{\ie}{{\it i.e.} }
\newcommand{\eg}{{\it e.g.} }

%
% Energy scales
%
\newcommand{\ev}{{\,{\rm eV}}}
\newcommand{\kev}{{\,{\rm keV}}}
\newcommand{\mev}{{\,{\rm MeV}}}
\newcommand{\gev}{{\,{\rm GeV}}}
\newcommand{\tev}{{\,{\rm TeV}}}
\newcommand{\fb}{{\,{\rm fb}}}
\newcommand{\ifb}{{\,{\rm fb}^{-1}}}

%
% SUSY notations
%
\newcommand{\neu}{\tilde{\chi}^0}
\newcommand{\neuo}{{\tilde{\chi}^0_1}}
\newcommand{\neut}{{\tilde{\chi}^0_2}}
\newcommand{\cha}{{\tilde{\chi}^\pm}}
\newcommand{\chao}{{\tilde{\chi}^\pm_1}}
\newcommand{\chaop}{{\tilde{\chi}^+_1}}
\newcommand{\chaom}{{\tilde{\chi}^-_1}}
\newcommand{\Wpm}{W^\pm}
\newcommand{\chat}{{\tilde{\chi}^\pm_2}}
\newcommand{\smu}{{\tilde{\mu}}}
\newcommand{\smur}{\tilde{\mu}_R}
\newcommand{\smul}{\tilde{\mu}_L}
\newcommand{\sel}{{\tilde{e}}}
\newcommand{\selr}{\tilde{e}_R}
\newcommand{\sell}{\tilde{e}_L}
\newcommand{\smurl}{\tilde{\mu}_{R,L}}

\newcommand{\casea}{\texttt{IA}}
\newcommand{\caseb}{\texttt{IB}}
\newcommand{\casec}{\texttt{II}}

\newcommand{\caseasix}{\texttt{IA-6}}

%
% Greek
%
\newcommand{\es}{{\epsilon}}
\newcommand{\sg}{{\sigma}}
\newcommand{\dt}{{\delta}}
\newcommand{\kp}{{\kappa}}
\newcommand{\lm}{{\lambda}}
\newcommand{\Lm}{{\Lambda}}
\newcommand{\gm}{{\gamma}}
\newcommand{\mn}{{\mu\nu}}
\newcommand{\Gm}{{\Gamma}}
\newcommand{\tho}{{\theta_1}}
\newcommand{\tht}{{\theta_2}}
\newcommand{\lmo}{{\lambda_1}}
\newcommand{\lmt}{{\lambda_2}}
%
% LaTeX equations
%
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bit}{\begin{itemize}}
\newcommand{\eit}{\end{itemize}}

\newcommand{\nbea}{\begin{eqnarray*}}
\newcommand{\neea}{\end{eqnarray*}}
\newcommand{\nbeq}{\begin{equation*}}
\newcommand{\neeq}{\end{equation*}}

\newcommand{\no}{{\nonumber}}
\newcommand{\td}[1]{{\widetilde{#1}}}
\newcommand{\sqt}{{\sqrt{2}}}
%
\newcommand{\me}{{\rlap/\!E}}
\newcommand{\met}{{\rlap/\!E_T}}
\newcommand{\rdmu}{{\partial^\mu}}
\newcommand{\gmm}{{\gamma^\mu}}
\newcommand{\gmb}{{\gamma^\beta}}
\newcommand{\gma}{{\gamma^\alpha}}
\newcommand{\gmn}{{\gamma^\nu}}
\newcommand{\gmf}{{\gamma^5}}
%
% Roman expressions
%
\newcommand{\br}{{\rm Br}}
\newcommand{\sign}{{\rm sign}}
\newcommand{\Lg}{{\mathcal{L}}}
\newcommand{\M}{{\mathcal{M}}}
\newcommand{\tr}{{\rm Tr}}

\newcommand{\msq}{{\overline{|\mathcal{M}|^2}}}

%
% kinematic variables
%
%\newcommand{\mc}{m^{\rm cusp}}
%\newcommand{\mmax}{m^{\rm max}}
%\newcommand{\mmin}{m^{\rm min}}
%\newcommand{\mll}{m_{\ell\ell}}
%\newcommand{\mllc}{m^{\rm cusp}_{\ell\ell}}
%\newcommand{\mllmax}{m^{\rm max}_{\ell\ell}}
%\newcommand{\mllmin}{m^{\rm min}_{\ell\ell}}
%\newcommand{\elmax} {E_\ell^{\rm max}}
%\newcommand{\elmin} {E_\ell^{\rm min}}
\newcommand{\mxx}{m_{\chi\chi}}
\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%\newcommand{\mpt}{\rlap/p_T}

%%%song
\newcommand{\cosmax}{|\cos\Theta|_{\rm max} }
\newcommand{\maa}{m_{aa}}
\newcommand{\maac}{m^{\rm cusp}_{aa}}
\newcommand{\maamax}{m^{\rm max}_{aa}}
\newcommand{\maamin}{m^{\rm min}_{aa}}
\newcommand{\eamax} {E_a^{\rm max}}
\newcommand{\eamin} {E_a^{\rm min}}
\newcommand{\eaamax} {E_{aa}^{\rm max}}
\newcommand{\eaacusp} {E_{aa}^{\rm cusp}}
\newcommand{\eaamin} {E_{aa}^{\rm min}}
\newcommand{\exxmax} {E_{\neuo \neuo}^{\rm max}}
\newcommand{\exxcusp} {E_{\neuo \neuo}^{\rm cusp}}
\newcommand{\exxmin} {E_{\neuo \neuo}^{\rm min}}
%\newcommand{\mxx}{m_{XX}}
%\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\erec}{E_{\rm rec}}
%\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
%\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
%\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%%%song

\newcommand{\mc}{m^{\rm cusp}}
\newcommand{\mmax}{m^{\rm max}}
\newcommand{\mmin}{m^{\rm min}}
\newcommand{\mll}{m_{\mu\mu}}
\newcommand{\mllc}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\mllmax}{m^{\rm max}_{\mu\mu}}
\newcommand{\mllmin}{m^{\rm min}_{\mu\mu}}
\newcommand{\mllcusp}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\elmax} {E_\mu^{\rm max}}
\newcommand{\elmin} {E_\mu^{\rm min}}
\newcommand{\elmaxw} {E_W^{\rm max}}
\newcommand{\elminw} {E_W^{\rm min}}
\newcommand{\R} {{\cal R}}

\newcommand{\ewmax} {E_W^{\rm max}}
\newcommand{\ewmin} {E_W^{\rm min}}
\newcommand{\mwrec}{m_{WW}}
\newcommand{\mwrecmin}{m_{WW}^{\rm min}}
\newcommand{\mwrecc}{m_{WW}^{\rm cusp}}
\newcommand{\mwrecmax}{m_{WW}^{\rm max}}

\newcommand{\mpt}{{\rlap/p}_T}

%%%%%% END My stuffs - Stef

\newcommand{\dunno}{$ {}^{\mbox {--}}\backslash(^{\rm o}{}\underline{\hspace{0.2cm}}{\rm o})/^{\mbox {--}}$}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\tor}{tor}





\begin{document}

\title{Apostol's Analytic Number Theory}
\bigskip
\author{Stefanus$^1$\\
$^1$ Samsung Semiconductor Inc\\ San Jose, CA 95134 USA\\
}
%
\date{\today}
%
\begin{abstract}
Just for fun :)

\end{abstract}
%
\maketitle

\renewcommand{\theequation}{A.\arabic{equation}}  % redefine the command that creates the equation no.
\setcounter{equation}{0}  % reset counter 

\underline{\textbf{\textit{Chapter 2}}}
\bigskip

{\bf Problem 2.1} Find all integers $n$ such that
%
\nbea
\begin{array}{l r c l c l r c l c l r c l}
{\rm(a)} & \varphi(n) & = & n/2 & ~~~~~~~~~ & {\rm(b)} & \varphi(n) & = & \varphi(2n) & ~~~~~~~~~ & {\rm(c)} & \varphi(n) & = & 12
\end{array}
\neea
%

For (a), using the definition of $\varphi(n)$, $\varphi(n) = n \prod_{p|n} \left ( 1 - \frac{1}{p} \right )$
%
\nbea
\frac{\bcancel{n}}{2} & = & \bcancel{n} \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\frac{1}{2} & = & \frac{\prod_{p|n} \left ( p - 1 \right )}{\prod_{p|n} p} \\
\prod_{p|n} p & = & 2\prod_{p|n} \left ( p - 1 \right )
\neea
%
if $n$ is odd the LHS is odd while the RHS is even, so it can't be. If $n$ is even the LHS only has one factor of 2 while the RHS has many so it will only work if $n=2$.

For (b)
%
\nbea
\bcancel{n} \prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2\bcancel{n} \prod_{p|2n} \left ( 1 - \frac{1}{p} \right )
\neea
%
If $n$ is even then
%
\nbea
\prod_{p|2n} \left ( 1 - \frac{1}{p} \right ) & = & \prod_{p|n} \left ( 1 - \frac{1}{p} \right )
\neea
%
and so
%
\nbea
\prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2\prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\to 1 & = & 2
\neea
%
which is impossible, so $n$ has to be odd, in that case
%
\nbea
\prod_{p|2n} \left ( 1 - \frac{1}{p} \right ) & = & \left ( 1 - \frac{1}{2} \right ) \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
& = & \frac{1}{2} \prod_{p|n} \left ( 1 - \frac{1}{p} \right )
\neea
%
and therefore
%
\nbea
\prod_{p|n} \left ( 1 - \frac{1}{p} \right )  & = & 2 \frac{1}{2} \prod_{p|n} \left ( 1 - \frac{1}{p} \right ) \\
\to 1 & = & 1
\neea
%
and therefore $\varphi(n) = \varphi(2n)$ for all odd $n$.

For (c)
%
\nbea
\varphi(n) = 12 & = & 2 \cdot 2 \cdot 3 \\
& = & \prod_{p|n} p^{\alpha_p} - p^{\alpha_p-1} \\
\varphi\left (\prod_{p|n} p^{\alpha_p} \right ) & = & \prod_{p|n}p^{\alpha_p-1} (p - 1)
\neea
%
the only possible solution is $n=13$

{\bf Problem 2.2}. For each of the following statements either give a proof or exhibit a counter example.

(a) If $(m,n)=1$ then $(\varphi(m),\varphi(n)) = 1$

(b) If $n$ is composite, then $(n, \varphi(n)) > 1$

(c) If the same primes divide $m$ and $n$, then $n\varphi(m) = m\varphi(n)$

For (a) a counter example will be $(3,4) = 1$, while $\varphi(3) = 2, ~\varphi(4) = 2$

For (b) a counter example would be $n = 15$ which means that $\varphi(15) = 8$ and $(15,8) = 1$

For (c) I think what it means by ``the same primes divide $m$ and $n$'' is that $m = \prod p^{\alpha_p}$ and $n = \prod p^{\beta_p}$, so they both have the same primes but they might have different exponents for each prime, in this case $\prod_{p|n} = \prod_{p|m}$
%
\nbea
n\varphi(m) & = & n \left ( m \prod_{p|m} \left ( 1 - \frac{1}{p}\right ) \right ) \\
& = & m \left ( n \prod_{p|n} \left ( 1 - \frac{1}{p}\right ) \right ) \\
n\varphi(m) & = & m\varphi(n)
\neea
%

{\bf Problem 2.3}. Prove that
%
\nbea
\frac{n}{\varphi(n)} = \sum_{d|n} \frac{\mu^2(d)}{\varphi(d)}
\neea
%

Since $\mu(n)$ and $\varphi(n)$ are both multiplicative so is $\mu^2/\varphi$, in that case $g(n) = \sum_{d|n} \frac{\mu^2(d)}{\varphi(d)}$ is also multiplicative. To determine $g(n)$ we need only compute $g(p^\alpha)$ for prime powers
%
\nbea
g(p^\alpha) & = & \sum_{d|p^\alpha} \frac{\mu^2(d)}{\varphi(d)} \\
& = & \frac{\mu^2(1)}{\varphi(1)} + \frac{\mu^2(p)}{\varphi(p)} + \ldots + \frac{\mu^2(p^\alpha)}{\varphi(p^\alpha)} \\
& = & 1 + \frac{1}{p - 1} \\
& = & \frac{p}{p - 1} \\
& = & p^\alpha \cdot \frac{p}{p^\alpha(p - 1)} \\
\to \sum_{d|p^\alpha} \frac{\mu^2(d)}{\varphi(d)}& = & \frac{p^\alpha}{\varphi(p^\alpha)}
\neea
%

We can also prove it the other way around by assuming the LHS, to do this it is easiest to use the Mobius inversion formula
%
\nbea
\frac{n}{\varphi(n)} = \sum_{d|n} g(d)
\neea
%
and we want to find out what this $g(d)$ is, which is
%
\nbea
g(n) & = & \sum_{d|n} \frac{d}{\varphi(d)} \mu\left ( \frac{n}{d}\right )
\neea
%
The RHS is multiplicative so like above we just need to evaluate $g(p^\alpha)$ for prime powers
%
\nbea
g(p^\alpha) & = & \sum_{d|p^\alpha} \frac{d}{\varphi(d)} \mu\left ( \frac{p^\alpha}{d}\right ) \\
& = & \frac{p^{\alpha-1}}{\varphi(p^{\alpha-1})} \mu\left ( \frac{p^\alpha}{p^{\alpha-1}}\right ) + \frac{p^\alpha}{\varphi(p^\alpha)} \mu\left ( \frac{p^\alpha}{p^\alpha}\right ) \\
& = & -\frac{p^{\alpha-1}}{\varphi(p^{\alpha-1})} + \frac{p^\alpha}{\varphi(p^\alpha)} \\
& = & -\frac{p^\alpha}{\varphi(p^\alpha)}  + \frac{p^\alpha}{\varphi(p^\alpha)} \\
& = & 0
\neea
%
if $\alpha > 1$ and if $\alpha = 1$ we get
%
\nbea
g(p) & = & \sum_{d|p} \frac{d}{\varphi(d)} \mu\left ( \frac{p}{d}\right ) \\
& = & \frac{1}{\varphi(1)} \mu\left ( \frac{p}{1}\right ) + \frac{p}{\varphi(p)} \mu\left ( \frac{p}{p}\right ) \\
& = & -1 + \frac{p}{\varphi(p)} \\
& = & -1 + \frac{p}{p - 1} \\
& = & \frac{1}{p - 1} \\
g(p) & = & \frac{1}{\varphi(p)}
\neea
%
This means that $g(p^\alpha) = 1/\varphi(p^\alpha)$ is $\alpha = 1$ and $g(p^\alpha) = 0$ if $\alpha > 1$, in other words $g(p^\alpha) = \mu^2(p^\alpha)/\varphi(p^\alpha)$

{\bf Problem 2.4}. Prove that $\varphi(n) > n/6$ for all $n$ with at most $8$ distinct prime factors.

First, let's demystify this number $8$, the reason $8$ is involved is because if you multiply out $(p-1)/p$ for the first eight primes we get
%
\nbea
\frac{1}{2}\cdot\frac{2}{3}\cdot\frac{4}{5}\cdot\frac{6}{7}\cdot\frac{10}{11}\cdot\frac{12}{13}\cdot\frac{16}{17}\cdot\frac{18}{19} & = & \frac{55296}{323323} \sim 0.171  > \frac{1}{6}
\neea
%
but if we multiply the first nine
%
\nbea
\frac{1}{2}\cdot\frac{2}{3}\cdot\frac{4}{5}\cdot\frac{6}{7}\cdot\frac{10}{11}\cdot\frac{12}{13}\cdot\frac{16}{17}\cdot\frac{18}{19}\cdot\frac{22}{23} & = & \frac{110592}{676039} \sim 0.164  < \frac{1}{6}
\neea
%
So that's how we got the eight and of course if we chose any other eight primes we will get something bigger than $55296/323323>1/6$ because $n/(n+1)$ converges to 1 as $n \to \infty$, \ie $n/(n+1)$ gets bigger as $n$ gets bigger.

Another reason we have to limit it to eight is because $n/(n+1) < 1$ and if we keep multiplying them we'll get a smaller and smaller number and after some point we will reach $< 1/6$.

The rest is straightforward,
%
\nbea
\frac{\varphi(n)}{n} & = & \prod_{p|n}\frac{p - 1}{p}
\neea
%
so the argument above holds

{\bf Problem 2.5}. Define $\nu(1) = 0$, and for $n > 1$ let $\nu(n)$ be the number of distinct prime factors of $n$. Let $f = \mu * \nu$ and prove that $f(n)$ is either 0 or 1.

As the inverse of $\mu$ is $\mu^{-1} = u$, this means that
%
\nbea
u * f & = & (u * \mu) * \nu \\
& = & I * \nu \\
u * f & = & \nu \\
\to \nu(n) & = & \sum_{d|n} f(d)
\neea
%
$\nu$ is obviously not multiplicative since $\nu(1) \neq 1,~\nu(pq) \neq \nu(p)\nu(q)$ but it is actually additive since $\nu(p^\alpha q^\beta) = \nu(p^\alpha) + \nu(q^\beta) = \nu(p) + \nu(q)$ where $p \neq q$ are distinct primes, so let's decompose $n$ into its primal constituents, $n = \prod_i p_i^{\alpha_i}$
%
\nbea
\nu\left(\prod_i p_i^{\alpha_i}\right) & = & \sum_{d|n} f(d) \\
\sum_i \nu\left(p_i^{\alpha_i}\right) & = & \sum_{d|n} f(d) \\
\sum_i \nu\left(p_i\right) & = & \sum_{d|n} f(d)
\neea
%
from here we can immediately see that $f(n)$ is given by
%
\nbea
f(n) = \left\{
\begin{array}{l}
1 {\rm~if~} n {\rm ~is~prime} \\
0 {\rm~otherwise}
\end{array} \right.
\neea
%

{\bf Problem 2.6}. Prove that
%
\nbea
\sum_{d^2|n} \mu(d) & = & \mu^2(n)
\neea
%
and, more generally,
%
\nbea
\sum_{d^k|n} \mu(d) = \left \{
\begin{array}{l c l}
0 & & {\rm if~} m^k|n {\rm~for~some~} m > 1 \\
1 & & {\rm otherwise}
\end{array}\right.
\neea
%
The last sum is extended over all positive divisors $d$ of $n$ whose $k$th power also divide $n$.

The key point here is again ``multiplicative'', since $\mu(d)$ is multiplicative so is $\sum_{d^2|n} \mu(d)$ so we need to only consider $g(p^\alpha) = \sum_{d^2|p^\alpha} \mu(d)$ but note that even though the sum is over $d^2 \to \sum_{d^2|n}$, $\mu$ is only taking $d$, $\mu(d)$ and not $\mu(d^2)$
%
\nbea
\sum_{d^2|p^\alpha} \mu(d) & = & \mu(1) + \mu(p) \\
& = & 1 - 1 \\
& = & 0
\neea
%
The above holds if $\alpha > 1$ otherwise for $0 \le \alpha \le 1 \to \sum_{d^2|p^\alpha} \mu(d) = \mu(1) = +1$, in short
%
\nbea
g(p^\alpha) = \sum_{d^2|p^\alpha} \mu(d) & = & \left \{
\begin{array}{r c  l}
0 && {\rm if ~} \alpha > 1 \\
1 && {\rm if ~} 0 \le \alpha \le 1 \\
\end{array}\right. \\
& = & \mu^2(p^\alpha)
\neea
%
The second part follows closely, again since it is multiplicative and again note that even though the sum is over $d^k \to \sum_{d^k|n}$, $\mu$ is only taking $d$, $\mu(d)$ and not $\mu(d^k)$
%
\nbea
\sum_{d^k|p^\alpha} \mu(d) & = & \mu(1) + \mu(p) \\
& = & 1 - 1 \\
& = & 0
\neea
%
if $\alpha > k$ otherwise for $0 \le \alpha \le k \to \sum_{d^k|p^\alpha} \mu(d) = \mu(1) = +1$, the only difference now is that we can't say it is equal to $\mu^2(p^\alpha)$ because say $\alpha = k-1 > 0 \to \mu(p^{k-1}) = 0$ but $\sum_{d^k|p^{k-1}} \mu(d) = \mu(1) = +1$

{\bf Problem 2.7}. Let $\mu(p,d)$ denote the value of the Mobius function at the gcd of $p$ and $d$. Prove that for every prime $p$ we have
%
\nbea
\sum_{d|n} \mu(d)\mu(p,d) = \left \{
\begin{array}{l c l}
1 && {\rm if~} n = 1 \\
2 && {\rm if~} n = p^a, a \ge 1 \\
0 && {\rm otherwise}.
\end{array}\right.
\neea
%

The thing is the gcd $(p,mn)$ is multiplicative as long as $(m,n)=1$ because $p$ is prime and once we expand $m$ and $n$ in their primal constituents it is evident, \ie $(p,mn) = (p,m)(p,n)$, therefore $\mu(p,mn) = \mu(p,m)\mu(p,n)$

The first case is obvious $\sum_{d|1} \mu(d)\mu(p,d) = \mu(1)\mu(1) = 1$.

The second case
%
\nbea
\sum_{d|p^a} \mu(d)\mu(p,d) & = & \mu(1)\mu(p,1) + \mu(p)\mu(p,p) \\
& = & \mu(1)\mu(1) + \mu(p)\mu(p) \\
& = & (1)(1) + (-1)(-1) \\
& = & 2
\neea
%

To show the last case it's easiest to utilize the fact that $g(n) = \sum_{d|n}\mu(d)\mu(p,d)$ is multiplicative and now we just need to show $g(q^b), ~q\neq p$ as $g(p^a)$ is already covered above
%
\nbea
g(q^b) = \sum_{d|q^b}\mu(d)\mu(p,d) & = & \mu(1)\mu(p,1) + \mu(q)\mu(p,q) \\
& = & \mu(1)\mu(1) + \mu(q)\mu(1) \\
& = & (1)(1) + (-1)(1) \\
& = & 0
\neea
%

{\bf Problem 2.8}. Prove that
%
\nbea
\sum_{d|n} \mu(d) \log^m d = 0
\neea
%
if $m \ge 1$ and $n$ has more than $m$ distinct prime factors. [{\it Hint:} Induction.]

To use induction we need to prove the base case, the thing is that $\log$ is not multiplicative, so that's a bit hard. The base case should be $m = 1$ and then we go up from there to bigger $m$ ?!? \dunno

But one thing I notice is that we only need to consider numbers with one power of distinct primes, \ie $n = p_1p_2\ldots p_k$ because $\mu(d)$ is zero if the powers of the primes are not zero that is
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & \cancel{\mu(1) \log^m(1)} + \mu(p_1)\log^m(p_1) + \ldots + \mu(p_k)\log^m(p_k) + \\
&& \mu(p_1p_2)\log^m(p_1p_2) + \ldots + \mu(p_{k-1}p_k)\log^m(p_{k-1}p_k) + \ldots + \\
&& \mu(p_1p_2\ldots p_k)\log^m(p_1p_2\ldots p_k)
\neea
%
and from the definition of $\mu(d)$ we know that if it has odd number of primes it's negative and it there are an even number of distinct primes $\mu$ is positive, therefore
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -(\log^m(p_1) + \ldots + \log^m(p_k)) \\
&& +(\log^m(p_1p_2) + \ldots + \log^m(p_{k-1}p_k)) + \\
&& -(\log^m(p_1p_2p_3)+ \ldots + \log^m(p_{k-2}p_{k-1}p_k)) +\\
&& (-1)^k\log^m(p_1p_2\ldots p_k)
\neea
%
Since log is additive we can expand them but before we do that let's denote $\log(p_k) = l_k$
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -\sum_{i_1 = (k|1)} l_{i_1}^m + \sum_{i_1, i_2 = (k|2)} (l_{i_1} + l_{i_2})^m - \sum_{i_1, i_2, i_3 = (k|3)} (l_{i_1} + l_{i_2} + l_{i_3})^m + \\
&& \ldots + (-1)^k \sum_{i_1, i_2, \ldots , i_k = (k|k)} (l_{i_1} + l_{i_2} + \ldots + l_{i_k})
\neea
%
where the notation $(k|j)$ means that all combinations of $k$ choose $j$, as a concrete example, say $m=4, ~k=5$ which is the minimum $k$ required
%
\nbea
\sum_{d|n} \mu(d) \log^m d & = & -(l_1^4 + l_2^4 + l_3^4 + l_4^4 + l_5^4) + \\
&& + ((l_1+l_2)^4 + (l_1+l_3)^4 + (l_1+l_4)^4 + (l_1+l_5)^4 + (l_2+l_3)^4 + (l_2+l_4)^4 +  \\ 
&& ~~~~(l_2+l_5)^4 + (l_3+l_4)^4 + (l_3+l_5)^4 + (l_4+l_5)^4) + \\
&& - ((l_1 + l_2 + l_3)^4 + (l_1 + l_2 + l_4)^4 + (l_1 + l_2 + l_5)^4 + (l_1 + l_3 + l_4)^4 + \\
&& ~~~~ (l_1 + l_3 + l_5)^4  + (l_1 + l_4 + l_5)^4  + (l_2 + l_3 + l_4)^4 + (l_2 + l_3 + l_5)^4 + \\
&& ~~~~ (l_2 + l_4 + l_5)^4 + (l_3 + l_4 + l_5)^4) \\
&& + ((l_1 + l_2 + l_3 + l_4)^4 + (l_1 + l_2 + l_3 + l_5)^4 + (l_1 + l_2 + l_4 + l_5)^4 + \\
&& ~~~~ (l_1 + l_3 + l_4 + l_5)^4 + (l_2 + l_3 + l_4 + l_5)^4) + \\
&& - ((l_1 + l_2 + l_3 + l_4 + l_5)^4)
\neea
%
Now we gather coefficients of same powers, say we collect all $l_1^4$, 
%
\nbea
(5|1) & \to & (-1)l_1^4 \\
(5|2) & \to & (+4)l_1^4 \\
(5|3) & \to & (-6)l_1^4 \\
(5|4) & \to & (+4)l_1^4 \\
(5|5) & \to & (-1)l_1^4
\neea
%
so they're basically the Pascal triangle coefficients, why is this? Well, for example, for $(5|1)$, first we fix {\bf one} $l$ and then choose a partner for it from the remaining {\bf four}, however in this case we only need one $l$ and we already fixed it, so we will just need {\bf zero} partner, \ie ${4 \choose 0} = 1$.

For $(5|2)$ we first pick an $l$ and then choose a partner (again because $(5|${\bf 2}$)$ means we need {\bf 2} $l$'s in total) for it from 4 available choices, which is ${4 \choose 1}$, \ie this $l$ will appear ${4 \choose 1} = 4$ times, for $(5|3)$ it's the same thing we first pick an $l$ and then choose {\it two} partners for it, \ie  this $l$ will then appear ${4 \choose 2} = 6$ times, and for $(5|3)$, it's pick an $l$ and choose ${4 \choose 3} = 4$ partners and so on and therefore the coefficients of $l_1$ is just those of Pascal triangle's but with the signs alternating between plus and minus. And this is true for other $l$'s not just $l_1$.

We now need to tackle the cross terms say $l_1^3l_2$, first thing to note that this cross product is always preceded by a constant (which again is from Pascal triangle), for $(l_1 + l_2)^4$ it is $4l_1^3l_2$, note that this coefficient is the same no matter how many terms are being exponentiated, \ie even for $(l_1 + l_2 + l_3 + \ldots + l_w)^4$, the coefficient for $l_1^3l_2$ is still 4 because it is still ${4 \choose 3}$ no matter what, this is because
%
\nbea
(l_1 + l_2 + \ldots)^4 & = & \underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#1}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#2}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#3}\underbrace{(l_1 + l_2 + \ldots)}_\text{bin \#4}
\neea
%
To get $l_1^3l_2$ we need to gather {\bf three} $l_1$'s and we have {\bf four} bins to choose for as shown above that's why we have 4 choose 3, ${4 \choose 3} = 4$ possibilities. And as the number of bins are the same no matter how many $l$'s we have the number of possibilities is still the same.

We also have other cross terms like $l_1^2l_3l_4$, in this case, we need to gather {\bf two} $l_1$'s from {\bf four} bins so it's ${4 \choose 2} = 6$, next we need to choose {\bf one} $l_3$ from the remaining {\bf two} bins which is ${2 \choose 1} = 2$ and once we've chosen the bin for $l_2$, the other bin will definitely contain $l_3$, so in total there are
%
\nbea
{4 \choose 2}\times{2 \choose 1} & = & 6 \times 2 = 12
\neea
%
and since the number of bins is constant no matter what this coefficient remains the same no matter how many $l$'s we have.

So now for $4l_1^3l_2$ we have
%
\nbea
(5|1) & \to & (0) \\
(5|2) & \to & (+1)4l_1^3l_2 \\
(5|3) & \to & (-3)4l_1^3l_2 \\
(5|4) & \to & (+3)4l_1^3l_2 \\
(5|5) & \to & (-1)4l_1^3l_2
\neea
%
again Pascal triangle, why is this? This time we fix {\bf two} $l$'s (instead of just one for $l^4$ above), and then calculate how many partners this couple might have, for $(5|2)$, we only need {\bf two} in total so because we already fixed two of them we just need {\bf zero} partner from the three remaining ones, \ie ${3 \choose 0} = 1$. For $(5|3)$, again we fix {\bf two} $l$'s and choose one more partner (because in total we need 3) from the remaining three, \ie ${3 \choose 1} = 3$ and so on. This is also true for any two-term cross terms.

And this pattern continues for higher cross terms like $l_1^2l_2l_3$, \eg for $(5|4)$ we fix {\bf three} $l$'s and then choose one partner from the remaining {\bf two}, which means ${2 \choose 1} = 2$.

This pattern continues for any $k$, say we now have $k=6$ while $m$ stays the same, $m=4$, in this case we have $(6|1),(6|2),(6|3),(6|4),(6|5),(6|6)$, and to get the coefficients for different $l$ powers we use the same method as described above.

Say you want to know the coefficient $l_1^4$ for each $(6|1),(6|2),(6|3),(6|4),(6|5),(6|6)$, then fix an $l$ and choose a partner for it depending on which combination $(6|j)$ you're on; for just a single $l$ the combination is ${6-1\choose j-1}$ and for three $l$'s like $l_1l_2l_3^2$ we fix three and then choose a partner resulting in ${6-3 \choose j-3}$ combo.

And here we immediately see why the number of distinct primes $k$ must be larger than $m$, the exponent of $\log$, it's because if $k = m$ then on the last combo $(k=m|j=m)$ we will have ${m-m\choose m-m} = 1$ but these $l$'s, $l_1^{a_1}l_2^{a_2}\ldots l_m^{a_m}$ can only be found once and there'll be nothing to cancel it, the same is true if $k < m$, the longest $l$ combo $l_1^{a_1}l_2^{a_2}\ldots l_k^{a_k}$ is only generated once and there's nothing to cancel it to zero.

As a concrete example take $m=3$ and $k=2$, we will then have
%
\nbea
-(l_1^3 + l_2^3) + (l_1+l_2)^3 & = & 3l_1^2l_2 + 3l_1l_2^2
\neea
%
and for $m=3$, $k=3$
%
\nbea
-(l_1^3 + l_2^3 + l_3^3) + ((l_1+l_2)^3 + (l_1+l_3)^3 + (l_2+l_3)^3) - (l_1 + l_2 + l_3)^3 & = & -6l_1l_2l_3
\neea
%
so you see the longest $l$ combo is not canceled whenever $k \le m$. But if $k > m$ then the longest $l$ combo is still $m$ and for every combo of the form $(k|m \le j \le k)$ we have a coefficient of ${k-m\choose j - m}$ which is just the Pascal triangle for $(1-1)^{k-m} = 0$.

In summary, there are three numbers involved, the exponent $m$, the number of distinct primes $k$, and lastly the dummy index $j$ as indicated below
%
\nbea
\sum_{j=1}^{k} \sum_{(k|j)} \left ( l_{i_1} + \ldots + l_{i_j} \right )^m
\neea
%
and the pattern of these different combinations of $l$'s can be seen in Table~\ref{Tab:1} and we immediately see why they all sum to zero.

%
\begin{table}[]
\centering
\caption{Coefficients of various combo of $l$'s for different $j$'s with a given $k$ and $m$, note that the sum of the exponents of $l$'s is always $m$, $\sum_i a_i = m$}
\label{Tab:1}
\begin{tabular}{c | c c c c c }
~~~ ~ ~~~ & ~~~$\underbrace{l^m}_\text{one $l$}$~~~ & ~~$\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}}_\text{2 $l$'s}$~~ & ~~$\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}l_{b_3}^{a_3}}_\text{3 $l$'s}$~~ & ~~~ $\ldots$ ~~~ & $\underbrace{l_{b_1}^{a_1}l_{b_2}^{a_2}\ldots l_{b_m}^{a_m}}_\text{$m$ $l$'s}$ \\ \hline
$(k|1)$ & ${k-1 \choose 1-1}$ & & & & \\ 
$(k|2)$ & ${k-1 \choose 2-1}$ & ${k-2 \choose 2-2}$ & & & \\ 
$(k|3)$ & ${k-1 \choose 3-1}$ & ${k-2 \choose 3-2}$ & ${k-3 \choose 3-3}$ & & \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & &\\ 
$(k|m)$ & ${k-1 \choose m-1}$ & ${k-2 \choose m-2}$ & ${k-3 \choose m-3}$ & & ${k-m \choose m-m}$ \\ 
$(k|m+1)$ & ${k-1 \choose (m+1)-1}$ & ${k-2 \choose (m+1)-2}$ & ${k-3 \choose (m+1)-3}$ & & ${k-m \choose (m+1)-m}$ \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & & $\vdots$ \\ 
$(k|k)$ & ${k-1 \choose k-1}$ & ${k-2 \choose k-2}$ & ${k-3 \choose k-3}$ & & ${k-m \choose m-m}$ \\ 
\end{tabular}
\end{table}
%

















\bigskip
In Exercises 10, 11, and 12, $d(n)$ denotes the number of positive divisors of $n$.

{\bf Problem 2.10}. Prove that $\prod_{t|n} t = n^{d(n)/2}$.

Again, let's decompose $n$ into its primal constituents $n = \prod_i^N p_i^{\alpha_i}$ then $d(n)$ is given by
%
\nbea
d(n) = d\left(\prod_i^N p_i^{\alpha_i}\right) & = & \prod_i^N (\alpha_i + 1)
\neea
%
To see why this is we just need to recall that the number of combinations an $N$-digit (base-10) number has is 
%
\nbea
\# {\rm~of~combo} = \underbrace{10 \times 10 \times 10 \times \ldots \times 10}_\text{$N$ {\rm of~them}}
\neea
%
because each digit can take 10 possible different values. For our case, each prime factor plays the role of a digit, however, each has different possible values, which is $(\alpha_i+1)$ because we can have $p_i^0,p_i^1,p_i^2,\ldots,p_N^{\alpha_N}$ so the total number of combinations for $\prod_i^N p_i^{\alpha_i}$ is
%
\nbea
\# {\rm~of~combo} = \underbrace{(\alpha_1 + 1) (\alpha_2 + 1) (\alpha_3 + 1) \ldots (\alpha_N + 1)}_\text{$N$ {\rm prime~factors}}
\neea
%

Next, we can decompose $\prod_{t|n} t$ in terms of its primal constituents as well, say we focus on $p_1$ of $\prod_i^N p_i^{\alpha_i}$, the divisors of $p_1^{\alpha_1}$ are $p_1^0, p_1^1, \ldots, p_1^{\alpha_1}$, so if we multiply all of them we have $p_1^{1 + 2 + 3 + \ldots + \alpha_1} = p_1^{\frac{\alpha_1(\alpha_1 + 1)}{2}} = \left ( p_1^{\alpha_1}\right )^{\frac{\alpha_1+1}{2}}$.

But here $p_1^{\alpha_1}$ is not alone, each divisor of $p_1^{\alpha_1}$, \ie $p_1^{j}, ~0 \le j \le \alpha_1$, occurs $(\alpha_2+1)(\alpha_3+1)\ldots(\alpha_N+1)$ times, so the final exponent for $p_1$ in $\prod_{t|n} t$ is
%
\nbea
\left (p_1^{\alpha_1}\right )^{\frac{(\alpha_1+1)}{2}(\alpha_2+1)(\alpha_3+1)\ldots(\alpha_N+1)} & = & \left (p_1^{\alpha_1}\right )^{d(n)/2}
\neea
%
the same case goes for any other $p_i$, thus $\prod_{t|n}t = n^{d(n)/2}$. As a concrete example, take $n = p_1^2p_2^3$, the divisors of $n$ are
%
\nbea
\begin{array}{c c c c c c c}
p_1^0 ~~ p_2^0 & ~~~~~~~~ & p_1^0 ~~ p_2^1 & ~~~~~~~~ & p_1^0 ~~ p_2^2 & ~~~~~~~~ & p_1^0 ~~ p_2^3 \\
p_1^1 ~~ p_2^0 & ~~~~~~~~ & p_1^1 ~~ p_2^1 & ~~~~~~~~ & p_1^1 ~~ p_2^2 & ~~~~~~~~ & p_1^1 ~~ p_2^3 \\
p_1^2 ~~ p_2^0 & ~~~~~~~~ & p_1^2 ~~ p_2^1 & ~~~~~~~~ & p_1^2 ~~ p_2^2 & ~~~~~~~~ & p_1^2 ~~ p_2^3
\end{array}
\neea
%
so you can see that $(p_1^0~p_1^1~p_1^2)$ occurs $4=(\alpha_2+1)$ times $\to (p_1^0~p_1^1~p_1^2)^{\alpha_2+1}$.

{\bf Problem 2.11}. Prove that $d(n)$ is odd if, and only if, $n$ is square.

As shown above for $n = \prod_i^N p_i^{\alpha_i}$, $d(n) = \prod_i^N (\alpha_i + 1)$, so to get $d(n)$ to be odd we need {\it all} of $\alpha_i$ to be even so that $(\alpha_i + 1)$ is odd, therefore $n$ must be even

{\bf Problem 2.12}. Prove that $\sum_{t|n} d(t)^3 = \left (\sum_{t|n} d(t)\right )^2$.

The above relationship is evidently not true in general, we therefore need to utilize the properties of $d(t)$ to derive it. One thing to note is that $g(n) = \sum_{t|n} d(t)^3$ is multiplicative as $d(t)$ is. Therefore we just need to consider $g(p^\alpha) = \sum_{t|p^\alpha} d(t)^3$.

My strategy would be to utilize induction. Assume that $\sum_{t|p^\alpha} d(t)^3 = \left (\sum_{t|p^\alpha} d(t)\right )^2$ is true up to some $p^\alpha$, we now want to know what happens with $p^{\alpha+1}$
%
\nbea
\sum_{t|p^{\alpha+1}} d(t)^3 & = & d(p^{\alpha+1})^3 + \sum_{t|p^\alpha} d(t)^3
\neea
%
and $d(p^{\alpha+1}) = \alpha+2$ thus
%
\nbea
d(p^{\alpha+1})^3 + \sum_{t|p^\alpha} d(t)^3 & = & (\alpha + 2)^3 + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & (\alpha + 2)^2(\alpha + 2) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & (\alpha + 2)^2 + (\alpha + 2)^2(\alpha + 1) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & d(p^{\alpha + 1})^2 + (\alpha + 2)\cdot 2 \frac{(\alpha + 2)(\alpha + 1)}{2} + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & d(p^{\alpha + 1})^2 + 2 d(p^{\alpha+1})\left (\sum_{t|p^\alpha} d(t) \right ) + \left ( \sum_{t|p^\alpha} d(t)\right )^2 \\
& = & \left ( d(p^{\alpha + 1}) + \sum_{t|p^\alpha} d(t) \right )^2 \\
\sum_{t|p^{\alpha+1}} d(t)^3 & = & \left ( \sum_{t|p^{\alpha+1}} d(t) \right )^2
\neea
%
Going to line 5 we have used the fact that $\sum_{t|p^\alpha} d(t) = \sum_{i=1}^{\alpha+1} i = \frac{(\alpha+1)(\alpha + 2)}{2} $ since $d(p^j) = j+1$. We can of course dispel induction for a bruter force approach by expanding $\sum_{t|p^\alpha+1} d(t)^3 = \sum_{i=1}^{\alpha+1} i^3$ but this requires us to know the formula for a sum of consecutive cubes \dunno

\bigskip
\underline{\textbf{\textit{Chapter 3}}}
\smallskip

{\bf Section 3.3, Page 54}. ``Euler's summation formula, Theorem 3.1'', if you look carefully enough at the definition the lower limit of the sum, $\sum_{y<n\le x}$, is just a less than sign and {\bf not} and less than {\bf equal} sign, this is crucial as we go to the proof of Theorem 3.3

{\bf PROOF of Theorem 3.1, Page 55}, there's some ``fudging'' going on here and not just once :) in the first line
%
\nbea
\int_{n-1}^{n}[t] f'(t)dt & \to & \int_{n-1}^n (n-1)f'(t)dt
\neea
%
so we assume that $[t] = n-1$ for the whole interval $[n-1,n]$, well this is true for if the interval excludes $n$, \ie $[n-1,n)$. So here's where the ``fudging'' comes in, in the definition of Riemann integral we can always remove a point since the area under a curve of just one point is zero $\to dt = 0$ so in this case we remove the end point $n$.

The second ``fudging'' happens in Eq (6) when we go from $-\int_m^k \to -\int_y^x$, the area under the curve is definitely different for those two integrals unless $m=[y]=y$ and $k=[x]=x$ , let's see this with a concrete example say, $f(t) = t \to f'(t) = 1$ with $y = 1.5$ and $x = 3.1$, the integral $\int_y^x[t]f'(t)dt$ is given by
%
\nbea
\int_{1.5}^{3.1}[t]f'(t)dt & = & \int_{1.5}^{2}dt + \int_{2}^{3}2dt+  \int_{3}^{3.1}3dt \\
& = & (2-1.5) + 2(3-2) + 3(3.1-3) \\
& = & 0.5 + 2 + 0.3 \\
& = & 2.8
\neea
%
while the integral $\int_{[y]}^{[x]}[t]f'(t)dt$ is given by
%
\nbea
\int_{[1.5]}^{[3.1]}[t]f'(t)dt & = & \int_{1}^{2}dt + \int_{2}^{3}2dt \\
& = & (2-1) + 2(3-2) \\
& = & 3
\neea
%
so ........ \dunno

{\bf Page 55}, ``Integration by parts gives us $\dots$ and when this is combined with (6) we obtain (5)'', what we want to do here is to move everything to the LHS
%
\nbea
\int_y^x f(t)dt = xf(x) - yf(y) - \int_y^xtf'(t)dt \\
\to \int_y^x f(t)dt - xf(x) + yf(y) + \int_y^xtf'(t)dt & = & 0
\neea
%
and we add this zero to (6) to get (5) sans the fudging discussed above :)

{\bf PROOF of Theorem 3.2, Page 55} The peculiar thing here is the contant 1 which we get from $-f(y)([y]-y)$. The problem here is that the lower limit $y = 1$ and so $[y]-y = 1-1=0$, however, as explained above, the lower limit must not be an integer as $y < n$ and $n$ starts with $n=1$, the less than sign is crucial here.

This means that $0 < y < 1$ and in this case $y$ has to be $y = 1^{-}$ such that we can take the limit $y \to 1$, so even though the lower limit of the integrals is $y=1$ we cannot just simply choose $y=1$, this manifests more strongly in the proof of Theorem 3.2 part (b) where in this case $f(y) = x^{-s}$
%
\nbea
-f(y)([y]-y) & = & -\frac{1}{y^s} (0 - y) \\
& = & \frac{1}{y^{s-1}}
\neea
%
it won't equal 1 unless we take the limit $y \to 1$, we can however, choose any value of $y$ in the range $0 <y < 1$ say $y = 1/w$ where $0 < w < \infty$
%
\nbea
\sum_{n\le x} \frac{1}{n^s} & = & \int_{1/w}^x \frac{dt}{t^s} - s\int_{1/w}^x\frac{t-[t]}{t^{s+1}} + \frac{[x]-x}{x^s} - \frac{0 - (1/w)}{(1/w)^s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{(1/w)^{1-s}}{1-s} - s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + (1/w)^{1-s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{(1/w)^{1-s}}{1-s} - s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + \frac{(1-s)(1/w)^{1-s}}{1-s}
\neea
%
we now focus on the first integral on the RHS
%
\nbea
-s\int_{1/w}^1\frac{t-[t]}{t^{s+1}} & = & -s\int_{1/w}^1\frac{t-[1/w]}{t^{s+1}} \\
& = & -s\int_{1/w}^1\frac{t}{t^{s+1}} \\
& = & -s\int_{1/w}^1\frac{1}{t^{s}} \\
& = & -\frac{s}{1-s} + \frac{s (1/w)^{1-s}}{1-s}
\neea
%
Combining everything we get
%
\nbea
\sum_{n\le x} \frac{1}{n^s} & = & \frac{x^{1-s}}{1-s} - \bcancel{\frac{(1/w)^{1-s}}{1-s}} -\frac{s}{1-s} + \cancel{\frac{s(1/w)^{1-s}}{1-s}} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} + \frac{(\bcancel{1}-\cancel{s})(1/w)^{1-s}}{1-s} \\
& = & \frac{x^{1-s}}{1-s} +\frac{-1 + (1 - s)}{1-s} - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s} \\
& = & \frac{x^{1-s}}{1-s} - \frac{1}{1-s} + 1 - s\int_{1}^x\frac{t-[t]}{t^{s+1}} - \frac{x-[x]}{x^s}
\neea
%
and we get the same result.

The lesson here is that we need to be very careful in choosing and processing these limits otherwise we'll get the wrong result.

{\bf Page 56}, first equation, the key here is that $t-[t] < 1$ and so the inequality holds

{\bf Page 56}, the value of $C$ (and $C(s)$), in the roughly middle section of the page we have
%
\nbea
\lim_{x\to\infty}\left ( \sum_{n \le x} \frac{1}{n} - \log x\right) = 1 - \int_1^\infty \frac{t - [t]}{t^2} dt,
\neea
%
and the RHS is $C$ and therefore $C$ equals the Euler's constant since the LHS is Euler's constant but it seems like this is only true when $x \to \infty$, which is to say that $C$ is independent of $x$, but recall that from earlier in the page
%
\nbea
\sum_{n\le x} \frac{1}{n} & = & \log x + C + O\left ( \frac{1}{x}\right ) \\
\to C & = & \sum_{n\le x} \frac{1}{n} - \log x - O\left ( \frac{1}{x}\right ) 
\neea
%
It therefore seems like $C$ depends on $x$ after all, how can this be? The answer is that
%
\nbea
\sum_{n\le x} \frac{1}{n} - \log x - O\left ( \frac{1}{x}\right ) & = & \lim_{x\to\infty}\left ( \sum_{n \le x} \frac{1}{n} - \log x\right)
\neea
%
Thus the LHS does {\bf not} depend on $x$ after all even though it looks like it, this argument also applies to $C(s)$ lower down in the page

{\bf Page 58}, Figure 3.1, note that this figure is a bit deceptive, to calculate $\sum_{qd \le 10}$ we need to draw one hyperbola for every $qd = \{1,2,3,4,5,6,7,8,9,10\}$, in the figure there are only 3 hyperbolas drawn. Also, the way the sum is calculated is by counting {\bf all} lattice points underneath the largest hyperbola, true that we have to count only points that lie on the hyperbolas but if we draw {\bf all} hyperbolas with $qd \le x$ we will cover all lattice points under the largest hyperbolic curve.

{\bf Page 60}, ``It can be shown that $\zeta(2) = \pi^2/6$'', an elementary proof of this fact can be obtained from the Fourier series ({\it not} Fourier transform) of $x^2$
%
\nbea
x^2 = \frac{a_0}{2} + \sum_{n=1}^\infty a_n\cos(nx) + \sum_{n=1}^\infty b_n\sin(nx)
\neea
%
$b_n = 0$ for all $n$ because $x^2$ is an even function while
%
\nbea
a_0 & = & \int_{-\pi}^{+\pi} x^2 \frac{dx}{\pi} \\
& = & \frac{1}{3\pi} \left (\pi^3 - (-\pi)^3 \right ) \\
& = & \frac{2\pi^2}{3}
\neea
%
and
%
\nbea
a_n & = & \int_{-\pi}^{+\pi} x^2 \cos(nx) \frac{dx}{\pi} \\
& = & \left.\frac{2x}{n\pi}\sin(nx)\right|_{-\pi}^{+\pi} - 2\int_{-\pi}^{+\pi} x \sin(nx) \frac{dx}{n\pi}
\neea
%
the boundary terms are zero since $\sin(\pm\pi) = 0$, we now do another integration by parts on the remaining integral
%
\nbea
- 2\int_{-\pi}^{+\pi} x \sin(nx) \frac{dx}{n\pi} & = & \left.\frac{2x}{n^2\pi}\cos(nx)\right|_{-\pi}^{+\pi} - 2\int_{-\pi}^{+\pi}  \cos(nx) \frac{dx}{n^2\pi} \\
& = & \left.\frac{2x}{n^2\pi}\cos(nx)\right|_{-\pi}^{+\pi}  + \left.\frac{-2}{n^3\pi}\sin(nx)\right|_{-\pi}^{+\pi} \\
a_n & = & (-1)^n\frac{4}{n^2}
\neea
%
where $\cos(\pm n\pi) = \cos(n\pi) = (-1)^n$ and of course $\sin(\pm n\pi) = 0$, thus
%
\nbea
x^2 & = & \frac{\pi^2}{3} + \sum_{n=1}^\infty (-1)^n\frac{4}{n^2} \cos(nx)
\neea
%
setting $x=\pi$ we get
%
\nbea
\pi^2 & = & \frac{\pi^2}{3} + \sum_{n=1}^\infty (-1)^n\frac{4}{n^2} \cos(n\pi) \\
\frac{2\pi^2}{3} & = & \sum_{n=1}^\infty (-1)^{2n}\frac{4}{n^2} \\
\to \frac{\pi^2}{6} & = & \sum_{n=1}^\infty \frac{1}{n^2}
\neea
%

{\bf Page 61}, PROOF of Theorem 3.6,
%
\nbea
\sum_{n\le x} \sigma_{-\beta}(n) & = & \sum_{n\le x} \sum_{d|n}\frac{1}{d^\beta} = \sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta}
\neea
%

if $\beta \neq 1$ we have
%
\nbea
\sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta} & = & \sum_{d\le x} \frac{(x/d)^{1-\beta}}{1-\beta} + \zeta(\beta) + O\left ((x/d)^{-\beta}\right ) \\
& = & x\zeta(\beta) + \frac{x^{1-\beta}}{1-\beta} \sum_{d\le x} d^{\beta-1} + O\left (\frac{1}{x^\beta}\sum_{d\le x} d^{\beta}\right ) \\
& = & x\zeta(\beta) + \frac{x^{1-\beta}}{1-\beta} \left ( \frac{x^\beta}{\beta} + O(x^{\beta-1}) \right ) + O\left (\frac{1}{x^\beta}\left (\frac{x^{\beta+1}}{\beta+1} + O(x^{\beta}) \right )\right ) \\
& = & x\zeta(\beta) + O(x)  + O(1)  + O(x) + O(1) \\
& = & x\zeta(\beta) + O(x)
\neea
%




%
\nbea
\sum_{n\le x} \log n & = & \int_1^x \log t ~dt + \int _1^x \frac{(t - [t]) }{t} dt + \log x ([x] - x) - \lim_{y\to 1} \log y ([y] - y) \\
& = & \bcancel{ x \log x} - x + 1 + \int _1^x \frac{(t - [t]) }{t} dt - \bcancel{x \log x}  + [x]\log x \\
& = & [x]\log x - x + 1 + O(\log x) \\
& = & O(x \log x)
\neea
%

if $\beta = 1$ we have
%
\nbea
\sum_{d\le x} \sum_{q\le x/d}\frac{1}{q^\beta} & = & \sum_{d\le x} \log \left ( \frac{x}{d}\right ) + C + O\left ( \frac{d}{x}\right ) \\
& = & xC + x \log x - \sum_{d\le x} \log d + O\left ( \frac{1}{x} \sum_{d\le x} d\right ) \\
& = & xC + x \log x - O(x \log x) + O\left ( \frac{1}{x} \left (\frac{x^2}{2} + O(x)\right )\right ) \\
& = & xC + x \log x - O(x \log x) + O(x) + O(1)\\
& = & xC + O(x \log x)
\neea
%

{\bf Problem 20}. If $n$ is a positive integer prove that $[\sqrt{n} + \sqrt{n+1}] = [\sqrt{4n+2}]$

%
\nbea
\sqrt{n} + \sqrt{n+1} & = & \sqrt{\left (\sqrt{n} + \sqrt{n+1} \right )^2} \\
& = & \sqrt{2n + 1 + 2\sqrt{n(n+1)}} \\
& = & \sqrt{2n + 1 + 2\sqrt{\left (n+\frac{1}{2}\right )^2 - \frac{1}{4}}} \\
& = & \sqrt{2n + 1 + \sqrt{\left (2n+1\right )^2 - 1}} \\
& = & \sqrt{2n + 1 + ((2n+1) -\Delta )} \\
& = & \sqrt{4n + 2 -\Delta}
\neea
%
where $0 <\Delta < 1$, this means $\sqrt{n} + \sqrt{n+1} < \sqrt{4n + 2}$, next we would like to compare $\sqrt{4n + 2}$ to $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}$
%
\nbea
\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} & = & \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \\
\to \left ( \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \right )^2 & = & 4n + 2 - \Delta + \Delta + 2\sqrt{\Delta}(4n + 2 - \Delta) \\
\to \left ( \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} \right )^2 & > & \left ( \sqrt{4n + 2} \right )^2 \\
\to \sqrt{4n + 2 -\Delta} + \sqrt{\Delta} & > & \sqrt{4n + 2} \\
\to \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} & > & \sqrt{4n + 2}
\neea
%
and since $0 < \Delta < 1$ it means that $0 < \sqrt{\Delta}<1$ and so

Thus what we have is
%
\nbea
\sqrt{n} + \sqrt{n+1} < & \sqrt{4n + 2} & < \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}
\neea
%
we now need to be extra careful, $\sqrt{4n + 2}$ might not be an integer and it can be that say, $\sqrt{n} + \sqrt{n+1} = 15.9\ldots$ while $\sqrt{4n + 2} = 16.001\ldots$ and $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta} = 16.002\ldots$, in this case if we take the floor of all three entities we will get something like
%
\nbea
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack \le & \lbrack \sqrt{4n + 2} \rbrack & \le \lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack 
\neea
%
the less than equal sign is troublesome because in this case it can be that $\lbrack \sqrt{4n + 2} \rbrack = \lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack = \lbrack \sqrt{n} + \sqrt{n+1} \rbrack + 1$.

The crucial info we need here is that
%
\nbea
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack < & \sqrt{4n + 2} & < \lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack  \\
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack < & \sqrt{4n + 2} & < \lbrack \sqrt{n} + \sqrt{n+1} \rbrack + 1
\neea
%
we can substitute $\lbrack \sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}\rbrack$ with $\lbrack \sqrt{n} + \sqrt{n+1}\rbrack+1$ because $\sqrt{n} + \sqrt{n+1}$ and $\sqrt{n} + \sqrt{n+1} + \sqrt{\Delta}$ differ by $< 1$.

Now since the outermost LHS and outermost RHS are integers and the inequalities are strict inequalities we can deduce that
%
\nbea
\lbrack \sqrt{n} + \sqrt{n+1} \rbrack & = & \lbrack\sqrt{4n + 2}\rbrack
\neea
%

%
\nbea
\frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} & = & \frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} \times \frac{\sqrt{n+1} - \sqrt{n}}{\sqrt{n+1} - \sqrt{n}} \\
& = & \frac{\sqrt{4n+2}\left (\sqrt{n}\sqrt{1+\frac{1}{n}} - \sqrt{n}\right)}{n+1 - n} \\
& = & \frac{\sqrt{4n+2}\left (\sqrt{n}\left ( 1 + \frac{1}{2n}\right ) - \sqrt{n}\right)}{1} \\
& = & \sqrt{4n+2}\left (\frac{1}{2\sqrt{n}}\right ) \\
& = & \sqrt{1 + \frac{1}{2n}} \\
\frac{\sqrt{4n+2}}{\sqrt{n+1} + \sqrt{n}} & = & 1 + \frac{1}{4n}
\neea
%

%
\nbea
\frac{1}{4n} \left ( \sqrt{n+1} + \sqrt{n} \right ) & = & \sqrt{\frac{1}{16n} + \frac{1}{16n^2}}
\neea
%



%
\nbea
\sqrt{n} + \sqrt{n+1} & = & \sqrt{\left (\sqrt{n} + \sqrt{n+1} \right )^2} \\
& = & \sqrt{2n + 1 + 2\sqrt{n(n+1)}} \\
& = & \sqrt{2n + 1 + 2\sqrt{\left (n+\frac{1}{2}\right )^2 - \frac{1}{4}}} \\
& = & \sqrt{2n + 1 + \sqrt{\left (2n+1\right )^2 - 1}} \\
& = & \sqrt{2n + 1 + \left((2n+1) -\frac{1}{2(2n+1)} \right)} \\
& = & \sqrt{4n + 2 -\frac{1}{2(2n+1)}} \\
& = & \sqrt{4n+2} - \frac{1}{2(4n+2)^{3/2}}
\neea
%



physicist's way, Taylor expansion
%
\nbea
\sqrt{n+1} & = & \sqrt{n}\sqrt{1 + \frac{1}{n}} \\
& = & \sqrt{n} \left ( 1 + \frac{1}{2}\left ( \frac{1}{n} \right)\right)
\neea
%




Note that $4n + 2$ cannot be a perfect square because otherwise
%
\nbea
2(2n+1) & = & m^2
\neea
%
$\to m = 2w$ and
%
\nbea
\bcancel{2}(2n+1) & = & \bcancel{2}2w^2 \\
1 & = & 2 (w^2 - n) \\
\to 2 &|& 1
\neea
%
which is a contradiction, while $4n + 1$ is free to be a perfect square, in fact the square of any odd number is $(2x+1)^2 = 4(x^2+x) + 1$ thus as we let $n$ run from $1,2,\ldots$, we'll cover the square of every odd number except for $1^2$

But if we look at $\sqrt{4n+1},\sqrt{4n+2},\sqrt{4n+3},\sqrt{4n+4}$ the value will increase ``linearly'' and since only $4n+1$ can be a perfect square, the above sequence will only hit an integer if $4n+1$ is a perfect square

Why can't $4n+3$ be a perfect square, the answer lies in quadratic residue modulo 4
%
\nbea
h^2 & = & 4n + 3 \\
\to h^2 & \equiv & 3 \pmod{4}
\neea
% 
and $3$ is not a quadratic residue modulo 4 and so there's no such $h$






















{\bf Problem 21}. Determine all positive integers $n$ such that $[\sqrt{n}]$ divides $n$

First, fix $n = a^2$ this means that for all integers $m \in \{n+1,n+2,\ldots,(a+1)^2-1\}$, $[\sqrt{m}] = a$ and since $a|n$ any number $w = n+aq, ~ n \le w < (a+1)^2$ is divisible by $a = [\sqrt{n}]$ so they are
%
\nbea
\{1,2,3,4,6,8,9,12,15,16,20,24,25,30,35,36,42,48,49,\ldots\}
\neea
%
so given an $n$ calculate $a=[\sqrt{n}]$ if $\sqrt{n}$ is not an integer calculate $b = n - a^2$ and see if $a|b$


{\bf Problem 22}. If $n$ is a positive integer, prove that
%
\nbea
\left \lbrack \frac{8n + 13}{25} \right \rbrack - \left \lbrack \frac{n - 12 - \left \lbrack \frac{n-17}{25}\right \rbrack}{3} \right \rbrack
\neea
%
is independent of $n$

%
\nbea
8n + 13 & = & 25w + r \\
8(n+1) + 13 & = & 25(w+1) + r' \\
8 & = & 25 + r' - r \\
\to r' - r & = & -17
\neea
%


%
\nbea
n-12 - l & = & 3u + z \\
(n+1) -12 - l' & = & 3(u+1) + z' \\
1 - (l' - l) & = & 3 + z' - z \\
(l'-l) & = & -2 + z - z' \\
(l'-l) +(z'-z) & = & -2
\neea
%


but since $(25,8) = 1$ it must mean that $25|a$ and the smallest $a$ is $a=25$.

%
\nbea
\frac{\frac{25j - 13}{8} - 17}{25} & = & 
\neea
%

Using Bezout's lemma, since $\gcd(25,8) = 1$ we have
%
\nbea
25x + 8y & = & 1 \\
25x' + 8y' & = & 13
\neea
%



OK, the strategy here is simple, although initially I wanted to see if I can utilize something from chapter 3 to solve this problem, maybe like putting a sum in front of those two terms and see what I get but let's just stay simple.

The strategy here is to show that when we increase $n$ the change in the first square bracket is the same as the change in the second square bracket, let's now look at the first square bracket more closely,
%
\nbea
%\begin{array}{}
8\cdot 1 + 13 & \equiv & -4 \pmod{25} \\
8\cdot 2 + 13 & \equiv & -5 \pmod{25} \\
8\cdot 5 + 13 & \equiv & -6 \pmod{25} \\
8\cdot 8 + 13 & \equiv & -7 \pmod{25} \\
8\cdot 11 + 13 & \equiv & -8 \pmod{25} \\
8\cdot 14 + 13 & \equiv & ~~0 \pmod{25} \\
8\cdot 15 + 13 & \equiv & -1 \pmod{25} \\
8\cdot 18 + 13 & \equiv & -2 \pmod{25} \\
8\cdot 21 + 13 & \equiv & -3 \pmod{25}
%\end{array}
\neea
%
The first thing to note here is that from $n \to n+3$ we go from $-x \pmod{25} \to -(x+1) \pmod{25}$ this means that going from $n+1\to n+2 \to n+3$ will not change $\left \lbrack \frac{8n+13}{25} \right \rbrack$ because
%
\nbea
8\cdot1 + 13 & = & 25\cdot0 + 21 \\
8\cdot2 + 13 & = & 25\cdot0 + 21 \\
\neea
%


and thus $8\cdot 14 + 13 \equiv 0 \pmod{25}$ meaning $8\cdot (13 + 3) + 13 \not\equiv -1 \pmod{25}$ instead $8\cdot(14 + 3) + 13 \equiv -1 \pmod{25}$

At the same time $\left \lbrack \frac{n-17}{25} \right \rbrack$ will change value at transition from $n=16 \to n=17$ and this is in sync with $\left \lbrack \frac{8\cdot 16 + 13}{25} \right \rbrack \to \left \lbrack \frac{8\cdot 17 + 13}{25} \right \rbrack$

the pattern repeats every 25 counts $n \to n + 25$ as 
%
\nbea
8m + 13 & = & 25j \\
8(m + 25) + 13 & = & 8m + 13 + 8\cdot 25 \\
& = & 25(j + 8)
\neea
%

%
\nbea
8(m + a) + 13 & = & 8m + 13 + 8\cdot a \\
25h & = & 25j + 8a \\
25(h-j) & = & 8a \\
25 &|& 8a
\neea
%
ditto with $\frac{n-17}{25}$





















\end{document}