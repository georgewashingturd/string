\documentclass[aps,preprint,preprintnumbers,nofootinbib,showpacs,prd]{revtex4-1}
\usepackage{graphicx,color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amssymb}
\usepackage{multirow}
\usepackage{amsthm}%        But you can't use \usewithpatch for several packages as in this line. The search 

\usepackage{cancel}

%%% for SLE
\usepackage{dcolumn}   % needed for some tables
\usepackage{bm}        % for math
\usepackage{amssymb}   % for math
\usepackage{multirow}
%%% for SLE -End

\usepackage{ulem}
\usepackage{cancel}

\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage[top=1in, bottom=1.25in, left=1.1in, right=1.1in]{geometry}

\usepackage{mathtools} % for \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newcommand{\msout}[1]{\text{\sout{\ensuremath{#1}}}}


%%%%%% My stuffs - Stef
\newcommand{\lsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$<$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}
\newcommand{\gsim}{\mathrel{\mathop{\kern 0pt \rlap
  {\raise.2ex\hbox{$>$}}}
  \lower.9ex\hbox{\kern-.190em $\sim$}}}

%
% Key
%
\newcommand{\key}[1]{\medskip{\sffamily\bfseries\color{blue}#1}\par\medskip}
%\newcommand{\key}[1]{}
\newcommand{\q}[1] {\medskip{\sffamily\bfseries\color{red}#1}\par\medskip}
\newcommand{\comment}[2]{{\color{red}{{\bf #1:}  #2}}}


\newcommand{\ie}{{\it i.e.} }
\newcommand{\eg}{{\it e.g.} }

%
% Energy scales
%
\newcommand{\ev}{{\,{\rm eV}}}
\newcommand{\kev}{{\,{\rm keV}}}
\newcommand{\mev}{{\,{\rm MeV}}}
\newcommand{\gev}{{\,{\rm GeV}}}
\newcommand{\tev}{{\,{\rm TeV}}}
\newcommand{\fb}{{\,{\rm fb}}}
\newcommand{\ifb}{{\,{\rm fb}^{-1}}}

%
% SUSY notations
%
\newcommand{\neu}{\tilde{\chi}^0}
\newcommand{\neuo}{{\tilde{\chi}^0_1}}
\newcommand{\neut}{{\tilde{\chi}^0_2}}
\newcommand{\cha}{{\tilde{\chi}^\pm}}
\newcommand{\chao}{{\tilde{\chi}^\pm_1}}
\newcommand{\chaop}{{\tilde{\chi}^+_1}}
\newcommand{\chaom}{{\tilde{\chi}^-_1}}
\newcommand{\Wpm}{W^\pm}
\newcommand{\chat}{{\tilde{\chi}^\pm_2}}
\newcommand{\smu}{{\tilde{\mu}}}
\newcommand{\smur}{\tilde{\mu}_R}
\newcommand{\smul}{\tilde{\mu}_L}
\newcommand{\sel}{{\tilde{e}}}
\newcommand{\selr}{\tilde{e}_R}
\newcommand{\sell}{\tilde{e}_L}
\newcommand{\smurl}{\tilde{\mu}_{R,L}}

\newcommand{\casea}{\texttt{IA}}
\newcommand{\caseb}{\texttt{IB}}
\newcommand{\casec}{\texttt{II}}

\newcommand{\caseasix}{\texttt{IA-6}}

%
% Greek
%
\newcommand{\es}{{\epsilon}}
\newcommand{\sg}{{\sigma}}
\newcommand{\dt}{{\delta}}
\newcommand{\kp}{{\kappa}}
\newcommand{\lm}{{\lambda}}
\newcommand{\Lm}{{\Lambda}}
\newcommand{\gm}{{\gamma}}
\newcommand{\mn}{{\mu\nu}}
\newcommand{\Gm}{{\Gamma}}
\newcommand{\tho}{{\theta_1}}
\newcommand{\tht}{{\theta_2}}
\newcommand{\lmo}{{\lambda_1}}
\newcommand{\lmt}{{\lambda_2}}
%
% LaTeX equations
%
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bit}{\begin{itemize}}
\newcommand{\eit}{\end{itemize}}

\newcommand{\nbea}{\begin{eqnarray*}}
\newcommand{\neea}{\end{eqnarray*}}
\newcommand{\nbeq}{\begin{equation*}}
\newcommand{\neeq}{\end{equation*}}

\newcommand{\no}{{\nonumber}}
\newcommand{\td}[1]{{\widetilde{#1}}}
\newcommand{\sqt}{{\sqrt{2}}}
%
\newcommand{\me}{{\rlap/\!E}}
\newcommand{\met}{{\rlap/\!E_T}}
\newcommand{\rdmu}{{\partial^\mu}}
\newcommand{\gmm}{{\gamma^\mu}}
\newcommand{\gmb}{{\gamma^\beta}}
\newcommand{\gma}{{\gamma^\alpha}}
\newcommand{\gmn}{{\gamma^\nu}}
\newcommand{\gmf}{{\gamma^5}}
%
% Roman expressions
%
\newcommand{\br}{{\rm Br}}
\newcommand{\sign}{{\rm sign}}
\newcommand{\Lg}{{\mathcal{L}}}
\newcommand{\M}{{\mathcal{M}}}
\newcommand{\tr}{{\rm Tr}}

\newcommand{\msq}{{\overline{|\mathcal{M}|^2}}}

%
% kinematic variables
%
%\newcommand{\mc}{m^{\rm cusp}}
%\newcommand{\mmax}{m^{\rm max}}
%\newcommand{\mmin}{m^{\rm min}}
%\newcommand{\mll}{m_{\ell\ell}}
%\newcommand{\mllc}{m^{\rm cusp}_{\ell\ell}}
%\newcommand{\mllmax}{m^{\rm max}_{\ell\ell}}
%\newcommand{\mllmin}{m^{\rm min}_{\ell\ell}}
%\newcommand{\elmax} {E_\ell^{\rm max}}
%\newcommand{\elmin} {E_\ell^{\rm min}}
\newcommand{\mxx}{m_{\chi\chi}}
\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%\newcommand{\mpt}{\rlap/p_T}

%%%song
\newcommand{\cosmax}{|\cos\Theta|_{\rm max} }
\newcommand{\maa}{m_{aa}}
\newcommand{\maac}{m^{\rm cusp}_{aa}}
\newcommand{\maamax}{m^{\rm max}_{aa}}
\newcommand{\maamin}{m^{\rm min}_{aa}}
\newcommand{\eamax} {E_a^{\rm max}}
\newcommand{\eamin} {E_a^{\rm min}}
\newcommand{\eaamax} {E_{aa}^{\rm max}}
\newcommand{\eaacusp} {E_{aa}^{\rm cusp}}
\newcommand{\eaamin} {E_{aa}^{\rm min}}
\newcommand{\exxmax} {E_{\neuo \neuo}^{\rm max}}
\newcommand{\exxcusp} {E_{\neuo \neuo}^{\rm cusp}}
\newcommand{\exxmin} {E_{\neuo \neuo}^{\rm min}}
%\newcommand{\mxx}{m_{XX}}
%\newcommand{\mrec}{m_{\rm rec}}
\newcommand{\erec}{E_{\rm rec}}
%\newcommand{\mrecmin}{m_{\rm rec}^{\rm min}}
%\newcommand{\mrecc}{m_{\rm rec}^{\rm cusp}}
%\newcommand{\mrecmax}{m_{\rm rec}^{\rm max}}
%%%song

\newcommand{\mc}{m^{\rm cusp}}
\newcommand{\mmax}{m^{\rm max}}
\newcommand{\mmin}{m^{\rm min}}
\newcommand{\mll}{m_{\mu\mu}}
\newcommand{\mllc}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\mllmax}{m^{\rm max}_{\mu\mu}}
\newcommand{\mllmin}{m^{\rm min}_{\mu\mu}}
\newcommand{\mllcusp}{m^{\rm cusp}_{\mu\mu}}
\newcommand{\elmax} {E_\mu^{\rm max}}
\newcommand{\elmin} {E_\mu^{\rm min}}
\newcommand{\elmaxw} {E_W^{\rm max}}
\newcommand{\elminw} {E_W^{\rm min}}
\newcommand{\R} {{\cal R}}

\newcommand{\ewmax} {E_W^{\rm max}}
\newcommand{\ewmin} {E_W^{\rm min}}
\newcommand{\mwrec}{m_{WW}}
\newcommand{\mwrecmin}{m_{WW}^{\rm min}}
\newcommand{\mwrecc}{m_{WW}^{\rm cusp}}
\newcommand{\mwrecmax}{m_{WW}^{\rm max}}

\newcommand{\mpt}{{\rlap/p}_T}

%%%%%% END My stuffs - Stef

\newcommand{\dunno}{$ {}^{\mbox {--}}\backslash(^{\rm o}{}\underline{\hspace{0.2cm}}{\rm o})/^{\mbox {--}}$}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\DeclareMathOperator{\re}{Re}


\begin{document}

\title{Notes on Pollack's ``Not Always Buried Deep''}
\bigskip
\author{Stefanus Koesno$^1$\\
$^1$ Somewhere in California\\ San Jose, CA 95134 USA\\
}
%
\date{\today}
%
\begin{abstract}
This is one of the best books on analytic number theory I've found to date. The comments here will be based on his notes with the same title instead of the book because the notes is free while the book is not :)

\end{abstract}
%
\maketitle

\renewcommand{\theequation}{A.\arabic{equation}}  % redefine the command that creates the equation no.
\setcounter{equation}{0}  % reset counter 

{\bf Page 3}. On {\it Euclid's second proof}. The trick here is to show that $\varphi(P) > 1$, one thing to note is that $\varphi(n)$ measures the number of numbers that are co-prime to $n$. Since $\varphi(P) > 1$, there is a number that is co-prime to $P$ but in that case that number must contain a new prime. The other details were to make sure there is such a co-prime number.

{\bf Page 4}. This is really clever, first let's do induction to show that $n_i = 2^{2^{i-1}} + 1$. For $i = 1$ this is obvious as $3 = 2^{2^0} + 1$ we just need to show the induction hypothesis is true, say $n_i = 2^{2^{i-1}} + 1$ we need to show the same holds for $n_{i+1}$
%
\nbea
n_{i+1} & = & 2 + \prod_{1 \le j < i+1} n_j \\
& = & 2 + n_i\prod_{1 \le j < i} n_j \\
& = & 2 + n_i(n_i - 2) \\
& = & 2  - 2n_i + n_i^2 \\
& = & (n_i - 1)^2 + 1 \\
& = & 2^{2^{i}} + 1
\neea
%

Next we tackle the claim that this upper bound on $p_n$ gives us a lower bound on $\pi(x)$. Start with
%
\nbea
p_i & < & n_i \\
& < & 2^{2^{i-1}} + 1 \\
& < & 2^{2^{\pi(p_i)-1}} + 1 \\
\log \log (p_i) & < & \pi(p_i)
\neea
%
where there will be some very small correction terms due to the constant in the exponent and the one outside and of course due to the fact that we are using natural log instead of $\log_2$.

{Page 5}. Top of page, ``the order of $2 \pmod{p}$ is precisely $2^i$'', why is this so? Why can't the order be smaller than $2^i$, this is because
%
\nbea
2^{2^i} & = & \left(\left(\left(2\right)^2\right)^2\right)^2\dots
\neea
%
so we are just squaring over and over again, and since $2^{2^{i-1}} \equiv -1$ this means that there's no lower exponent that produces $+1$ otherwise $2^{2^{i-1}}$ wouldn't have been $-1$.

Next we tackle the comment that ``$a_n = 2^n - 1$ has the desired properties (note that $a_{11} = 23\cdot89$).'' The problem is when $n=13$ which is also a prime $2^{13}-1=8191$ which is a prime, it even fails for $2^5 - 1 = 31$, in hindsight, this is obvious since there are things called the Mersenne primes  of the form $2^n - 1$ :)

I then tried changing it to $a_n = 2^n + 1$ but it fails for $n=3$ as $a_3 = 9$ and it doesn't have two distinct prime divisors but it's more promising, what we need is that $2^{2j+1} + 1$ to have more than 1 prime divisor, we know that $2^{2j+1} + 1$ is always a multiple of 3, it's obvious when you do (mod 3) as $2 \equiv -1 \pmod{3}$.

The question now is if there will be a $k$ such that $3^k = 2^{2j+1} + 1$, well for $j=1$ we have $3^2 = 2^3 + 1$ so how about for $j > 1$?

Suppose we find a $k$ such that $3^k = 2^{2j+1} + 1$, since $j > 1$, $4|2^{2j+1}$ and so by modulo 4 we know that $k$ is even since $3 \equiv -1 \pmod{4}$, so we can denote $k = 2m$
%
\nbea
3^{2m} & = & 2^{2j+1} + 1 \\
3^{2m} - 1 & = & 2^{2j+1}
\neea
%
Focusing on the LHS
%
\nbea
3^{2m} - 1 & = & (3 - 1)(3^{2m-1} + 3^{2m-2} + 3^{2m-3} + 3^{2m-4} + \dots + 3 + 1) \\
& = & 2(3^{2m-2} (3 + 1) + 3^{2m-4}(3 + 1) + \dots + (3 + 1)) \\
& = & 2^3(3^{2m-2} + 3^{2m-4} + \dots + 1)
\neea
%
Now there are $m$ terms inside the brackets in the RHS, if $m$ is odd then
%
\nbea
3^{2m-2} + 3^{2m-4} + 3^{2m-6} + 3^{2m-8} + \dots + 1 & = & (3^{2m-2} + 3^{2m-4}) + (3^{2m-6} + 3^{2m-8}) + \dots + 1 
\neea
%
Each bracket in the RHS is even and so the total is odd and thus
%
\nbea
3^{2m} - 1 & = & 2^3(2M+1)
\neea
%
and it can't be $2^{2j+1}$ since $(2M+1)$ is odd. Now if $m$ is even we get
%
\nbea
3^{2m-2} + 3^{2m-4} + 3^{2m-6} + 3^{2m-8} + \dots + 3^2 + 1 & = & 3^{2m-4}(3^2 + 1) + 3^{2m-8}(3^2 + 1) + \dots + (3^2 + 1) \\
& = & 2\cdot5(3^{2m-4} + 3^{2m-8} + \dots + 1)
\neea
%
but $5$ is prime and so $3^k - 1$ can't be $2^{2j+1}$. Therefore $2^{2j+1} + 1$ contains at least two prime divisors for $j > 1$ only for $j=1$ does it contain only one prime divisor.

But we cannot use $a_n = 2^n + 1$ for the proof in the book, because then each $a_n$ is a multiple of 3 and they are not co-prime.

The proof in the book still works even is we use $a_n = 2^n - 1$ as long as we include $n=11$ because then $a_2a_3a_5a_7a_{11}$ still have $5+1$ prime factors, note that $a_2,a_3,a_5,a_7$ are all prime numbers.

{\bf Page 9}. Mid page-ish, ``Proceeding as above, we deduce that $\sum_{p\le x}(p-1)^{-1} \ge \log \log x$'', it's very tempting to just do log on both sides of (1.4) since the RHS is already $\log x$ but this will lead to some messy situation, salvageable but messy
%
\nbea
\log \left ( \prod_{p\le x} \frac{1}{1 - \frac{1}{p}} \right ) & \ge & \log \log x \\
\sum_{p\le x} \log \left (\frac{p}{p-1}\right ) & \ge & \log \log x
\neea
%

We can still proceed by showing that
%
\nbea
\frac{1}{p - 1} & > & \log \left (\frac{p}{p-1}\right )
\neea
%
One way to show this is to show $\frac{1}{x - 1} > \log \left (\frac{x}{x-1}\right )$ instead with all real number $x \ge 2$ ( we choose 2 as the starting point for simplicity).

Well we know that at $x = 2$, $\frac{1}{2 - 1} > \log \left (\frac{2}{2-1}\right )$, we now show that the slope for $\frac{1}{x - 1}$ is always smaller to that of $\log \left (\frac{x}{x-1}\right )$ for all $x$ and so $\frac{1}{x - 1} > \log \left (\frac{x}{x-1}\right )$ always holds (we need a smaller slope because the function is a decreasing one).

The slope for $\frac{1}{x - 1}$ is
%
\nbea
\frac{d}{dx}\left( \frac{1}{x - 1} \right ) & = & -\frac{1}{(x-1)(x-1)}
\neea
%
while for $\log \left (\frac{x}{x-1}\right )$
%
\nbea
\frac{d}{dx} \left (\log \left (\frac{x}{x-1}\right ) \right ) & = & -\frac{1}{x(x-1)}
\neea
%
and so the slope for $\frac{1}{x - 1}$ is indeed smaller than that of $\log \left (\frac{x}{x-1}\right )$ and so $\frac{1}{x - 1} > \log \left (\frac{x}{x-1}\right )$, this is one way.

Another way to show that $\sum_{p\le x}(p-1)^{-1} \ge \log \log x$ is to go back to the top of Page 9
%
\nbea
\prod_{p \le x} \frac{1}{1 - \frac{1}{p}} & = & \prod_{p \le x} \left ( 1 + \frac{1}{p - 1} \right ) \\
& \le & \prod_{p \le x} e^{1/(p-1)} = e^{\sum_{p\le x}(p-1)^{-1}}
\neea
%
Combining all the inequalities (the one involving $\log x$ is from (1.4))
%
\nbea
\log x \le \prod_{p \le x} \frac{1}{1 - \frac{1}{p}} \le e^{\sum_{p\le x}(p-1)^{-1}}
\neea
%
taking the logarithm of both the far LHS and far RHS we have
%
\nbea
\log \log x \le \sum_{p\le x}(p-1)^{-1}
\neea
%
which is what we want to show in the first place.

{\bf Page 11}. There's a simple mistake on {\it J. Perott's proof}, ``by removing those divisible by $1^2 \dots$'', we cannot remove numbers divisible by $1^2$ because then we will remove every number :)

{\bf Page 12}. On J. Perott's proof, top of page, ``It follows that $A(N)/N$ is bounded below $\dots$ so the squarefree numbers have positive lower density'', what it all means is that since $A(N)/N$ has a lower bound, if there are only a finite number of squarefree numbers then after a while (once we've passed the last one) $A(N)/N$ will get smaller and smaller and eventually gets smaller than the lower bound which is not allowed :)

{\bf Page 13}. First paragraph, the conclusion of Erdos's super smart proof, ``But $C\sqrt{N} < N/2$ whenever $N$ is large'', the question is so what? we know that $C\sqrt{N}$ is the number of integers $\le N$ whose prime factors $\le M$. The problem here is that we know that from page 12, the number of integers $\le N$ whose prime factors $> M$ is $< N/2$, so the total number of integers (those with prime factors $\le M$ + those with prime factors $> M$) must be $N$ but here we have $< N/2$ + $< N/2$ which can never reach $N$



{\it Exercise} 1.2.7. {\bf Page 9}. It's interesting that removing $\sum_p 1/p$ from $\sum_n 1/n$ makes the latter a convergent series. The question now is what is the minimum amount we need to subtract from $\sum_n 1/n$ to make it convergent?

Anyway, what we want to show is that $\sum_n 1/n$ with only {\it squarefull} $n$ converges. We start with
%
\nbea
\prod_p \left( 1 + \frac{1}{p^2} + \frac{1}{p^3} + \dots\right ) = \prod_p \left (\frac{1}{1 - \frac{1}{p}} \right ) - \frac{1}{p}
\neea
%
\ie we remove the $1/p$ term from each series. Note that $1$ is a squarefull number because the statement is that if $p|n$ then $p^2|n$ is a must, but for $1$ no $p$ divides 1 so it is considered squarefull a well. We then follow the same method as shown on Page 9
%
\nbea
\prod_p \left\lbrack\left (\frac{1}{1 - \frac{1}{p}} \right ) - \frac{1}{p}\right\rbrack = \prod_p \left ( 1 + \frac{1}{p-1} - \frac{1}{p} \right ) = \prod_p \left( 1 + \frac{1}{p(p-1)}\right )
\neea
%
Now note that $1/(p-1) < 2/p$ so
%
\nbea
\prod_p \left( 1 + \frac{1}{p(p-1)}\right ) < \prod_p \left( 1 + \frac{2}{p^2}\right ) < \prod_p e^{2/p^2} = e^{\sum_{p} 2/p^2} < e^{2C}
\neea
%
We can safely deduce that $\sum_p 1/p^2 < C$ because it is a convergent series, since the above is convergent by Theorem 1.2.2, $\sum_n 1/n$ with $n$ only squarefull numbers is also convergent.

As for $\alpha$ so that $\sum_n 1/n^\alpha$ is also convergent, my first guess will be $\alpha > 1/2$, this is because with $\alpha = 1/2$ we will have $1/p$ term in the series and it will cause things to blow up. Another clue is in the fact that involving an exponent $\alpha$ means that the upper bound becomes
%
\nbea
e^{\sum_{p} 2/p^{2\alpha}}
\neea
%
and if $\alpha$ goes below $\le 1/2$ we will have an divergent series while $\sum_n 1/n^\beta$ is convergent if $\beta > 1$ by the integral test.

{\it Exercise } 1.3.1. {\bf Page} 22. We want to show that
%
\nbea
\int_2^x \frac{dt}{\log t} & \sim & \frac{x}{\log x}
\neea
%
using L'Hospital's rule. From what I know L'Hospital's rule only works if the limit is indefinite like $0/0$ or $\infty/\infty$ but looks like I was wrong, you can use is even if it's not indefinite.

So we need to do a derivative w.r.t $x$ on the integral above, how do we do it? for now assume that the integral is indefinite
%
\nbea
\int \frac{dt}{\log t} = F(t) ~~~~~ \longrightarrow ~~~~~ \int_2^x \frac{dt}{\log t} = F(x) - F(2)
\neea
%
Taking the derivative with respect to $x$ means that
%
\nbea
\frac{d}{dx} \int_2^x \frac{dt}{\log t} & = & \frac{d}{dx} F(x)
\neea
%
But in this case
%
\nbea
\frac{d}{dx} F(x) = \left.\frac{d}{dt}F(t) \right|_{t = x} = \left.\frac{d}{dt}\left(\int \frac{dt}{\log t}\right) \right|_{t = x} = \frac{1}{\log x}
\neea
%
While (on the other hand)
%
\nbea
\frac{d}{dx} \left ( \frac{x}{\log x} \right )  = \frac{\log x - 1}{\log^2 x} = \frac{1}{\log x} - \frac{1}{\log^2}
\neea
%
taking the ratio
%
\nbea
\lim_{x\to\infty} \frac{x/\log x}{\int_2^x dt/\log t} & = & \lim_{x\to\infty} \frac{1/\log x - 1/\log^2x}{1/\log x} \\
& = & \lim_{x\to\infty} 1 - \frac{1}{\log x} \\
& = & 1
\neea
%

{\bf Page 24}. Before Lemma 1.4.2. This is a bit confusing, well more than a bit actually :) ``Another way of viewing this argument is that all but finitely many primes fall into the unique reduced residue class (mod 2); from this perspective, the correct generalization is in plain sight. Namely, take any integer $q$; then every prime $p \nmid q$ has to fall into one of the $\varphi(q)/q$ reduced residue classes (mod $q$), and this forces the proportion of primes to be at most $\varphi(q)/q$.''

First, $\varphi(q)$ is the Euler totient function, \ie the number of numbers $< q$ that are co-prime to $q$. The original logic was that since half of all integers are even, so the proportion of prime numbers can only be at most 1/2. So at first, this looks a lot like the logic of sieve. Since you know that 2 is prime any multiple of 2 cannot be prime and so half of the numbers are gone. But this is not what we are doing, we are not doing sieve.

Instead what happens is this, if we choose $q=4$ instead of 2, now if we group the integers as follows
%
\nbea
\{\textbf{\textit 1},2,\textbf{\textit 3},4\},\{\textbf{\textit 5},6,\textbf{\textit {7}},8\},\{\textbf{\textit 9},10,\textbf{\textit {11}},12\}, \dots
\neea
%
\ie we are grouping them as residue classes of (mod 4), we see that each \textbf{\textit{bold}} number is co-prime to 4, now the number itself might bot be prime, \eg \textbf{\textit{9}}, but \textbf{\textit{they}} are all co-prime to 4. Recall that $\gcd(a, q) = \gcd(a + qm, q)$ so if $a \equiv b \pmod{q}$ then $\gcd(a,q) = \gcd(b,q)$ and so in each residue class the number of numbers that are co-prime to $a$ stays the same.

A number can only be prime if it is co-prime to $q$, which in this case is 4, this is a necessary condition, not a sufficient one, but we are only interested in the upper bound here so the necessary condition is sufficient :)

So if we group the integers into the residue classes of $q$ there will be $\varphi(q)$ numbers that are co-prime to $q$ and so the upper bound of the ratio of the prime numbers to all of the numbers is obviously $\varphi(q)/q$. But of course there's a caveat, this is correct only for the second residue class and beyond, in the first residue class, \{\textbf{\textit 1},\underline{2},\textbf{\textit 3},4\}, 2 is also prime but it doesn't contribute towards $\varphi(q)$ because $2|4$, but this doesn't matter since the upper bound of the total ratio is given by
%
\nbea
\frac{(\Delta + \varphi(q)) + \varphi(q) + \varphi(q) + \dots }{q + q + q + \dots} = \frac{\Delta + \infty\cdot \varphi(q)}{\infty \cdot q} = \frac{\varphi(q)}{q}
\neea
%
Now, the statement ``all but finitely many primes fall into the unique reduced residue class (mod 2);'' means this, say for our $q=4$ example above, each residue class, whether the first, second or third, each of them can only take a finite amount of prime numbers and each prime number must of course fall into only one of them, ergo the word ``unique'', that's what the statement above means.

{\bf Page 24}. Top of page, ``the partial products $\prod_{2\le n\le x} n/(n-1)$ telescope to $\floor{x}$'', it telescope because
%
\nbea
\prod_{2\le n\le x} \frac{n}{n-1} = \frac{\bcancel{2}}{1}\cdot\frac{\bcancel{3}}{\bcancel{2}}\cdot\frac{\bcancel{4}}{\bcancel{3}} \dots \frac{x}{\bcancel{x-1}} = \frac{x}{1}
\neea
%

{\bf Page 24}. Lemma 1.4.2. The first equality, recall that due to its multiplicity $\varphi(q) = \prod_{p_i} p_i^{\alpha_i - 1}( p_i -1) = \prod_{p_i} p_i^{\alpha_i }( 1 -1/p_i)$, so when you divide it by $q$, the $p_i^{\alpha_i }$ terms disappear and you're left with only the $\prod_{p_i} ( 1 -1/p_i)$.

In physics I always use the expansion $\frac{1}{1-x} = 1 + x + x^2 + \dots$, \ie the geometric series, here, we use this a lot too :) to get the inequality $\varphi(q_x)/q_x \le (\log x)^{-1}$, we need to invert it
%
\nbea
\frac{1}{\prod_{p\le x}1/(1-1/p)} = \prod_{p\le x}\left(1 + \frac{1}{p} + \frac{1}{p^2} + \frac{1}{p^3} + \dots \right) = \sum_{n: p|n, p \le x} \frac{1}{n} \ge \sum_{n \le x} \frac{1}{n} \ge \log x
\neea
%
and then we invert it again and y doing so reverses the inequality sign as well.

{\bf Page 24}. Last equation on page, we need to be careful here, first we choose our desired $\epsilon$ then to get $\varphi(q)/q < \epsilon/2$ we need to choose $q$, and finally once we've fixed $q$ we can choose $x$ big enough to get $\varphi(q)/x + \nu(q)/x < \epsilon/2$.

{\bf Page 25}. Last sentence of first paragraph, ``the second product below telescopes so is easy to compute'', 
%
\nbea
\prod_{n=2}^\infty \frac{n^2}{n^2 - 1} & = & \frac{2^2}{2^2-1} \cdot \frac{3^2}{3^2 - 1} \cdot \frac{4^2}{4^2 - 1} \dots \\
& = & \frac{2~\bcancel{(3-1)}}{(2-1)~\cancel{(2+1)}} \cdot \frac{\cancel{(2+1)}~\bcancel{(4-1)}}{\bcancel{(3 - 1)}~\cancel{(3 + 1)}} \cdot \frac{\cancel{(3+1)}~\bcancel{(5-1)}}{\bcancel{(4 - 1)}~\cancel{(4+1)}} \dots \\
& = & \frac{2}{1}
\neea
%
only the first term survives.

{\bf Page 25}. Eq (1.21), it's just a different way of writing
%
\nbea
\int_{3/2}^x \frac{1}{t} \pi'(t) dt = \int_{3/2}^x \frac{1}{t} \frac{d\pi(t)}{\bcancel{dt}} \bcancel{dt} = \int_{3/2}^x \frac{1}{t} d\pi(t)
\neea
%
where the cancellation is basically the chain rule





-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

{\it Exercise} 1.3.2, {\bf Page} 22, show that $p_n \sim n \log n$. The hint tells us that we need to show that if $a_n \sim b_n$ then $a_n \log a_n \sim b_n \log b_n$, let's do this first.

The key is to use L'Hospital's rule
%
\nbea
\lim_{n\to\infty} \frac{a_n\log a_n}{b_n\log b_n} & = & \lim_{n\to\infty} \frac{a_n}{b_n} \cdot \frac{\log a_n}{\log b_n} \\
& = & \lim_{n\to\infty} 1 \cdot \frac{1/a_n}{1/b_n}, ~~~~~  \lim_{n\to\infty} \frac{a_n}{b_n} = 1 {\rm~by~hypothesis}\\
& = & 1
\neea
%
We then set $a_n = p_n\log p_n$ and $b_n = n$, we now need to show that $p_n/\log p_n \sim n$
%
\nbea
\lim_{n\to\infty}\frac{p_n\log p_n}{n} & = & \lim_{n\to\infty}\frac{p_n\log p_n}{\pi(p_n)}, ~~~~~ \pi(p_n) \sim p_n\log p_n {\rm~from~PNT} \\
& = & \lim_{n\to\infty}\frac{p_n/\log p_n}{p_n/\log p_n} \\
& = & 1
\neea
%
Finally, as a consequence of the above result, \ie $a_n \sim b_n \to a_n\log _n \sim b_n \log b_n$ we have
%
\nbea
1 = \lim_{n\to\infty}\frac{p_n\log p_n\log(p_n\log p_n)}{n\log n} & = & \lim_{n\to\infty}\frac{p_n}{n\log n} + \frac{\log p_n\log(p_n\log p_n)}{\pi(n)\log \pi(n)} \\
& = & \lim_{n\to\infty}\frac{p_n}{n\log n} + \frac{\log^2 p_n + \log \log p_n}{p_n/\log p_n \log (p_n/\log p_n)} \\
& = & \lim_{n\to\infty}\frac{p_n}{n\log n} + \frac{\log^2 p_n + \log \log p_n}{p_n - \log \log p_n/\log p_n} \\
& = & \lim_{n\to\infty}\frac{p_n}{n\log n} + \frac{p_n}{p_n}\cdot\frac{\log^2 p_n/p_n + \log \log p_n/p_n}{1 - \log \log p_n/p_n\log p_n} \\
& = & \lim_{n\to\infty}\frac{p_n}{n\log n} + 0 \\
1 & = & \lim_{n\to\infty}\frac{p_n}{n\log n}
\neea
%

{\it Exercise} 1.4.3, {\bf Page} 26, so we have non-negative function $f$ (for $x > x_0$) and $f(x)\to\infty$ as $x\to\infty$, need to find a set of integers $\mathcal{A}$ where
%
\nbea
\sum_{a\in\mathcal{A}} \frac{1}{a} = \infty ~~~~~~~~~~~~ \liminf_{x\to\infty}\frac{A(x)}{f(x)} = 0
\neea
%

We can follow the hint or just reuse (1.21), replacing $\pi(x)$ with $A(x)$ (the function that counts the members of $\mathcal{A}$ less than equal to $x$) and the lower integration limit to $N-1$ instead of $3/2$
%
\nbea
\sum_{a\in\mathcal{A}} \frac{1}{a} & = & \int_{N-1}^{x} \frac{dA(t)}{t} \\
& = & \frac{A(x)}{x} - \frac{A(N-1)}{N-1} + \int_{N-1}^x \frac{A(t)}{t^2}dt \\
& = & \int_{N-1}^x \frac{A(t)}{t^2}dt + O(1)
\neea
%
Since we are not including every number we know that $A(x)$ is at most $x$ so $A(x)/x$ is at most 1, ergo the $O(1)$.

But I actually don't understand this problem, say $f(x) = \log x$ which meets our criteria above, if $\liminf_{x\to\infty} A(x)/f(x) = 0$, does it mean that $A(x)$ is slower than $\log(x)$? if that's the case the integral above will be finite and the sum $\sum 1/a$ will not be divergent which is a contradiction.

Recall that the definition of $\liminf$ is
%
\nbea
\liminf_{x\to\infty} g(x) = \lim_{n\to\infty}\left(\inf_{x>n} g(x)\right) = L
\neea
%
where $\inf$ means the lowest value in that set which in this case is the lowest value of $g(x)$ for $x > n$. Now the definition of $\lim_{n\to\infty}$ in itself means for every number $\varepsilon > 0$ there is some number $M > 0$ such that
%
\nbea
\left|\left(\inf_{x>n} g(x)\right) - L\right| < \varepsilon ~~~~~ {\rm whenever} ~~~~~ n > M
\neea
%
so here once $\varepsilon$ is given we then choose an $M$ such that $\left|\left(\inf_{x>M} g(x)\right) - L\right| < \varepsilon$ (we have replaced $x>n \to x>M$ since $n > M$). In our case $g(x) = A(x)/f(x)$ and $L = 0$.

Note that $A(x)$ just like $\pi(x)$ is piecewise continuous. So what we need to do is to leave gaps in the set $\mathcal{A}$ so that say for some $x > M$ there is a section $x\in(M<a,b)$ where $A(x)$ stays constant meanwhile $f(x)$ is always growing, but this also means that since $A(x)$ has been stagnant for some time $A(x)/f(x)$ in $(a>m,b)$ can be set to be less than $\varepsilon$ which can be achieved by extending the stagnation interval to inhibit the growth of $A(x)$, we need to do this periodically because $\varepsilon$ can be any real number.

The only thing left is to see if producing gaps like this will still result in divergent $\sum 1/a$. I actually have a ``counter example'', say we start with the harmonic series $1/n$ and we pick only a few numbers every $e^x$, \ie 
%
\nbea
\sum_{n=\ceil{e^1}+1}^{\ceil{e^1}+2} \frac{1}{n} + \sum_{n=\ceil{e^2}+1}^{\ceil{e^2}+2} \frac{1}{n} + \sum_{n=\ceil{e^3}+1}^{\ceil{e^3}+2}\frac{1}{n} + \dots
\neea
%
We can estimate this series by replacing each sum with an integral (of course the value of the integral will be $>$ than the corresponding sum) and the integrals will yield
%
\nbea
\int_{e^1}^{e^1+3} \frac{dx}{x} + \int_{e^2}^{e^2+3} \frac{dx}{x} + \int_{e^3}^{e^3+3} \frac{dx}{x} + \dots & = & \log\left(\frac{e^1 + 3}{e^1}\right) + \log\left(\frac{e^2 + 3}{e^2}\right) + \log\left(\frac{e^3 + 3}{e^3}\right) + \dots \\
& = & \sum_{k = 1}^{\infty} \log \left(\frac{e^k+3}{e^k}\right)
\neea
%
If we do an integral test on the above we'll get ${{\mathit{li}}_{2}}\left(-3{{e}^{-x}}\right)$, the dilogarithm function and the limit as $x\to\infty$ is zero and so by the integral test it is convergent, so in this case we remove too many things. If instead of $e^k$ we pick $k^m$
%
\nbea
\sum_{k = 1}^{\infty} \log \left(\frac{k^{m}+3}{k^{m}}\right)
\neea
%
the above is only divergent for $m=1$ and is convergent for all $m > 1$.

A cautionary tale in taking a limit, during my adventure deploying the root test
%
\nbea
\lim_{k\to\infty} \left|a_k\right|^{1/k} & = & \lim_{k\to\infty} \left(\log\left(\frac{k+3}{k}\right)\right)^{1/k}
\neea 
%
for $k$ really big $k+3/k \to 1$ and $\log(k+3/k) \to 0^{+}$, the $k^{\rm th}$ root of a number less than 1 is obviously less than 1, the bigger $k$ is the closer to 1 the $k^{\rm th}$ root is, so at a glance it seems like the limit is less than 1 but this is wrong. If we take the log we get
%
\nbea
\lim_{k\to\infty} \log\left(\log\left(\frac{k+3}{k}\right)\right)^{1/k} & = & \lim_{k\to\infty} \frac{\log\left(\log\left(\frac{k+3}{k}\right)\right)}{k} \\
& = & 0 \\
\to \lim_{k\to\infty} \left(\log\left(\frac{k+3}{k}\right)\right)^{1/k} & = & 1
\neea
%

Note that
%
\nbea
\liminf_{x\to\infty} \frac{A(x)}{f(x)} = 0 ~~~~~~~~ {\rm means~that} ~~~~~~~~ A(x) \ll f(x) ~~~{\rm i.e} ~~~ A(x) = O(f(x))
\neea
%
while what we want is the reverse $f(x) = O(A(x))$












\end{document}